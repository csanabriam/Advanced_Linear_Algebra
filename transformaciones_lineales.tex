\chapter{Estructura de las transformaciones lineales}

Sea $\mathbb{K}$ un cuerpo.

\section{Descomposici\'on por suma directa}

Sean $V$ y $W$ espacios vectoriales sobre $\mathbb{K}$.

\begin{defn}
  Sean $V_1,\ldots,V_r$ subespacios de $V$. Cuando tenemos $V=V_1\oplus\cdots\oplus V_r$ llamamos a esta igualdad una \emph{descomposición en suma directa}, o simplemente \emph{una descomposición}, de $V$.
\end{defn}

\begin{teo}\label{descomposicionsumadirecta}
Dada $f\in\Hom_\mathbb{K}(V,W)$, existen $V_0,V_1\le V$ y $W_1,W_2\le W$ tales que $V=V_0\oplus V_1$ y $W=W_1\oplus W_2$ con $\ker(f)=V_0$ e $\im(f)=W_1$. En particular $f$ induce un isomorfismo entre $V_1$ y $W_1$.
\end{teo}

\dem Sea $\mathcal{B}_0$ una base de $V_0=\ker(f)$, la cual extendemos a una base $\left(\mathcal{B}_0| \mathcal{B}_1\right)$ de $V$. Defina $V_1=\langle \mathcal{B}_1\rangle$. As\'i, por la observación \ref{baseparticion} se tiene $V=V_0\oplus V_1$. Por otro lado, si $v,v'\in V_1$ son tales que $f(v)=f(v')$, entonces $v-v'\in \ker(f)=V_0$, luego $v-v'\in V_0\cap V_1=\{0\}$, luego $v=v'$. Es decir la restricci\'on de $f$ a $V_1$ es inyectiva.\\
Sea $\mathcal{B}'_1=f(\mathcal{B}_1)$. Como la restricción de $f$ a $V_1$ es inyectiva, es decir que $f(v)=0$ con $v\in V_1$ si y solo si $v=0$, entonces $\mathcal{B}'_1$ es linealmente independiente. Defina $W_1=\langle \mathcal{B}'_1\rangle$, de forma que $\mathcal{B}'_1$ es una base de $W_1$ y $W_1=f(V_1)$. Por construcci\'on $\im(f)=W_1$; pues, dado $w\in\im(f)$, existe $v\in V$ tal que $w=f(v)$, si $v=v_0+v_1$ con $(v_0,v_1)\in V_0\times V_1$, se tiene $w=f(v)=f(v_0)+f(v_1)=f(v_1)$. Finalmente, extienda $\mathcal{B}'_1$ a una base $\left(\mathcal{B}'_1| \mathcal{B}'_2\right)$ de $W$. Si $W_2=\langle \mathcal{B}'_2\rangle$ se tiene $W=W_1\oplus W_2$. Como $f$ es inyectiva en $V_1$ y $f(V_1)=W_1$, $f$ induce un isomorfismo entre $V_1$ y $W_1$.\qed

\begin{obs}
Suponga que en el teorema \ref{descomposicionsumadirecta} los espacios $V$ y $W$ tienen dimensi\'on finita, con $n=\dim(V)$, $m=\dim(W)$ y $r=\dim(\im(f))$. Si, como en la demostración, $\mathcal{B}_0$, $\mathcal{B}_1$ son bases de $V_0$ y $V_1$, y $\mathcal{B}'_1$ y $\mathcal{B}'_2$ son bases de $W_1$ y $W_2$. sea $f\in\Hom_\mathbb{K}(V,W)$, y denote $n=\dim(V)$, $m=\dim(W)$ y $r=\dim(\im(f))$. Entonces para las bases $\mathcal{B}=\left(\mathcal{B}_1|\mathcal{B}_0\right)$ y $\mathcal{B}'=\left(\mathcal{B}'_1|\mathcal{B}'_2\right)$ de $V$ y $W$, para
\[
A=\Big[f\Big]^{\mathcal{B}'}_{\mathcal{B}}=(a_{ij}),
\]
se tiene $a_{ii}=1$ si $0\le i\le r$ y $a_{ij}=0$ si $i\ne j$, o si $r<i$ e $i=j$. Es decir
\[
A=\left[\begin{array}{c|c}
I_r & 0\\
\hline
0   & 0
\end{array}\right]
\]
donde $I_r$ denota la matriz $r\times r$ con unos en diagonal y ceros en el resto de entradas y $0$ denota los or\'igenes de $M_{r\times (n-r)}(\mathbb{K})$, $M_{(m-r)\times r}(\mathbb{K})$ y $M_{(m-r)\times(n-r)}(\mathbb{K})$.
\end{obs}

\section{Espacios estables y propios}

Sea $V$ un espacio vectorial sobre $\K$ y $f$ un operador de $V$, e.d. $f\in\End_K(V)$.

\begin{obs}
Sean $A=(a_{ij})_{i,j=1}^n$ y $C=(c_{ij})_{i,j=1}^n$ matrices $n\times n$. Se tiene
\[
  \tr(AC)=\sum_{i=1}^n\sum_{j=1}^na_{ij}c_{ji}=\sum_{j=1}^n\sum_{i=1}^nc_{ij}a_{ji}=\sum_{i=1}^n\sum_{j=1}^nc_{ij}a_{ji}=\tr(CA).
\]
Ahora, si $V$ tiene dimensi\'on finita igual a $n$, dadas dos bases $\mathcal{B}$ y $\mathcal{B}'$ de $V$, tenemos dos matrices $n\times n$ de $f$, $A=\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$ y $B=\Big[f\Big]^{\mathcal{B}'}_{\mathcal{B}'}$. Entonces, si adem\'as $C=\Big[\id_V\Big]_{\mathcal{B}'}^{\mathcal{B}}$ es la matriz de cambio de coordenadas de $\B$ a $\B'$, se tiene
\[
  B=C^{-1}AC,
\]
y
\begin{eqnarray*}
  \tr(B) & = &\tr(C^{-1}AC)=\tr(ACC^{-1})\\
           & = &\tr(A)\\
  \det(B) & = & \det(C^{-1}AC)=\det(C)^{1}\det(A)\det(C)\\
             & = &\det(A)
\end{eqnarray*}
Es decir que la traza y el determinante de la matriz de un operador lineal, tomando la misma base para el dominio y el rango, es independiente de la base escogida.
\end{obs}

\begin{defn}
Suponga que $V$ tiene dimensi\'on finita. Definimos el \emph{determinante} y la \emph{traza} de $f$ respectivamente por
\[
\det(f)=\det\left(\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}\right)\qquad \tr(f)=\tr\left(\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}\right).
\]
donde $\mathcal{B}$ cualquier base de $V$.
\end{defn}

\begin{defn}
Sea $V_0\le V$. Decimos que $V_0$ es \emph{estable bajo $f$} (ó \emph{$f$-estable}) si $f(V_0)\le V_0$. En tal caso, a la restricci\'on de $f$ a $V_0$ la denotamos $f_{V_0}$, esto es $f_{V_0}\in\Hom_\mathbb{K}(V_0,V_0)$ es el operador definido por:
\begin{eqnarray*}
f_{V_0}: V_0 & \longrightarrow & V_0\\
 v_0 & \longmapsto & f(v_0)
\end{eqnarray*}
\end{defn}

\begin{obs}
  De acuerdo con la proposición \ref{operadorcociente}, cuando $V_0\le V$ es estable bajo $f$, el operador $f$ induce un operador $f_{/V_0}$ de $V/V_0$.
\end{obs}

\begin{obs}\label{festablecompa}
  Suponga que $V$ es finito-dimensional. Dado $v\in V$ no nulo, existe un entero $r$ maximal tal que $\{v,f(v),\ldots,f^{r-1}(v)\}$ es linealmente independiente. Luego, por la propiedad \ref{inddep}, existen $a_0,\ldots,a_{r-1}\in\K$ tal que
  $$f^r(v)=a_{r-1}f^{r-1}(v)+\ldots+a_{1}f(v)+a_0v.$$
De esta forma, $V_0=\langle v,f(v),\ldots,f^{r-1}(v)\rangle$ es $f$-estable. Más aún, sí $\B$ es una base de $V$ que extiende la base $\B_0=(v,f(v),\ldots,f^{r-1}(v))$ de $V_0$, entonces la matrix de $f$ para $\B$ es de la forma
  $$
    \left[f\right]_\B^\B=\left[\begin{array}{c|c}
      A & B\\
      \hline
      O & C
    \end{array}\right]
  $$
donde $A$ es la matriz compañera
  $$
  A=\left[\begin{array}{ccccc}
    0 & 0 & \cdots & 0 & a_0\\
    1 & 0 & \cdots & 0 & a_1\\
    0 & 1 & \cdots & 0 & a_2\\
    \vdots & \vdots & \ddots & \vdots & \vdots\\
    0 & 0 & \cdots & 1 & a_{r-1}
  \end{array}\right]=\left[f_{V_o}\right]_{\B_0}^{\B_0}.
  $$
\end{obs}

\begin{defn}
  Un escalar $\lambda\in\K$ es un \emph{valor propio} de $f$ si $f(v)=\lambda v$ para algún vector no nulo $v\in V$, y en tal caso decimos que $v$ es un \emph{vector propio} de $f$ con valor propio $\lambda$. Si $\lambda$ es un valor propio de $f$, al subespacio de vectores $v\in V$ tales que $f(v)=\lambda v$ lo llamamos el espacio propio de $f$ asociado a $\lambda$.
\end{defn}

\begin{obs}
  Si $V_0\le V$ es el espacio propio asociado al valor propio $\lambda_0$, entonces $V_0$ es un subespacio $f$-estable tal que $f_{V_0}=\lambda_0\id_{V_0}$.
\end{obs}

\begin{defn}
Sea $A=(a_{ij})$ una matriz $n\times n$. Decimos que $A$ es \emph{diagonal} si $a_{ij}=0$ siempre que $i\ne j$. Si $V$ tiene dimensión finita, decimos que el operador $f$ es diagonalizable si $A=\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$ es diagonal para alguna base $\mathcal{B}$ de $V$.
\end{defn}

\begin{teo}\label{diagosiysolosi}
Si $V$ tiene dimensión finita, el operador $f$ es diagonalizable si y solo si existe una descomposición $V=V_1\oplus\cdots\oplus V_r$ en subespacios propios. En tal caso, si, para $i\in\{1,\ldots,r\}$, $V_i$ es un espacio propio asociado a $\lambda_i$, entonces $f=\lambda_1\id_{V_1}\oplus\cdots\oplus\lambda_r\id_{V_r}$ y $f=\lambda_1p_1+\cdots+\lambda_rp_r$ donde $p_1,\ldots,p_r$ son las proyecciones de acuerdo a la descomposición $V=V_1\oplus\cdots\oplus V_r$ (ver la observación \ref{sumayproyeccion}).
\end{teo}

\dem Suponga primero que $f$ es diagonalizable y sea $\mathcal{B}=(v_1,\ldots,v_n)$ una base de $V$ tal que $A=(a_{ij})=\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$ es diagonal. Para cada $i\in\{1,\ldots,n\}$, defina $V_i=\langle v_i\rangle$, de forma que $V=V_1\oplus\cdots\oplus V_n$ (ver la observación \ref{baseparticion}). Dado $j\in\{1,\ldots,n\}$, se tiene, por definición de $A$, $f(v_j)=a_{1j}v_1+\cdots+a_{nj}v_n$. Pero, como $A$ es diagonal, entonces $a_{ij}=0$ si $i\ne j$ y así $f(v_j)=a_{jj}v_j$. En particular, cada $V_j$ es $f$-estable, $f_{V_j}=\lambda_j\id_{V_j}$ con $\lambda_j=a_{jj}$ y tenemos que $V=V_1\oplus\cdots\oplus V_n$ es una descomposición en subespacios $f$-estables. Finalmente, los espacios $V_j$ con un mismo valor $\lambda_j$ se puede sumar para obtener un espacios propio.\\
Suponga ahora que tenemos una descomposición $V=V_1\oplus\cdots\oplus V_r$ en espacios propios asociados a loa valores propios $\lambda_1,\ldots,\lambda_r\in\K$. Para cada $i\in\{1,\ldots,r\}$, tomamos una base $\B_i$ de $V_i$. En particular, si $v\in B_i$ entonces $f(v)=\lambda_iv$. La concatenación $\mathcal{B}=\left(\B_1|\cdots|\B_r\right)$ es una base de $V$. Sea $\B=(v_1,\ldots,v_n)$ y $A=(a_{ij})=\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$, es decir que $f(v_j)=a_{1j}v_1+\cdots+a_{nj}v_n$. Pero si $v_j\in V_l$, como $f(v_j)=\lambda_lv_j$, entonces $a_{ij}=0$ si $i\ne j$ y $a_{jj}=\lambda_l$, y por ende $A$ es diagonal.\\
Finalmente, si $V=V_1\oplus\cdots\oplus V_r$ es una descomposición en espacios propios, entonces para $v=v_1+\cdots+v_r$ con $(v_1,\ldots,v_r)\in V_1\times\cdots\times V_r$, se tiene $f(v)=\lambda_1v_1+\cdots+\lambda_rv_r = \lambda_1p_1(v)+\cdots+\lambda_rp_r(v)$ y así $f=\lambda_1\id_{V_1}\oplus\cdots\oplus\lambda_r\id_{V_r}$ (ver definición \ref{sumadirectaoperadores}) y $f=\lambda_1p_1+\cdots+\lambda_rp_r$.\qed

\section{El teorema de Cayley-Hamilton}

El teorema de Cayley-Hamilton (teorema \ref{cayleyhamilton} abajo) nos permitirá generalizar la descomposición del teorema \ref{diagosiysolosi} con espacios estables más generales que los espacios propios. Esto se hace con el lema de los núcleos (proposición \ref{propdescomp} abajo).\\
Como en la sección anterior, $V$ denota un espacio sobre $\K$ y $f$ un operador de $V$.

\begin{obs}
Del mismo modo en que definimos una matriz sobre los escalares como una familia de escalares indexados por dos índices, podemos definir matrices sobre $\K[t]$. A este conjunto lo denotaremos $M_{m\times n}(\mathbb{K}[t])$. Los elementos en $\mathbb{K}[t]$ se pueden multiplicar y sumar entre si con operaciones basadas en las operaciones de multiplicaci\'on y suma en $\mathbb{K}$. Igualmente, podemos sumar y multiplicar matrices con entradas polinomiales cuando las dimensiones de las matrices lo permiten. Además, podemos también hablar del determinante y de la traza de matrices cuadradas con entradas en $\mathbb{K}[t]$, los cuales ser\'an polinomios en $\mathbb{K}[t]$. De hecho, toda matriz con entradas en $\mathbb{K}[t]$ puede ser vista como un caso especial de una matriz con entradas en el cuerpo $\K(t)$.
\end{obs}

\begin{obs}
Sea $n$ un entero positivo y $A$ una matriz en $M_{n\times n}(\mathbb{K})$. Dada cualquier $C\in M_{n\times n}(\mathbb{K})$, invertible, tenemos
\[
\det(t I_n-A)=\det\Big(C^{-1}(t I_n-A)C\Big)=\det(t I_n-C^{-1}AC)
\]
donde $t I_n-A$ y $t I_n-C^{-1}AC$ son matrices en $M_{n\times n}(\mathbb{K}[t])$. Esta observaci\'on nos permite formular la siguiente definici\'on.
\end{obs}

\begin{defn}
Suponga que $V$ tiene dimensi\'on finita $n$. Dado $f\in\End_\mathbb{K}(V)$, definimos el \emph{polinomio carater\'istico} de $f$ por
\[
P_f(t)=\det(t I_n-A)\in \mathbb{K}[t]
\]
donde $A=\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$ para cualquier base $\mathcal{B}$ de $V$. Similarmente, dada una matriz $A$ de tamaño $n\times n$, definimos su polinomio característico por
\[
P_A(t)=\det(t I_n-A)\in \mathbb{K}[t]
\]
\end{defn}

\begin{obs}
  Si $V$ tiene dimensión finita, entonces el grado del polinomio característico de $f$ coincide con la dimensión de $V$.
\end{obs}

\begin{teo}
Suponga que $V$ tiene dimensi\'on finita y sea $\lambda$ un escalar. Entonces, $\lambda$ es un valor propio de $f$ si y solo si $P_f(\lambda)=0$.
\end{teo}

\dem Sea $\mathcal{B}$ una base de $v$. El escalar $\lambda$ es un valor propio de $f$ si y solo si existe $v\in V$, con $v\ne 0$, tal que $f(v)=\lambda v$, o, equivalentemente, tal que $\left(\lambda\id_V-f\right)(v)=0$. Es decir $\lambda\in \mathbb{K}$ es un valor propio de $f$ si y solo si $\lambda\id_V-f$ no es inyectiva, lo que equivale a
\[
0=\det(\lambda\id_V-f)=\det\left(\lambda I_n-\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}\right)=P_f(\lambda).
\]
\qed

\begin{defn}
Dado $P(t)\in \mathbb{K}[t]$, definimos el operador $P(f)\in\End_\mathbb{K}(V)$ por
\[
P(f)=a_nf^n+a_{n-1}f^{n-1}+\cdots+a_1f+a_0\id_V
\]
si $P(t)=a_nt^n+a_{n-1}t^{n-1}+\cdots+a_1t+a_0$, donde
\[
f^k=\underbrace{f\circ\ldots\circ f}_{k-\textrm{veces}}
\]
para cualquier entero positivo $k$, y $f^0=\id_V$. Similarmente, para toda matriz $A\in M_{n\times n}(\K)$ se define la matriz $P(A)\in M_{n\times n}(\K)$ por
\[
P(A)=a_nA^n+a_{n-1}A^{n-1}+\cdots+a_1A+a_0I_n.
\]
Decimos que $P(t)$ es una polinomio anulador de $f$ (ó de $A$) si $P(f)=\underline{O}$ (ó $P(A)=O$).
\end{defn}

\begin{obs}
  Si $V$ tiene dimensión finita, para toda base $\B$ de $V$ y todo $P(t)\in\K[t]$ se tiene
  $$\left[P(f)\right]_{\B}^{\B}=P\left([f]_\B^\B\right)$$.
\end{obs}

\begin{obs}\label{observacionesparacayleyhamilton}
  \begin{enumerate}[(i)]
  \item Dados $P_1(t),P_2(t)\in \mathbb{K}[t]$, si $P(t)=P_1(t)P_2(t)$, entonces $P(f)=P_1(f)\circ P_2(f)=P_2(f)\circ P_1(f)$, pues para los monomios $at^m$ y $bt^nS$ se tiene $\left(af^m\right)\circ\left( bf^n\right)=abf^{m+n}=\left( bf^n\right)\circ \left(af^m\right)$ y de esto se sigue la igualdad para polinomios más generales.
  \item El polinomio característico de la matriz compañera (ver observación \ref{festablecompa})
  $$
  A=\left[\begin{array}{ccccc}
    0 & 0 & \cdots & 0 & a_0\\
    1 & 0 & \cdots & 0 & a_1\\
    0 & 1 & \cdots & 0 & a_2\\
    \vdots & \vdots & \ddots & \vdots & \vdots\\
    0 & 0 & \cdots & 1 & a_{r-1}
  \end{array}\right]
  $$
  es $P_A(t)=t^r-a_{r-1}t^{r-1}-\cdots-a_1t-a_0$.
\end{enumerate}
\end{obs}

\begin{teo}[Cayley-Hamilton]\label{cayleyhamilton}
  Si $V$ tiene dimensi\'on finita, entonces $P_f(f)=\underline{O}$.
\end{teo}

\dem Sea $v\in V$ no nulo. Como en la observación \ref{festablecompa}, existe un entero $r$ maximal tal que $\{v,f(v),\ldots,f^{r-1}(v)\}$ es linealmente independiente, y escalares $a_0,\ldots,a_{r-1}$ tales que
$$f^r(v)=a_{r-1}f^{r-1}(v)+\cdots+a_{1}f(v)+a_0v.$$
El subespacio $V_0=\langle v,f(v),\ldots,f^{r-1}(v)\rangle$ es $f$-estable y si $\B$ es una base de $V$ que extiende la base $\B_0=(v,f(v),\ldots,f^{r-1}(v))$ de $V_0$, entonces la matrix de $f$ para $\B$ es de la forma
$$
  \left[f\right]_\B^\B=\left[\begin{array}{c|c}
    A & B\\
    \hline
    O & C
  \end{array}\right]
$$
donde $A$ es una matriz compañera. Ahora, $P_f(t)=P_A(t)P_C(t)$, así, por las observaciones \ref{observacionesparacayleyhamilton} (i) y (ii),
\begin{align*}
  P_f(f)(v) = & P_A(f)\circ P_C(f)(v)\\
   = & P_C(f)\circ P_A(f)(v)\\
   = & P_C(f)(f^r-a_{r-1}f^{r-1}-\cdots-a_1f-a_0\id_V)(v)\\
   = & P_C(f)(f^r(v)-a_{r-1}f^{r-1}(v)-\cdots-a_{1}f(v)+a_0v)\\
   = & P_C(f)(O)=O.
\end{align*}
Por ende, para todo $v\in V$, se tiene $P_f(f)(v)=\underline{O}$, es decir que $P_f(f)=\underline{O}$.\qed

\begin{obs}[Otra demostración del teorema de Cayley-Hamilton]
  Antes de mostrar la otra demostración arrancamos con una serie de observaciones.
  \begin{enumerate}[(i)]
    \item Dada una matriz $C=\left(c_{ij}(t)\right)$ en $M_{m\times n}(\mathbb{K}[t])$ definimos la transformaci\'on lineal
      \begin{eqnarray*}
        C_f:\underbrace{V\times\cdots\times V}_{n-\textrm{veces}} &\longrightarrow & \underbrace{V\times\cdots\times V}_{m-\textrm{veces}}
      \end{eqnarray*}
      por
      \[
        C_f(v_1,\ldots,v_n)=\left(\sum_{j=1}^nc_{1j}(f)(v_j),\ldots,\sum_{j=1}^nc_{mj}(f)(v_j)\right).
      \]
  \item Note que si nos son dadas $C_1\in M_{m\times n}(\mathbb{K}[t])$ y $C_2\in M_{l\times m}(\mathbb{K}[t])$, entonces 
      \[
        \left(C_1C_2\right)_f=C_{1 f}\circ C_{2 f}. 
      \]
  \item Dada $B=\left(b_{ij}(t)\right)$ en $M_{n\times n}(\mathbb{K}[t])$, denotamos por $\tilde{B}$ su matriz de cofactores, es decir la matriz $n\times n$ con entradas en $\mathbb{K}[t]$ cuya $ij$-\'esima entrada es
      \[
         \tilde{b}_{ij}(t)=(-1)^{i+j}\det(B_{ij})
      \]
    donde $B_{ij}$ es la matriz $(n-1)\times(n-1)$ que se obtiene a partir de $B$ eliminando la $i$-\'esima fila y la $j$-\'esima columna. De tal forma que
      \[
        B\tilde{B}^\intercal=\left[\begin{array}{cccc}
          \det(B) & 0 & \cdots & 0\\
          0 & \det(B) & \cdots & 0\\
          \vdots & \vdots & \ddots &\vdots\\
          0 & 0 &\cdots & \det(B)
          \end{array}\right]=(B\tilde{B}^\intercal)^\intercal=\tilde{B}B^\intercal
      \]
    donde $\tilde{B}^\intercal$ denota la transpuesta de $\tilde{B}$, es decir la matriz $n\times n$ cuya $ij$-\'esima entrada es la entrada $ji$-\'esima de $\tilde{B}$.
  \end{enumerate}
  Para hacer la demostración, consideramos una base $\mathcal{B}=(v_1,\ldots,v_n)$ de $V$ y la matriz $A=(a_{ij})$ de $f$ para $\B$, de forma que $$f(v_j)=a_{1j}v_1+\cdots+a_{nj}v_n=\sum_{i=1}^na_{ij}v_i.$$
Tomamos la matriz $B=tI_n-A$ de $M_{n\times n}(\mathbb{K}[t])$. Entonces $\tilde{B}B^\intercal=P_f(t)I_n$. Ahora, por un lado se tiene
\begin{eqnarray*}
\left(B^\intercal\right)_f(v_1,\ldots, v_n)& = & \left(f(v_1)-\left(\sum_{j=1}^na_{j1}v_j\right),\ldots, f(v_n)-\left(\sum_{j=1}^na_{jn}v_j\right)\right)\\
   & = & \left(0,\ldots, 0\right);
\end{eqnarray*}
y, por otro,
\begin{eqnarray*}
\left(P_f(f)(v_1),\ldots, P_f(f)(v_n)\right) & = & \left(P_f(t)I_n\right)_f(v_1,\ldots,v_n)\\
    & = & \left( \tilde{B}B^T \right)_f (v_1,\ldots, v_n)\\
    & = & \tilde{B}_f\circ\left(B^\intercal\right)_f(v_1,\ldots,v_n)\\
    & = & \tilde{B}_f(0,\ldots, 0)\\
    & = & (0,\ldots, 0).
\end{eqnarray*}
Luego $\mathcal{B}\subseteq \ker\left(P_f(f)\right)$ y as\'i, por el teorema \ref{unitrlin} de rigidez de las transformaciones lineales se sigue $P_f(f)=\underline{O}$.
\end{obs}

\section{Descomposición en espacios estables}

Sea $V$ un espacio vectorial sobre $\K$ y $f$ un operador de $V$.

\begin{prop}
Para todo $P(t)\in \mathbb{K}[t]$, el subespacio $V_0=\ker\left(P(f)\right)$ es estable bajo $f$.
\end{prop}

\dem Sea $v\in V_0$. Por la observación \ref{observacionesparacayleyhamilton}(i), se tiene
$$P(f)\left(f(v)\right)=P(f)\circ f(v)=f\circ P(f)(v)=f(O)=O.$$
Es decir que $f(v)\in\ker\left(P(f)\right)=V_0$.\qed

\begin{prop}
Suponga que $P(t)\in \mathbb{K}[t]$ es tal que
\begin{enumerate}[(i)]
  \item $P(f)=0$,
  \item $P(t)=P_1(t)P_2(t)$ con $\left(P_1(t),P_2(t)\right)=1$ y $P_1(t),P_2(t)\in\K[t]$.
\end{enumerate}
Entonces $V=V_1\oplus V_2$ y $f=f_{V_1}\oplus f_{V_2}$, donde $V_1=\ker\left(P_1(f)\right)$ y $V_2=\ker\left(P_2(f)\right)$. M\'as a\'un, existen polinomios $\Pi_1(t),\Pi_2(t)\in \mathbb{K}[t]$, tales que $p_1=\Pi_1(f)$ y $p_2=\Pi_2(f)$ son las proyecciones en $V_1$ y $V_2$ relativas a la descomposición $V=V_1\oplus V_2$ (ver la observación \ref{sumayproyeccion}).
\end{prop}

\dem Como $\left(P_1(t),P_2(t)\right)=1$, entonces existen $Q_1,Q_2\in \mathbb{K}[t]$ tales que $Q_1(t)P_1(t)+P_2(t)Q_2(t)=1$, luego
\[
Q_1(f)\circ P_1(f)+P_2(f)\circ Q_2(f)=\id_V,
\]
y en particular, para todo $v\in V$ se tiene
\[
\begin{array}{rcccc}
v & = & \underbrace{Q_1(f)\circ P_1(f)(v)} & + & \underbrace{P_2(f)\circ Q_2(f)(v)}\\
  & = & v_2 & + & v_1.
\end{array}
\]
Ahora
\[
P_2(f)(v_2)=P_2(f)\circ Q_1(f)\circ P_1(f)(v)=Q_1(f)\circ P_1(f)\circ P_2(f) (v)=Q_1(f)\circ P(f)(v)=0
\]
y
\[
P_1(f)(v_1)=P_1(f)\circ Q_2(f)\circ P_2(f)(v)=Q_2(f)\circ P_1(f)\circ P_2(f) (v)=Q_2(f)\circ P(f)(v)=0
\]
luego $v_2\in V_2$ y $v_1\in V_1$. As\'i $V=V_1+V_2$. Pero, si asumimos que $v\in V_1\cap V_2$, es decir que $P_1(f)(v)=O=P_2(f)(v)$, entonces en la descomposición $v=v_2+v1$, se tiene $v_2=O=v_1$, luego $v=O$. Por ende, $V_1\cap V_2=\{O\}$ y $V=V_1\oplus V_2$. Por la proposición anterior $V_1$ y $V_2$ son $f$-estables luego $f=f_{V_1}\oplus f_{V_2}$.\\
Finalmente, si $\Pi_1(t)=Q_2(t)P_2(t)$ y $\Pi_2(t)=Q_1(t)P_1(t)$, tenemos $\Pi_2(t)+\Pi_1(t)=1$ y así
$\Pi_2(f)+\Pi_1(f)=\id_V$, es decir $p_1+p_2=\id_V$, para $p_1=\Pi_1(f)$ y $p_2=\Pi_2(f)$. Ahora, como
\[
\Pi_1(t)\Pi_2(t)=Q_2(t)P_2(t)Q_1(t)P_1(t)=Q_2(t)Q_1(t)P(t)
\]
entonces $\Pi_1(f)\circ\Pi_2(f)=0$, es decir $p_1\circ p_2=\underline{O}$, y como
\[
\Pi_2(t)=\Pi_2(t)\left(\Pi_2(t)+\Pi_1(t)\right)=\left(\Pi_2(t)\right)^2+\Pi_2(t)\Pi_1(t)
\]
entonces $\Pi_2(f)=\left(\Pi_2(f)\right)^2$, es decir $p_2^2=p_2$. Similarmente, $p_1^2=p_1$. Por el teorema \ref{proysumadir}, basta ver que $\im(p_1)=V_1$ y $\im(p_2)=V_2$. Pero, si $v_1\in V_1=\ker(P_1(f))$ entonces $v_1=p_1(v_1)+p_2(v_1)=p_1(v_1)+Q_1(f)\circ P_1(f)(v_1)=p_1(v_1)$, luego $v_1\in\im(p_1)$; y si $v_1\in\im(p_1)$ entonces para algún $v\in V$ tenemos $v_1=p_1(v)$, así $P_1(f)(v_1)=P_1(f)\circ p_1(v)=P_1(f)\circ Q_2(f)\circ P_2(f)=Q_2(f)\circ P(f)(v)=O$, luego $v_1\in\ker(P_1(f))$. Similarmente se establece $\im(p_2)=V_2$.\qed

\begin{ejem}
Sea $p\in\End_\mathbb{K}(V)$ una proyecci\'on, es decir que $p^2=p$. Luego, si $P(t)=t^2-t$ entonces $P(p)=p^2-p=\underline{O}$ y $P(t)=P_1(t)P_2(t)$ con $P_1(t)=t-1$ y $P_2(t)=t$. Note que $\left(P_1(t),P_2(t)\right)=1$ y $$-P_1(t)+P_2(t)=1.$$
As\'i, por la demostraci\'on de la propiedad anterior obtenemos que, para
\begin{align*}
V_1 & =\ker\left(P_1(p)\right)=\ker\left(p-\id_V\right)\\
V_2 & =\ker\left(P_2(p)\right)=\ker\left(p\right),
\end{align*}
$V=V_1\oplus V_2$ y si
\begin{align*}
\Pi_1(t) & =P_2(t)=t\\
\Pi_2(t) & =-P_1(t)=1-t,
\end{align*}
entonces $p_1=\Pi_2(p)=p$ y $p_2=\Pi_1(p)=\id_V-p$ son proyecciones sobre $V_1$ y $V_2$ tales que $p_1+p_2=\id_V$.
\end{ejem}

\begin{ejem}
Suponga que $\chara(\mathbb{K})\ne 2$, de forma que $-1\ne 1$ y sea $f\in\End_\mathbb{K}\left(\mathbb{K}^2\right)$ el operador
$$f(x,y)=(y,x).$$
La matriz canónica de $f$ es
$$\left[ f\right]^{\mathcal{C}}_{\mathcal{C}}=
\left[\begin{array}{rr}
0 & 1\\ 1 & 0
\end{array}\right]$$
y así su polinomio característico es $P_f(t)=t^2-1$. Note que $P_f(t)=P_1(t)P_2(t)$ con $P_1(t)=t-1$ y $P_2(t)=t+1$. Por el teorema de Cayley-Hamilton se tiene $P_f(f)=0$, y por la proposición, $\mathbb{K}^2=V_1\oplus V_2$ donde $V_1=\ker\left(f-\id_{\mathbb{K}^2}\right)$ y $V_2=\ker\left(f+\id_{\mathbb{K}^2}\right)$. Como
$$-\frac{1}{2}P_1(t)+\frac{1}{2}P_2(t)=1$$
entonces
$$p_1=\frac{1}{2}\left(f+\id_{\mathbb{K}^2}\right)\quad\textrm{ y }\quad p_2=-\frac{1}{2}\left(f-\id_{\mathbb{K}^2}\right)$$
son las proyecciones sobre $V_1$ y $V_2$. Expl\'icitamente:
$$p_1(x,y)=\frac{1}{2}(x+y,x+y)\quad\textrm{ y }\quad p_2(x,y)=\frac{1}{2}(x-y,y-x).$$
\end{ejem}

\begin{obs}
Bajo las hipótesis de la proposición, para $i\{1,2\}$, tenemos $P_i(f_{V_i})=\underline{O}$, pues $V_i=\ker\left(P_i(f)\right)$. As\'i, podemos a su vez aplicar el resultado a $f_{V_i}$ dada un factorización de $P_i(t)$ en factores primos relativos. Inductivamente, obtenemos el siguiente resultado. 
\end{obs}

\begin{prop}[Lema de los núcleos]\label{propdescomp}
  Suponga que $P(t)\in \mathbb{K}[t]$ es tal que
  \begin{enumerate}[(i)]
    \item $P(f)=0$,
    \item $P(t)=P_1(t)\cdots P_r(t)$ con $P_1(t),\ldots,P_r(t)\in\K[t]$ y $\left(P_i(t),P_j(t)\right)=1$ si $i\ne j$.
  \end{enumerate}
  Entonces $V=V_1\oplus\cdots\oplus V_r$ y $f=f_{V_1}\oplus\cdots\oplus f_{V_r}$, donde $V_i=\ker\left(P_i(f)\right)$ para $i\in\{1,\ldots,r\}$. M\'as a\'un, existen polinomios $\Pi_1(t),\ldots,\Pi_r(t)\in \mathbb{K}[t]$, tales que $p_i=\Pi_i(f)$ es la proyección sobre $V_i$ relativa a la descomposición $V=V_1\oplus\cdots,\oplus V_r$ (ver la observación \ref{sumayproyeccion}).
\end{prop}

\dem Aunque la demostración se sigue por inducción de la proposición anterior, se puede hacer directamente de forma similar de la siguiente forma. Para $i=1,\ldots,r$ tomamos $R_i(t)=\prod_{j\ne i}P_j(t)$, y de esta forma se obtiene $(R_1(t),\ldots,R_r(t))=1$. Así que existen $Q_1(t),\ldots, Q_n(t)\in \mathbb{K}[t]$ para los cuales $Q_1(t)R_1(t)+\cdots Q_n(t)R_n(t)=1$. Si para $i\in\{1,\ldots,r\}$ definimos $\Pi_i(t)=Q_i(t)R_i(t)$ y $p_i=\Pi_i(f)$, entonces tenemos $p_1+\cdots+p_r=\id_V$,
$p_i\circ p_j=\underline{O}$ cuando $i\ne j$, y $p_i^2=p_i$. El resultado se sigue del teorema \ref{proysumadir} si demostramos que $\im(p_i)=V_i$. Para ello, dado $v_i\in V_i=\ker(P_i(f))$ se tiene
$$v_i=p_1(v_i)+\cdots+p_r(v_i)=p_i(v_i)+\sum_{j\ne i} Q_j(f)\circ R_j(f)(v_i),$$
pero $P_i(t)$ es factor de los $R_j(t)$, así $R_j(f)(v_i)=O$, luego $v_i=p_i(v_i)$ y $v_i\in\im(p_i)$. Recíprocamente, dado $v_i\in\im(p_i)$, tenemos $v_i=p_i(v)$ para algún $v\in V$, entonces 
$$P_i(f)(v_i)=P_i(f)\circ Q_i(f)\circ R_i(f)(v)=Q_i(f)\circ P(f)(v)=O$$
y así $v_i\in\ker(P_i(f))$.\qed

\begin{ejem}
Sea $f\in\End_{\mathbb{Q}}(\mathbb{Q}^4)$ el operador
$$f(x,y,z,w)=(x-y+w,-x-z+2w,2x-y-z-w,2x-y)$$
La matriz canónica de $f$ es
$$\Big[f\Big]_\mathcal{C}^\mathcal{C}=\left[\begin{array}{rrrr}
1 & -1 & 0 & 1\\
-1 & 0 & -1 & 2\\
2 & -1 & -1 & -1\\
2 & -1 & 0 & 0
\end{array}\right]$$
y así $P_f(t)=P_1(t)P_2(t)P_3(t)$ donde $P_1(t)=(t+1)$, $P_2(t)=(t-1)$ y $P_3(t)=(t^2-2)$. Luego, de la proposición anterior y el teorema de Cayley-Hamilton, si para $i=1,2,3$ definimos $V_i=\ker(P_i(f))$, cada uno de estos espacios es estable bajo $f$ y obtenemos la descomposici\'on:
$$\mathbb{Q}^4=V_1\oplus V_2\oplus V_3.$$
Si usamos la misma notaci\'on de la demostraci\'on, tenemos $R_1(t)=P_2(t)P3(t)=(t-1)(t^2-2)$, $R_2(t)=P_1(t)P_3(t)=(t+1)(t^2-2)$, $R_3=(t-1)(t+1)$, y como
$$\dfrac{1}{2}R_1(t)-\dfrac{1}{2}R_2(t)+R_3(t)=1,$$
para
\begin{align*}
\Pi_1(t) & =\dfrac{1}{2}R_1(t)=\dfrac{(t-1)(t^2-2)}{2},\\
\Pi_2(t) & =-\dfrac{1}{2}R_2(t)=-\dfrac{(t+1)(t^2-2)}{2},\textrm{ y }\\
\Pi_3(t) & =R_3(t)=(t-1)(t+1),
\end{align*}
los operadores $p_i=\Pi_i(f)$, para $i=1,2,3$, son las respectivas proyecciones sobre $V_i$ de acuerdo a nuestra descomposici\'on de $\mathbb{Q}^4$. Las representaciones matriciales en la base can\'onica de estas proyecciones son:
$$\Big[ p_1\Big]_\mathcal{C}^\mathcal{C}=\left[\begin{array}{rrrr}
1 & 0 & 0 & -1\\
2 & 0 & 0 & -2\\
1 & 0 & 0 & -1\\
0 & 0 & 0 & 0
\end{array}\right]$$
$$\Big[ p_2\Big]_\mathcal{C}^\mathcal{C}=\left[\begin{array}{rrrr}
-3 & 2 & -1 & 2\\
-3 & 2 & -1 & 2\\
0 & 0 & 0 & 0\\
-3 & 2 & -1 & 2
\end{array}\right] $$
$$\Big[ p_3\Big]_\mathcal{C}^\mathcal{C}=\left[\begin{array}{rrrr}
3 & -2 & 1 & -1\\
1 & -1 & 1 & 0\\
-1 & 0 & 1 & 1\\
3 & -2 & 1 & -1
\end{array}\right] $$
as\'i pues $V_1=\im(p_1)=\langle (1,2,1,0)\rangle$, $V_2=\im(p_2)=\langle (1,1,0,1)\rangle$ y $V_3=\im(p_3)=\langle (1,1,1,1),(1,0,-1,1)\rangle$. Para $\mathcal{B}=\left((1,2,1,0),(1,1,0,1),(1,1,1,1),(1,0,-1,1)\right)$, la matriz de $f$ es
$$\Big[ f\Big]_\mathcal{B}^\mathcal{B}=\left[\begin{array}{r|r|rr}
-1 & 0 & 0 & 0\\
\hline
0 & 1 & 0 & 0\\
\hline
0 & 0 & 0 & 2\\
0 & 0 & 1 & 0
\end{array}\right]$$
la cual es una matriz diagonal por bloques, donde cada bloque describe la restricci\'on de $f$ a cada uno de los subespacios estables de la descomposici\'on. 
\end{ejem}

\begin{teo}
  Si $V$ tiene dimensión finita y $$P_f(t)=P_1(t)^{m_1}\cdots P_r(t)^{m_r}$$ es una factorización del polinomio característico donde los $P_i(t)$ son polinomios irreducibles dos a dos distintos, entonces el operador $f$ se descompone como $$f=f_{V_1}\oplus\cdots\oplus f_{V_r}$$ donde, para $i\in\{1,\ldots,r\}$, los espacios $f$-estables $V_i=\ker\left(P_i(f)^{m_i}\right)$ son tales que $\dim(V_i)=\deg\left(P_i(t)^{m_i}\right)$ y el polinomio característico de las restricciones $f_{V_i}$ es $P_{f_{V_i}}=P_i(f)^{m_i}$. Además, si $\B_i$ es una base de $V_i$ entonces la concatenación $\B=(\B_1|\cdots|\B_r)$ es una base de $V$ para la cual la matriz de $f$ es la matriz diagonal por bloques
  \[
    \Big[f\Big]^\mathcal{B}_\mathcal{B}=\left[\begin{array}{c|c|c}
      A_1 & \cdots & 0\\
      \hline
      \vdots & \ddots & \vdots\\
      \hline
      0 & \cdots & A_r
      \end{array}\right] 
  \]
  donde cada bloque $A_i$ es la matriz de $f_{V_i}$ para $\B_i$. 
\end{teo}

\dem Del teorema \ref{cayleyhamilton} de Cayley-Hamilton y la proposición \ref{propdescomp} se sigue la descomposición $f=f_{V_1}\oplus\cdots\oplus f_{V_r}$ donde, para $i\in\{1,\ldots,r\}$, los espacios $V_i=\ker\left(P_i(f)^{m_i}\right)$ son $f$-estables. Por ello, si $\B_i$ es una base de $V_i$ entonces la concatenación $\B=(\B_1|\cdots|\B_r)$ es una base de $V$ para la cual la matriz de $f$ es una matriz diagonal por bloques donde cada bloque $A_i$ es la matriz de $f_{V_i}$ para $\B_i$. Falta ver que $\dim(V_i)=\deg\left(P_i(t)^{m_i}\right)$ y el polinomio característico de las restricciones $f_{V_i}$ es $P_{f_{V_i}}=P_i(f)^{m_i}$. De hecho, si $n_i=\dim(V_i)$, al calcular el polinomio característico $P_f(t)$ con la matriz de $f$ para $\B$ obtenemos
$$P_f(t)=\det(tI_{n_1}-A_1)\cdots\det(tI_{n_r}-A_r)=P_{f_{V_1}}(t)\cdots P_{f_{V_r}}(t).$$
Luego $P_1(t)^{m_1}\cdots P_r(t)^{m_r}=P_{f_{V_1}}(t)\cdots P_{f_{V_r}}(t)$. Suponga por contradicción que $P_j(t)$ divide a $P_{f_{V_1}}(t)$
\qed 

\section{Operadores nilpotentes, espacios c\'iclicos y forma de Jordan}

Sea $f\in\End_\mathbb{K}(V)$ un operador.

\begin{obs}
Note que si $V$ tiene dimensi\'on finita y tomamos $f\in\End_\mathbb{K}(V)$, $P_f(f)=0$. Ahora suponga que $P_f(t)$ se descompone en factores lineales
\[
P_f(t)=(t-\lambda_1)^{m_1}(t-\lambda_2)^{m_2}\ldots(t-\lambda_n)^{m_n}, \quad \lambda_1,\lambda_2,\ldots,\lambda_n\in \mathbb{K}.
\]
con $\lambda_i\ne\lambda_j$ si $i\ne j$. De esta forma, si $V_i=\ker\left((f-\lambda_i\id_V)^{m_i}\right)$, para $i=1,\ldots,n$,
\[
V=V_1\oplus V_2\oplus\cdots\oplus V_n
\]
y si adem\'as denotamos $g_i\in\Hom_K(V_i,V_i)$ a la restricci\'on de $f-\lambda_i\id_V$ a $V_i$, tenemos $g_i^{m_i}=0$. Este tipo de operadores, cuya potencia se anula, motivan la siguiente definici\'on.
\end{obs}

\begin{defn}
Decimos que $f$ es nilpotente si existe $r\in\mathbb{Z}_{>0}$ tal que $f^r=0$, y al m\'inimo entre estos lo llamamos el grado de $f$.
\end{defn}

\begin{pro}
Suponga que $f$ es nilpotente de grado $r$, y $V\ne\{0\}$, entonces tenemos una cadena de contenencias estrictas
\[
\{0\}<\ker(f)<\ker(f^2)<\ldots<\ker(f^r)=V.
\]
En particular si $V$ tiene dimensi\'on finita, $r\le\dim(V)$.
\end{pro}

\dem Note primero que para todo $i\in\mathbb{Z}_{>0}$, si $v\in V$ es tal que $f^i(v)=0$, entonces $f^{i+1}(v)=0$, luego $\ker(f^i)\le\ker(f^{i+1})$.\\
Si $r=1$, no hay nada que demostrar pues $f=0$ y as\'i la cadena corresponde a $\{0\}<V$. Ahora suponga que $r>1$, luego $f^{r-1}\ne 0$ y as\'i existe $v\in V$ tal que $f^{r-1}(v)\ne 0$. Note que para $i=1,\ldots,r-1$
\begin{align*}
f^{i-1}\left(f^{r-i}(v)\right) & =f^{r-1}(v)\ne 0,\textrm{ y }\\
  f^i\left(f^{r-i}(v)\right) & =f^r(v)=0
\end{align*}
as\'i $f^{r-i}(v)\in \ker(f^i)\setminus \ker(f^{i-1})$ y tenemos una contenencia estricta $\ker(f^{i-1})<\ker(f^i)$.\\
Suponga ahora que $V$ tiene dimensi\'on finita y denote, para $i=1,\ldots,r$, $n_i=\dim(\ker(f^i))$. Entonces
\[
0<n_1<n_2<\ldots<n_r=\dim(V)
\]
es una cadena de $r+1$ enteros estrictamente creciente que arranca en $0$, luego $1\le n_1$, $2\le n_2$, $\ldots$, $r\le n_r=\dim(V)$.\qed

\begin{ejem}\label{ejnil1}
Sea $f\in\Hom_K(K^4,K^4)$ definido por
$$f(x,y,z,w)=(y,z,w,0).$$
As\'i
\begin{align*}
f^2(x,y,z,w) & = (z,w,0,0),\\
f^3(x,y,z,w) & = (w,0,0,0),\\
f^4(x,y,z,w) & = (0,0,0,0)
\end{align*}
y si $n_i=\dim(\ker(f^i))$ entonces
$$n_1=1,\quad n_2=2,\quad n_3=3,\quad n_4=4.$$
La representaci\'on matricial de $f$ en la base can\'onica $\mathcal{C}$ es
$$
\left[f\right]^{\mathcal{C}}_{\mathcal{C}}=\left[\begin{array}{rrrr}
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 0
\end{array}\right]
$$
y el polinomio caracter\'istico es $P_f(t)=t^4$.
\end{ejem}

\begin{ejem}\label{ejnil2}
Sea $f\in\Hom_K(K^4,K^4)$ definido por
$$f(x,y,z,w)=(y,z,0,0).$$
As\'i
\begin{align*}
f^2(x,y,z,w) & = (z,0,0,0),\\
f^3(x,y,z,w) & = (0,0,0,0)
\end{align*}
y si $n_i=\dim(\ker(f^i))$ entonces
$$n_1=2,\quad n_2=3,\quad n_3=4.$$
La representaci\'on matricial de $f$ en la base can\'onica $\mathcal{C}$ es
$$
\left[f\right]^{\mathcal{C}}_{\mathcal{C}}\left[\begin{array}{rrr|r}
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 0\\
\hline
0 & 0 & 0 & 0
\end{array}\right]
$$
y el polinomio caracter\'istico es $P_f(t)=t^4$.
\end{ejem}

\begin{ejem}\label{ejnil3}
Sea $f\in\Hom_K(K^4,K^4)$ definido por
$$f(x,y,z,w)=(y,0,w,0).$$
As\'i
\begin{align*}
f^2(x,y,z,w) & = (0,0,0,0)
\end{align*}
y si $n_i=\dim(\ker(f^i))$ entonces
$$n_1=2,\quad n_2=4$$
La representaci\'on matricial de $f$ en la base can\'onica $\mathcal{C}$ es
$$
\left[f\right]^{\mathcal{C}}_{\mathcal{C}}\left[\begin{array}{rr|rr}
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
\hline
0 & 0 & 0 & 1\\
0 & 0 & 0 & 0
\end{array}\right]
$$
y el polinomio caracter\'istico es $P_f(t)=t^4$.
\end{ejem}

\begin{ejem}\label{ejnil4}
Sea $f\in\Hom_K(K^4,K^4)$ definido por
$$f(x,y,z,w)=(y,0,0,0).$$
As\'i
\begin{align*}
f^2(x,y,z,w) & = (0,0,0,0)
\end{align*}
y si $n_i=\dim(\ker(f^i))$ entonces
$$n_1=3,\quad n_2=4$$
La representaci\'on matricial de $f$ en la base can\'onica $\mathcal{C}$ es
$$
\left[f\right]^{\mathcal{C}}_{\mathcal{C}}\left[\begin{array}{rr|r|r}
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
\hline
0 & 0 & 0 & 0\\
\hline
0 & 0 & 0 & 0
\end{array}\right]
$$
y el polinomio caracter\'istico es $P_f(t)=t^4$.
\end{ejem}

\begin{defn}
Sea $v\in V$, si existe $k\in\mathbb{Z}_{>0}$ tal que $f^k(v)=0$, al m\'inimo entre estos los llamamos el orden de $v$ bajo $f$ y lo denotamos por $\ord_f(v)$.
\end{defn}

\begin{pro}
Sea $v\in V$, $v\ne 0$, y suponga que $k=\ord_f(v)$, entonces $S=\{v,f(v),\ldots,f^{k-1}(v)\}$ es linealmente independiente.
\end{pro}

\dem Suponga que $a_0,a_1,\ldots,a_{k-1}\in K$ son tales que
\[
a_0v+a_1f(v)+\cdots+a_{k-1}f^{{k-1}}(v)=0.
\]
Aplicando $f^{k-1}$ a esta igualdad obtenemos $a_0f^{k-1}(v)=0$, pero $f^{k-1}(v)\ne 0$ luego $a_0=0$. Inductivamente, si hemos establecido que $a_0=a_1=\ldots=a_{i-1}=0$ para $0<i<k-1$, aplicando $f^{k-i-1}$ a la misma igualdad, obtenemos $a_if^{k-1}(v)=0$, luego $a_i=0$. As\'i $a_0=a_1=\ldots=a_{k-1}=0$.\qed

\begin{obs}\label{obsformajordannil}
Suponga que $V$ tiene dimensi\'on finita y $f$ es nilpotente de grado $r=\dim(V)$. Si $v\in V$ es tal que $v\not\in\ker(f^{r-1})$ entonces $\ord_f(v)=r$, luego si $v_i=f^{r-i}(v)$ para $i=1,\ldots,r$, por la propiedad anterior
\[
\mathcal{B}=\{v_1,\ldots,v_r\}=\{f^{r-1}(v),\ldots,f(v),v\}
\]
es una base de $V$; m\'as a\'un
\[
\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}=\left[\begin{array}{ccccc}
0 & 1 & 0 &\cdots & 0\\
0 & 0 & 1 &\cdots & 0\\
\vdots & \vdots & \vdots &\ddots & \vdots\\
0 & 0 & 0 & \cdots & 1\\
0 & 0 & 0 & \cdots & 0
\end{array}\right].
\]
\end{obs}

\begin{defn}
Decimos que $V$ es c\'iclico bajo $f$ si
\[
S=\left\{f^i(v)\right\}_{i\in\mathbb{Z}_{>0}}
\]
genera a $V$, es decir $\langle S\rangle=V$, para alg\'un $v\in V$ . En tal caso decimos que $v$ es un \emph{vector c\'iclico} relativo a $f$.
\end{defn}

\begin{obs}
Si $V$ tiene dimensi\'on finita y $f\ne 0$ es nilpotente de grado $r=\dim(V)$, la observaci\'on anterior explica que $V$ es c\'iclico bajo $f$. 
\end{obs}

\begin{defn}
Suponga que $V$ tiene dimensi\'on finita y $f\ne 0$ es nilpotente de grado $r=\dim(V)$, una base de la forma
\[
\mathcal{B}=\{v_1,\ldots,v_r\},\qquad v_i=f^{r-i}(v_r)
\]
se llama una \emph{base de Jordan de $V$ relativa a $f$}.  
\end{defn}

\begin{obs}
En caso de que $f$ sea nilpotente de grado inferior, $V$ no es c\'iclico, pero se puede descomponer en subespacios invariantes bajo $f$ y c\'iclicos bajo la restricci\'on de $f$ a ellos. Esto es el contenido del siguiente teorema.
\end{obs}

\begin{teo}\label{formajordannil}
Suponga que $V$ tiene dimensi\'on finita y que $f\ne 0$ es nilpotente de grado $r$. Sea $n=\dim\left(\ker(f)\right)$. Entonces existen $n$ subespacios invariantes bajo $f$, $V_1,\ldots, V_n$ tales que  
\[
V=V_1\oplus\cdots\oplus V_n
\]
y si $f_i\in\Hom_K(V_i,V_i)$ es la restricci\'on de $f$ a $V_i$, para $i=1,\ldots,n$, entonces $V_i$ c\'iclico bajo $f_i$.
\end{teo}

\dem
Denotemos $K_i=\ker(f^i)$, de forma que $K_0=\{0\}$ y $K_r=V$. Note que para $i=1,\ldots,r-1$, $K_i<K_{i+1}$. Podemos as\'i descomponer para cada $i=2,\ldots r$
\[
K_i=K_{i-1}\oplus K'_i.
\]
De forma que si $v\in K'_i$, $v\ne 0$, entonces $\ord_f(v)=i$. Por lo tanto
\[
f\left(K'_i\right)\le K'_{i-1}.
\]
Tenemos entonces
\begin{eqnarray*}
V & = & K_r\\
   & = & K_{r-1}\oplus K'_r\\
   & \vdots &\\
   & = & K_1\oplus K'_2\oplus\cdots\oplus K'_r
\end{eqnarray*}
y
\[
K'_r\overset{f}\longrightarrow K'_{r-1}\overset{f}\longrightarrow\ldots\overset{f}\longrightarrow K'_2\overset{f}\longrightarrow K_1\overset{f}\longrightarrow \{0\}
\]
Se trata entonces de escoger una base de $V$ que sea compatible con esta descomposici\'on y esta cadena de im\'agenes bajo $f$. Denote $n_i=\dim(K_i)$ y $n'_i=\dim(K'_i)$, para $i=2,\ldots,r$, y $n_1=n=\dim(K_1)$ de forma que
$$n_i=n'_i+n_{i-1}$$
y
\begin{align*}
\dim(V)& =n_r\\
 & =n'_r+n_{r-1}\\
 & \vdots\\
 & =n'_r+n'_{r-1}+\cdots+n_2\\
 & =n'_r+n'_{r-1}+\cdots+n'_2+n_1\\
 & =n'_r+n'_{r-1}+\cdots+n'_2+n
\end{align*}
Sea $\mathcal{B}_r=\{v_{r,1},\ldots,v_{r,n'_r}\}\subseteq V$ una base de $K'_r$. Para $i=1,\ldots n'_r$, sea $$v_{r-1,i}=f(v_{r,i}).$$ Note que $f(\mathcal{B}_r)=\{v_{r-1,1},\ldots,v_{r-1,n'_r}\}\subseteq K'_{r-1}$ es linealmente independiente. De hecho si
\[
a_1v_{r-1,1}+\cdots+a_{n'_r}v_{r-1,n'_r}=0,
\]
entonces
\[
a_1f(v_{r,1})+\cdots+a_{n'_r}f(v_{r,n'_r})=0
\]
luego $a_1v_{r,1}+\cdots+a_{n'_r}v_{r,n'_r}\in K_1\cap K'_r$; por lo tanto $a_1v_{r,1}+\cdots+a_{n'_r}v_{r,n'_r}=0$ y $a_1=\ldots=a_{n'_r}=0$.\\
Sea $\mathcal{B}_{r-1}=\{v_{r-1,1},\ldots,v_{r-1,n'_{r-1}}\}$ un base de $K'_{r-1}$ que contiene a $f(\mathcal{B}_r)$. Para $i=1,\ldots n'_{r-1}$, sea $$v_{r-2,i}=f(v_{r-1,i}).$$ Similarmente, note que $f(\mathcal{B}_{r-1})=\{v_{r-2,1},\ldots,v_{r-2,n'_{r-1}}\}\subseteq K'_{r-2}$ es linealmente independiente.\\
Iterativamente obtenemos bases $\mathcal{B}_1,\mathcal{B}_2,\ldots,\mathcal{B}_r$ respectivamente de $K_1,K'_2,\ldots,K'_r$ con $f(\mathcal{B}_{i+1})\subseteq\mathcal{B}_i$ para $i=1,\ldots,r-1$. En particular
\[
\mathcal{B}=\mathcal{B}_1\cup \mathcal{B}_2\cup\ldots\cup \mathcal{B}_r
\]
es una base de $V$. Defina (ver Figura \ref{edificios})
\begin{eqnarray*}
V_1 & = & \langle v_{j,1}\in \mathcal{B}\ |\ 1\le \dim(K'_j)\rangle \\
V_2 & = & \langle v_{j,2}\in \mathcal{B}\ |\ 2\le \dim(K'_j)\rangle \\
       & \vdots & \\
V_n & = & \langle v_{j,n}\in \mathcal{B}\ |\ n\le \dim(K'_j)\rangle
\end{eqnarray*}
de esta forma por construcci\'on cada $V_i$, $i=1,\ldots, n$, son invariantes bajo $f$ y c\'iclicos bajo $f_i$.\qed 

\begin{figure}[!hbp]
\centering
\frame{
\begin{tikzpicture}[auto, node distance=1.1cm,>=latex']
    \node (Kr) {$K'_r$};
    \node (Kr-1) [below of=Kr] {$K'_{r-1}$};
    \node (Kdots) [below of=Kr-1] {$\vdots$};
    \node (K2) [below of=Kdots] {$K'_2$};
    \node (K1) [below of=K2] {$K_1$};
    \node (0) [below of=K1] {$\{0\}$};
    
    \node (v1r) [right of=Kr] {$v_{r,1}$};    
    \node (v2r) [right of=v1r] {$v_{r,2}$};
    \node (vdotsr) [right of=v2r] {$\cdots$};
    \node (vnrr) [right of=vdotsr] {$v_{r,n'_r}$};    
        
    \node (v1r-1) [right of=Kr-1] {$v_{r-1,1}$};    
    \node (v2r-1) [right of=v1r-1] {$v_{r-1,2}$};
    \node (vdotsr-1) [right of=v2r-1] {$\cdots$};
    \node (vnrr-1) [right of=vdotsr-1] {$v_{r-1,n'_r}$};
    \node (vdots2r-1) [right of=vnrr-1] {$\cdots$};
    \node (vnr-1r-1) [right of=vdots2r-1] {$v_{r-1,n'_{r-1}}$};
    
    \node (v1dots) [right of=Kdots] {$\vdots$};    
    \node (v2dots) [right of=v1dots] {$\vdots$};
    \node (vdotsdots) [right of=v2dots] {$\cdots$};
    \node (vnrdots) [right of=vdotsdots] {$\vdots$};
    \node (vdots2dots) [right of=vnrdots] {$\cdots$};
    \node (vnr-1dots) [right of=vdots2dots] {$\vdots$};

    \node (v12) [right of=K2] {$v_{2,1}$};    
    \node (v22) [right of=v12] {$v_{2,2}$};
    \node (vdots2) [right of=v22] {$\cdots$};
    \node (vnr2) [right of=vdots2] {$v_{2,n'_r}$};
    \node (vdots22) [right of=vnr2] {$\cdots$};
    \node (vnr-12) [right of=vdots22] {$v_{2,n'_{r-1}}$};
    \node (vdots32) [right of=vnr-12] {$\cdots$};
    \node (vn22) [right of=vdots32] {$v_{2,n'_2}$};

    \node (v11) [right of=K1] {$v_{1,1}$};    
    \node (v21) [right of=v11] {$v_{1,2}$};
    \node (vdots1) [right of=v21] {$\cdots$};
    \node (vnr1) [right of=vdots1] {$v_{1,n'_r}$};
    \node (vdots21) [right of=vnr1] {$\cdots$};
    \node (vnr-11) [right of=vdots21] {$v_{1,n'_{r-1}}$};
    \node (vdots31) [right of=vnr-11] {$\cdots$};
    \node (vn21) [right of=vdots31] {$v_{1,n'_2}$};
    \node (vdots41) [right of=vn21] {$\cdots$};
    \node (vn11) [right of=vdots41] {$v_{1,n}$};
    
    \node (v10) [below of=v11] {$0$};    
    \node (v20) [below of=v21] {$0$};
    \node (vdots0) [below of=vdots1] {$\cdots$};
    \node (vnr0) [below of=vnr1] {$0$};
    \node (vdots20) [below of=vdots21] {$\cdots$};
    \node (vnr-10) [below of=vnr-11] {$0$};
    \node (vdots30) [below of=vdots31] {$\cdots$};
    \node (vn20) [below of=vn21] {$0$};
    \node (vdots40) [below of=vdots41] {$\cdots$};
    \node (vn10) [below of=vn11] {$0$};
    
    \node (V1) [below of=v10] {$V_1$};    
    \node (V2) [below of=v20] {$V_2$};
    \node (Vdots) [below of=vdots0] {$\cdots$};
    \node (Vnr) [below of=vnr0] {$V_{n'_r}$};
    \node (Vdots2) [below of=vdots20] {$\cdots$};
    \node (Vnr-1) [below of=vnr-10] {$V_{n'_{r-1}}$};
    \node (Vdots3) [below of=vdots30] {$\cdots$};
    \node (Vn2) [below of=vn20] {$V_{n'_2}$};
    \node (Vdots4) [below of=vdots40] {$\cdots$};
    \node (Vn1) [below of=vn10] {$V_n$};
    
    \path[->] (Kr) edge node {} (Kr-1);
    \path[->] (v1r) edge  node {} (v1r-1);
    \path[->] (v2r) edge  node {} (v2r-1);
    \path[->] (vnrr) edge  node {} (vnrr-1);
    
    \path[->] (Kr-1) edge node {} (Kdots);
    \path[->] (v1r-1) edge  node {} (v1dots);
    \path[->] (v2r-1) edge  node {} (v2dots);
    \path[->] (vnrr-1) edge  node {} (vnrdots);
    \path[->] (vnr-1r-1) edge  node {} (vnr-1dots);

    \path[->] (Kdots) edge node {} (K2);
    \path[->] (v1dots) edge  node {} (v12);
    \path[->] (v2dots) edge  node {} (v22);
    \path[->] (vnrdots) edge  node {} (vnr2);
    \path[->] (vnr-1dots) edge  node {} (vnr-12);
  
    \path[->] (K2) edge node {} (K1);
    \path[->] (v12) edge  node {} (v11);
    \path[->] (v22) edge  node {} (v21);
    \path[->] (vnr2) edge  node {} (vnr1);
    \path[->] (vnr-12) edge  node {} (vnr-11);
    \path[->] (vn22) edge  node {} (vn21);
    
    \path[->] (K1) edge node {} (0);
    \path[->] (v11) edge  node {} (v10);
    \path[->] (v21) edge  node {} (v20);
    \path[->] (vnr1) edge  node {} (vnr0);
    \path[->] (vnr-11) edge  node {} (vnr-10);
    \path[->] (vn21) edge  node {} (vn20);
    \path[->] (vn11) edge node {} (vn10);    
\end{tikzpicture}
}
\caption{Edificios colapsando}
\label{edificios}
\end{figure}

\begin{ejem}
Si $f\in\Hom_K(K^4,K^4)$ est\'a definido como en Ejemplo \ref{ejnil1}
$$f(x,y,z,w)=(y,z,w,0),$$
entonces
$$n=1,\quad n'_2=1,\quad n'_3=1,\quad n'_4=1.$$
\end{ejem}

\begin{ejem}
Si $f\in\Hom_K(K^4,K^4)$ est\'a definido como en Ejemplo \ref{ejnil2}
$$f(x,y,z,w)=(y,z,0,0),$$
entonces
$$n=2,\quad n'_2=1,\quad n'_3=1.$$
\end{ejem}

\begin{ejem}
Si $f\in\Hom_K(K^4,K^4)$ est\'a definido como en Ejemplo \ref{ejnil3}
$$f(x,y,z,w)=(y,0,w,0),$$
entonces
$$n=2,\quad n'_2=2.$$
\end{ejem}

\begin{ejem}
Si $f\in\Hom_K(K^4,K^4)$ est\'a definido como en Ejemplo \ref{ejnil4}
$$f(x,y,z,w)=(y,0,0,0),$$
entonces
$$n=3,\quad n'_2=1.$$
\end{ejem}

\begin{obs}\label{bloquesjordannil}
Bajo la hip\'otesis del teorema, y usando la notaci\'on en \'el, obtenemos que para cada $V_i$, $i=1,\ldots,n$, tenemos una base de Jordan $\mathcal{B}_i$ relativa a $f_i$. De esta forma la uni\'on de ella forma una base $\mathcal{B}$ de $V$. La representaci\'on matricial de $f$ en la base $T$ es una matriz diagonal por bloques:
\[
\Big[f\Big]^\mathcal{B}_\mathcal{B}=\left[\begin{array}{c|c|c|c}
J_1 & 0 & \cdots & 0\\
\hline
0 & J_2 & \cdots & 0\\
\hline
\vdots & \vdots & \ddots & \vdots\\
\hline
0 & 0 & \cdots & J_n
\end{array}\right] 
\]
donde cada $J_i=\Big[f\Big]^{\mathcal{B}_i}_{\mathcal{B}_i}$ es una matriz $\dim(V_i)\times\dim(V_i)$ de la forma en Observaci\'on \ref{obsformajordannil}.
\end{obs}

\begin{obs}
Como corolario de la prueba del teorema tenemos que cuando $V$ tiene dimensi\'on finita y $f$ es nilpotente, la informaci\'on subministrada por las cantidades 
\begin{eqnarray*}
\dim(K_1) & = & n\\
\dim(K_i)-\dim(K_{i-1}) & = & n'_i,\qquad i=2,\ldots,r
\end{eqnarray*}
son tales que  $n\ge n'_2\ge \ldots \ge n'_r$ y determinan univocamente la transformaci\'on $f$, salvo cambio de coordenadas. De hecho dadas dos transformaciones con igual informaci\'on, para cada una podemos encontrar una base de $V$ que arrojan la misma representaci\'on matricial. Espec\'ificamente, $n$ indica el n\'umero de bloques de Jordan y $n'_i$ el n\'umero de bloques de Jordan de tama\~no mayor o igual a $i$.
\end{obs}

\begin{defn}
Se le llama \emph{matriz en bloque de Jordan} a una matriz cuadrada $n\times n$ de la forma
\[
J_{\lambda,n}=\left[\begin{array}{ccccc}
\lambda & 1 & 0 &\cdots & 0\\
0 & \lambda & 1 &\cdots & 0\\
\vdots & \vdots & \ddots &\ddots & \vdots\\
0 & 0 & 0 & \cdots & 1\\
0 & 0 & 0 & \cdots & \lambda
\end{array}\right].
\]
\end{defn}

\begin{lema}
Suponga que $V$ tiene dimensi\'on finita y que $P(t)=(t-\lambda)^m\in K[t]$, es tal que $P(f)=0$. Entonces existe una base $\mathcal{B}$ de $V$ tal que la representaci\'on matricial de $f$ en esta base es
es una matriz diagonal por bloques:
\[
\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}=\left[\begin{array}{c|c|c|c}
J_1 & 0 & \cdots & 0\\
\hline
0 & J_2 & \cdots & 0\\
\hline
\vdots & \vdots & \ddots & \vdots\\
\hline
0 & 0 & \cdots & J_n
\end{array}\right] 
\]
donde cada $J_i$, $i=1,\ldots,n$ es una matriz en bloque de Jordan.
\end{lema}

\dem Tenemos $P(f)=(f-\lambda\id_V)^m=0$. Luego el operador $g=f-\lambda\id_V$ es nilpotente. Por Teorema \ref{formajordannil},
\[
V=V_1\oplus V_2\oplus\cdots\oplus V_n
\]
donde para cada $V_i$, $i=1,\ldots, n$, hay una base de la forma $\mathcal{B}_i=\{v_{1,i},\ldots,v_{m_i,i}\}$, con $\dim(V_i)=m_i$ y
\[
\begin{array}{rcccl}
v_{m_i-1,i} & = & g(v_{m_i,i}) & = & f(v_{m_i,i})-\lambda v_{m_i,i}\\
v_{m_i-2,i} & = & g(v_{m_i-1,i}) & = & f(v_{m_i-1,i})-\lambda v_{m_i-1,i}\\
 & \vdots & & \vdots & \\
v_{1,i} & = & g(v_{2,i}) & = & f(v_{2,i})-\lambda v_{2,i}\\
0 & = & g(v_{1,i}) & = & f(v_{1,i})-\lambda v_{1,i}.
\end{array}
\]
As\'i,
\begin{eqnarray*}
f(v_{m_i,i}) & = & v_{m_i-1,i}+\lambda v_{m_i,i}\\
f(v_{m_i-1,i}) & = & v_{m_i-2,i}+\lambda v_{m_i-1,i}\\
 & \vdots & \\
f(v_{2,i}) & = & v_{1,i}+\lambda v_{2,i}\\
f(v_{1,i}) & = & \lambda v_{1,i}.
\end{eqnarray*}
En particular, cada $V_i$ es invariante bajo $f$, luego, si $f_i\in\Hom_K(V_i,V_i)$ denota la restricci\'on de $f$ a $V_i$,
$\Big[f_i\Big]^{\mathcal{B}_i}_{\mathcal{B}_i}=J_i$ es una matriz en bloque de Jordan. De esto, si $\mathcal{B}=\mathcal{B}_1\cup\ldots\cup \mathcal{B}_n$, la representaci\'on matricial $\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$ tiene la forma buscada.\qed

\begin{teo}[Teorema de Jordan]
Suponga que $V$ tiene dimensi\'on finita y que
\[
P_f(t)=(t-\lambda_1)^{m_1}(t-\lambda_2)^{m_2}\ldots(t-\lambda_r)^{m_r}, \quad \lambda_1,\lambda_2,\ldots,\lambda_r\in K.
\]
Entonces existe una base $\mathcal{B}$ de $V$ tal que la representaci\'on matricial de $f$ en esta base es
es una matriz diagonal por bloques de Jordan. 
\end{teo}

\dem Sin perdida de generalidad podemos asumir que $\lambda_i\ne\lambda_j$ si $i\ne j$. As\'i
\[
\left( (t-\lambda_i)^{m_i},(t-\lambda_j)^{m_j}\right)=1
\]
si $i\ne j$. Por el teorema de Caley-Hamilton $P_f(f)=0$, luego por Propiedad \ref{prodescomp},
\[
V=V_1\oplus \ldots \oplus V_r
\]
donde cada $V_i=\ker\left((f-\lambda_i\id_V)^{m_i}\right)$, $i=1,\ldots,r$, es invariante bajo $f$. En particular, si $f_i\in\Hom_K(V_i,V_i)$ es la restricci\'on de $f$ a $V_i$, $i=1,\ldots,r$, $P_i(f_i)=0$, donde $P_i(t)=(t-\lambda_i)^{m_i}$. Por lo tanto, el lema implica que existe una base $\mathcal{B}_i$ de $V_i$ para la cual $\Big[f_i\Big]^{\mathcal{B}_i}_{\mathcal{B}_i}$ es una matriz diagonal por bloques de Jordan. Finalmente si $\mathcal{B}=\mathcal{B}_1\cup\ldots\cup \mathcal{B}_n$, la representaci\'on matricial $\Big[f\Big]^{\mathcal{B}}_{\mathcal{B}}$ tiene la forma afirmada.\qed

\begin{defn}
Generalizamos la definici\'on anterior de base de Jordan. Si $V$ tiene dimensi\'on finita, decimos que una base de $V$ es una \emph{base de Jordan relativa a $f$} si la representaci\'on matricial de este operador en aquella base es diagonal en bloques de Jordan.
\end{defn}

\begin{lema}
Sea $f\in\End_K(V)$. Si $\lambda_1,\ldots,\lambda_n\in K$ son valores propios, todos distintos, de $f$, y, para $i=1,\ldots,n$, $v_i\in V$ es un vector propio de $\lambda_i$, entonces $\{v_1,\ldots,v_n\}$ es linealmente independiente. 
\end{lema}

\dem Por inducci\'on en $n$, siendo el caso base $n=1$ inmediato, pues $\{v_1\}$ es linealmente independiente si $v_1\ne 0$, la cual se cumple pues $v_1$ es vector propio. Para el paso inductivo, si $a_1,\ldots,a_n$ son tales que $a_1v_1+\cdots+a_nv_n=0$,por contradicci\'on podemos asumir que cada $a_i\ne 0$, o de lo contrario, por hipotesis de inducci\'on, si alg\'un $a_i$  es $0$ el resto tambi\'en lo son. Entonces
\[
0=(f-\lambda_n\id_V)(a_1v_1+\cdots+a_nv_n)=a_1(\lambda_1-\lambda_n)v_1+\cdots+a_{n-1}(\lambda_{n-1}-\lambda_n)v_{n-1};
\]
y as\'i, por hip\'otesis de inducci\'on, para $i=1,\ldots,n-1$, $a_i(\lambda_i-\lambda_n)=0$. Pero $a_i\ne 0$ y $\lambda_i-\lambda_n\ne 0$,  si $i\in\{1,\ldots,n-1\}$ , lo cual es una contradicci\'on.\qed

\begin{lema}
Suponga que $f\in\End_K(V)$ es diagonalizable, entonces:
\begin{enumerate}
\item Si $V_0\ne\{0\}$ es invariante bajo $f$, su restricci\'on a $V_0$, $f_0\in\Hom_K(V_0,V_0)$, tambi\'en es diagonalizable. 
\item Si  $g\in\End_K(V)$ es diagonalizable y $f\circ g=g\circ f$, entonces existe una familia $\{V_i\}_{i\in I}$ de espacios propios simult\'aneamente de $f$ y $g$ tal que $V=\bigoplus_{i\in I}V_i$. En particular si $v$ es un vector propio simult\'aneamente de $f$ y $g$, $v$ es un vector propio de $af+bg$ para todo $a,b\in K$.
\end{enumerate}
\end{lema} 

\dem \begin{enumerate}
\item Dado un valor propio $\lambda\in K$ de $f$, definimos $E_\lambda\le V$ como el subespacio generado por los vectores propios de $f$ asociados a $\lambda$, es decir $E_\lambda=\ker(f-\lambda\id_V)$, y $F_\lambda=V_0\cap E_\lambda$. Note que, como $f$ es diagonalizable, por el lema anterior,
\[
V=\bigoplus_{i\in I} E_{\lambda_i}
\]
donde $\{\lambda_i\}_{i\in I}$ es la colecci\'on de valores propios de $f$. Sea $v\in V_0$, $v\ne 0$, y
\[
v=v_1+\cdots+v_n
\]
una descomposici\'on en vectores propios asociados respectivamente a valores propios $\lambda_1, \ldots , \lambda_n\in K$. Por inducci\'on en $n$ veamos que $v_1,\ldots,v_n\in V_0$ siendo el caso base $n=1$ inmediato pues en tal caso $v_0=v_1$. Para el paso inductivo, como $V_0$ es invariante bajo $f$
\[
(f-\lambda_n\id_V)(v)=(\lambda_1-\lambda_n)v_1+\cdots+(\lambda_{n-1}-\lambda_{n})v_{n-1}
\]
tambi\'en pertenece a $V_0$. Luego por hip\'otesis inductiva , $(\lambda_1-\lambda_n)v_1, \ldots, (\lambda_{n-1}-\lambda_{n})v_{n-1}\in V_0$, as\'i pues $v_1, \ldots, v_{n-1}\in V_0$ y $v_n=v-v_1-\ldots-v_{n-1}\in V_0$. De donde
\[
V_0=\bigoplus_{i\in J} F_{\lambda_i},
\]
donde $J$ es la colecci\'on de $i\in I$ tales que $F_{\lambda_i}\ne\{0\}$. Entonces $f_0$ es diagonalizable tomando bases de cada $F_{\lambda_i}$, $i\in J$.
\item Usando la notaci\'on de la demostraci\'on de la primera afirmaci\'on del lema, si $v\in E_{\lambda_i}$, $i\in I$,
\[
f\left(g(v)\right)=g\left(f(v)\right)=\lambda_ig(v),
\]
luego $E_{\lambda_i}$ es invariante bajo $g$. Por la primera parte del lema, la restricci\'on de $g$ a $E_{\lambda_i}$, $g_i\in\Hom_K (E_{\lambda_i},E_{\lambda_i})$ es diagonalizable. Luego $g$ es diagonalizable tomando bases de cada $E_{\lambda_i}$, $i\in I$. Los espacios propios generados por cada uno de estos elementos de estas bases forman una colecci\'on de espacios propios simult\'aneos cuya suma es una suma directa igual a $V$. \qed 
\end{enumerate}   

\begin{teo}[Descomposici\'on de Jordan-Chevalley]\label{descjorche}
Suponga que $V$ tiene dimensi\'on finita y que
\[
P_f(t)=(t-\lambda_1)^{m_1}(t-\lambda_2)^{m_2}\ldots(t-\lambda_r)^{m_r}, \quad \lambda_1,\lambda_2,\ldots,\lambda_r\in K.
\]
donde $\lambda_i\ne\lambda_j$ si $i\ne j$. Entonces existen operadores $f_N,f_D\in\End_K(V)$, tales que
\begin{enumerate}
\item $f_D$ es diagonalizable y $f_N$ es nilpotente;
\item $f_D+f_N=f$; y,
\item $f_D\circ f_N=f_N\circ f_D$.
\end{enumerate}
M\'as a\'un, esta descomposici\'on es \'unica respecto a estas tres propiedades. Adem\'as existen polinomios $P_D(t),P_N(t)\in K[t]$ tales que $f_N=P_N(f)$ y $f_D=P_D(f)$.
\end{teo}

\dem Defina $P_i(t)=(t-\lambda_i)^{m_i}$, $i=1,\ldots,n$. Por Propiedad \ref{prodescomp}, existen $\Pi_1(t),\ldots,\Pi_n(t)\in K[t]$ tales que $\Pi_i(f)=p_i$, $i=1,\ldots,n$, son las proyecciones sobre $V_i=\ker\left((f-\lambda_i\id_V)^{m_i}\right)$ respecto a la descomposici\'on 
\[
V=V_1\oplus \ldots \oplus V_r.
\]
Defina $P_D(t)=\lambda_1\Pi_1(t)+\cdots+\lambda_n\Pi_n(t)$, y $f_D=P_D(f)$. De esta forma, si $v_i\in V_i$,
\[
f_D(v_i)=\lambda_1p_1(v_i)+\cdots+\lambda_np_n(v_i)=\lambda_iv_i,
\]
y as\'i $f_D$ es diagonalizable por Teorema \ref{diagosiysolosi}. Defina $P_N(t)=t-P_D(t)$ y $f_N=P_N(f)=f-f_D$. De esta forma, $f_D+f_N=f$, y si $v_i\in V_i$
\[
f_N(v_i)=f(v_i)-f_D(v_i)=f(v_i)-\lambda_i(v_i)=\left(f-\lambda_i\id_V\right)(v_i),
\]
luego la restricci\'on de $f_N$ a $V_i$ es nilpotente de grado $\le m_i$. De donde $f_N$ es nilpotente de grado $\le\max\{m_1,\ldots,m_n\}$. Finalmente,
\[
f_D\circ f_N=P_D(f)\circ P_N(f)=P_N(f)\circ P_D(f)=f_N\circ f_D.
\]
Si $f'_D,f'_N\in\End_K(V)$ conmutan y son respectivamente diagonalizable y nilpotente tales que $f=f'_D+f'_N$, entonces
\[
f\circ f'_D=(f'_D+f'_N)f'_D=f'_D\circ f'_D+f'_N\circ f'_D=f'_D\circ f'_D+f'_D\circ f'_N=f'_D\circ f,
\]
es decir $f$ y $f'_D$ conmutan. Por lo cual, $P_D(f)=f_D$ y $f'_D$ tambi\'en lo hacen.\\
Entonces $f_D$ y $f'_D$ son diagonalizables y conmutan. Ahora, si $v$ es un vector propio com\'un, entonces $v$ es un vector propio de $f_D-f'_D$. Pero $f_D-f'_D=f'_N-f_N$, y, como $f'_N$ y $f_N$ igualmente conmutan, $f'_N-f_N$ es igualmente nilpotente. As\'i $f_D-f'_D$ es diagonalizable y, a su vez, nilpotente, el valor propio asociado a $v$ es $0$. Por el lema anterior existe una base de $V$ de vectores propios simult\'aneos de $f_D$ y $f'_D$, luego todos los valores propios de $f_D-f'_D$ son $0$. Es decir $f_D-f'_D=0=f'_N-f_N$; y, $f'_D=f_D$ y $f'_N=f_N$.\qed

\section{Polinomio minimal y transformaciones semi-simples} 