\chapter{Espacios vectoriales y transformaciones lineales}

Sea $\mathbb{K}$ un cuerpo (ver la definición \ref{defcuerpo}). A los elementos de $\mathbb{K}$ los llamaremos \emph{escalares}.

\section{Espacios vectoriales}

\begin{defn}\label{defespvec}
Un \emph{espacio vectorial sobre $\mathbb{K}$} es un conjunto $V$ junto con dos operaciones binarias
\[
\begin{array}{rclcrcl}
+:V\times V & \longrightarrow & V &\qquad& \cdot: \mathbb{K}\times V & \longrightarrow & V \\
(v,w) & \longmapsto & v+w &\qquad& (c,v) & \longmapsto & cv, 
\end{array}
\]
que llamamos respectivamente \emph{suma} y \emph{producto por escalar} (o \emph{adici\'on} y \emph{multiplicaci\'on por escalar}), y que contiene un elemento $O\in V$, que llamamos \emph{el origen}, los cuales satisfacen las siguientes propiedades.
\begin{enumerate}[(i)]
\item \emph{La estructura $(V,+,O)$ es un grupo abeliano}: para todo $u,v,w\in V$ se tiene
\[ v+w=w+v,\qquad u+(v+w)=(u+v)+w,\qquad v+O=v,\]
y para todo $v\in V$ existe $-v\in V$ que satisface la igualdad $-v+v=O$.
\item \emph{El producto por escalar es unitario y asociativo}: para todo $a,b\in \mathbb{K}$ y todo $v\in V$ se tiene
\[ 1v=v,\qquad a(bv)=(ab)v.\]
\item \emph{El producto por escalar se distribuye sobre la suma}: para todo $a,b\in \mathbb{K}$ y todo $v,w\in V$ se tiene
\[ a(v+w)=av+aw,\qquad (a+b)v=av+bv.\] 
\end{enumerate}
Un \emph{vector} es un elemento de un espacio vectorial.
\end{defn}

\begin{ejem}\label{ejem0}
Los siguientes espacios vectoriales sobre $\mathbb{K}$ son ejemplos imprescindibles.
\begin{enumerate}[(i)]
\item \emph{Espacio cero-dimensional}: El conjunto $\{O\}$ junto con las \'unicas operaciones posibles.
\item \emph{Espacio uni-dimensional}: El conjunto $\mathbb{K}$ junto con las operaciones del cuerpo y $O=0$.
\item \emph{Espacio $n$-dimensional de coordenadas}: El conjunto $\mathbb{K}^n$ formado por el producto cartesiano de $n$ copias del cuerpo $K$, junto con las operaciones
\begin{eqnarray*}
(a_1,\ldots,a_n)+(b_1,\ldots,b_n) & = & (a_1+b_1,\ldots,a_n+b_n)\\
c(a_1,\ldots,a_n) & = & (ca_1,\ldots,ca_n)
\end{eqnarray*}
y $O=(0,\ldots,0)$.
\item \emph{Espacio de funciones con valor en $\mathbb{K}$}: Dado un conjunto $X$, el conjunto $\mathbb{K}^X$ de funciones $X\rightarrow \mathbb{K}$, junto con las operaciones
\begin{eqnarray*}
  f+g: x & \mapsto & f(x)+g(x)\\
  cf: x & \mapsto & cf(x)
\end{eqnarray*}
y el origen es la función $O: x\mapsto 0$.
\item \emph{Espacio de funciones con valor en $\mathbb{K}$, con casi todos los valores iguales a $0$}: Dado un conjunto $X$, el conjunto $\mathbb{K}^S_0$ de funciones $X\rightarrow \mathbb{K}$ para las que todos los valores, salvo para un n\'umero finito de elementos en $X$, son $0$, junto con las operaciones y el origen definidos para $\mathbb{K}^X$.
\item \emph{Espacio de polinomios con coeficientes en $\mathbb{K}$}: El conjunto $\mathbb{K}[t]$ de polinomios en la variable $t$ con coeficientes en $\mathbb{K}$ junto con las operaciones de suma y producto por escalar usuales y con el origen $O$ dado por el polinomio constante $0$ (ver la definición \ref{defpoly}).
\end{enumerate} 
\end{ejem}

\begin{prop}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$
\begin{enumerate}[(i)]
  \item \emph{Ley de cancelaci\'on}: Dados $u,v,w\in V$, la igualdad $u+v=w+v$ implica $u=w$.
  \item \emph{Unicidad del origen}: Si $o\in V$ es tal que $v+o=v$ para algún $v\in V$ entonces $v=0$.
  \item \emph{Unicidad del opuesto}: Dado $v\in V$, si $w\in V$ es tal que $v+w=O$, entonces $w=-v$. 
\end{enumerate}
\end{prop}

\dem
\begin{enumerate}[(i)]
  \item A partir de la igualdad $u+v=w+v$, si sumamos $-v$ a ambos lados obtenemos $u=w$.
  \item Se sigue de la ley cancelativa aplicada a $v+o=v=v+O$.
  \item Se sigue de la ley cancelativa aplicada a $v+w=O=v+(-v)$.
\end{enumerate}

\begin{prop}
Sea $V$ es un espacio vectorial sobre $\mathbb{K}$.
\begin{enumerate}[(i)]
\item Para todo $c\in \mathbb{K}$ y $v\in V$ tenemos $cO=0v=O$.
\item Para todo $v\in V$ tenemos $(-1)v=-v$.
\item Si tenemos $cv=O$, entonces $c=0$ \'o $v=O$.
\end{enumerate}
\end{prop}

\dem
\begin{enumerate}[(i)]
\item Tenemos $cO+O=cO=c(O+O)=cO+cO$, luego, por la ley de cancelaci\'on, $cO=O$. Igualmente, tenemos $0v+O=0v=(0+0)v=0v+0v$, luego $0v=O$.
\item Por la unicidad del opuesto, basta ver que $v+(-1)v=O$, lo cual se sigue de las igualdades $v+(-1)v=1v+(-1)v=\left(1+(-1)\right)v=0v$.
\item Suponga que $cv=O$ con $c\ne 0$, entonces tenemos $O=c^{-1}O=c^{-1}(cv)=(c^{-1}c)v=1v=v$.
\end{enumerate}
\qed

\begin{defn}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$ y $U\subseteq V$. Decimos que $U$ es un \emph{subespacio} de $V$ si $U$, con las operaciones heredadas de $V$, es un espacio vectorial.
\end{defn}

\begin{nota}
Usaremos los s\'imbolos $\le$, $<$, $\ge$ y $>$ para representar respectivamente \emph{subespacio de}, \emph{subespacio propio de}, \emph{superespacio de} y \emph{superespacio propio de}.
\end{nota}

\begin{prop}[Caracterización de subespacios]\label{subespsiysolosi}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$. Si $U$ es un subconjunto de $V$, entonces $U\le V$ si y solo si $U$ satisface las siguientes propiedades.
\begin{enumerate}[(i)]
\item $O\in U$.
\item \emph{El conjunto $U$ es cerrado bajo suma}: para todo $v,w\in U$, se tiene $v+w\in U$.
\item \emph{El conjunto $U$ es cerrado bajo multiplicaci\'on por escalar}: para todo $c\in \mathbb{K}$ y $v\in U$, se tiene $cv\in U$.
\end{enumerate} 
\end{prop}

\dem Suponga primero $U\le V$. Luego $U$ contiene un neutro respecto a la suma y, como la operaci\'on de suma es la de $V$, este es $O$. As\'i tenemos $O\in U$. Por otro lado, como $U$ es un espacio vectorial con las operaciones de $V$, la suma de dos elementos en $U$ est\'a en $U$ y producto por escalar de un elemento en $U$ tambi\'en est\'a en $U$.\\
Rec\'iprocamente, si $U$ contiene al origen y es cerrado bajo suma, la restricci\'on de la suma a $U\times U$ da una operaci\'on $+:U\times U\rightarrow U$ que cumple con el axioma (i) de la definici\'on \ref{defespvec}. Similarmente sucede con la restricci\'on del producto por escalar a $\mathbb{K}\times U$ y el axioma (ii). Finalmente, el axioma (iii) de distributividad se hereda de $V$.\qed

\begin{ejem}
Las soluciones a sistemas lineales homogéneos son subespacios. De hecho, tome $a_{i1},\ldots,a_{in}\in \mathbb{K}$, para $i\in\{1,\ldots,m\}$, con $m\le n$. El conjunto $U$ de soluciones $(x_1,\ldots,x_n)\in\mathbb{K}^n$ al sistema
$$\left\{
\begin{array}{lcr}
  a_{11}x_1+\cdots+a_{1n}x_n & = & 0\\
   & \vdots & \\
  a_{m1}x_1+\cdots+a_{mn}x_n & = & 0\\
\end{array}
\right.$$
contiene al origen, es cerrado mediante suma y producto por escalar, y es así un subespacio.
\end{ejem}

\begin{defn}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$ y sean $v_1,\ldots,v_n\in V$. Una \emph{combinaci\'on lineal} de  $v_1,\ldots,v_n$ es un vector $v\in V$ tal que
\[
v=c_1v_1+\cdots+c_nv_n
\]
con $c_1,\ldots,c_n\in\mathbb{K}$. A los elementos $c_1,\ldots,c_n$ los llamamos los \emph{coeficientes} de la combinaci\'on lineal.
\end{defn}

\begin{prop}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$. Dado un subconjunto no vac\'io $C$ de $V$, el conjunto formado por todas las combinaciones lineales de elementos en $C$ es un subespacio de $V$.
\end{prop}

\dem Sea $U$ el conjunto $\left\{\sum_{i=1}^nc_iv_i\Big|\ c_1,\ldots,c_n\in \mathbb{K},\ v_1,\ldots,v_n\in C \right\}$. Como $C$ no es vacío, para cualquier $c\in C$ se tiene $0c=O$ y así $U$ contiene al origen.
Para todo $v,w\in U$, existen $a_1,\ldots,a_n,b_1,\ldots,b_m\in \mathbb{K}$ y $v_1,\ldots,v_n,w_1,\ldots,w_m\in S$ tales que $v=\sum_{i=1}^n a_iv_i$ y $w=\sum_{j=1}^m b_jw_j$, y así
\[
v+w=a_1v_1+\cdots+a_nv_n+b_1w_1+\cdots+b_mw_m.
\]
Luego, $v+w$ es una combinaci\'on lineal de elementos de $C$ y $v+w$ pertenece a $U$. Similarmente, dado $c\in \mathbb{K}$, tenemos
\[
cv=ca_1v_1+\cdots+ca_nv_n,
\]
y as\'i $cv$ est\'a en $U$. Por lo tanto, $U$ es cerrado bajo suma y multiplicaci\'on por escalar, luego, por la propiedad \ref{subespsiysolosi}, $U$ es subespacio de $V$.\qed

\begin{defn}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$ y sea $C$ un subconjunto de $V$ no vac\'io. Al subespacio formado por todas las combinaciones lineales de elementos de $C$ lo llamamos el \emph{espacio generado por $C$} y lo denotamos por $\langle C \rangle$. Por convenci\'on, definimos $\langle \emptyset\rangle=\{O\}$.
\end{defn}

\begin{prop}\label{propunion}
Sea $V$ un espacio vectorial sobre $\mathbb{K}$.
\begin{enumerate}[(i)]
\item Si $\{U_i\}_{i\in I}$ es una familia de subespacios de $V$, entonces la intersecci\'on $\bigcap_{i \in I} U_i$ es un subespacio de $V$.
\item Si $C$ es un subconjunto de $V$, entonces $\langle C\rangle$ es el m\'inimo subespacio vectorial en $V$ que contiene a $C$. Es decir, si $W$ es un subespacio de $V$ que contiene a C, entonces $\langle C\rangle$ es un subespacio de $W$.
\end{enumerate}
\end{prop}

\dem
\begin{enumerate}[(i)]
\item Sea $U$ el conjunto $\bigcap_{i\in I} U_i$. Para todo $i\in I$, el origen $O$ está en $U_i$ y así $O\in U$. Sea $v,w\in U$ y $a\in \mathbb{K}$. Para todo $i \in I$ tenemos $v,w\in U_i$, luego $v+w$ y $cv$ pertenecen a todo $U_i$ y as\'i tambi\'en est\'an en $U$.
\item Sea  $W$ un subespacio de $V$ que contiene a $C$. Como $W$ es cerrado bajo suma y bajo multiplicaci\'on por escalar, dados $v_1,\ldots,v_n\in C$ y $c_1,\ldots,c_n\in \mathbb{K}$, la combinaci\'on lineal $\sum_i^{n} c_iv_i$ est\'a en $W$. Es decir que toda combinaci\'on lineal de elementos de $C$ est\'a en $W$. Luego, tenemos $\langle C\rangle \subseteq W$. Pero como $\langle C\rangle$ es un espacio vectorial, obtenemos $\langle C\rangle \le W$.\qed
\end{enumerate}

\section*{Ejercicios}

\begin{enumerate}
  \item Verique que los conjuntos en el ejemplo \ref{ejem0} con sus respectivas operaciones son espacios vectoriales.
  \item Verifique que el conjunto de funciones continuas de $\mathbb{R}$ en $\mathbb{R}$ es un espacio vectorial sobre $\mathbb{R}$ al igual que el conjunto de funciones de $\mathbb{R}$ en $\mathbb{R}$ diferenciables en todas partes.
  \item Verifique que el conjunto de funciones racionales $\mathbb{C}(z_1,\ldots,z_n)$ es un espacio vectorial sobre $\mathbb{C}$.
  \item Explique por qué los conjuntos $\mathbb{N}$ y $\mathbb{Z}$ no son espacios vectoriales.
  \item ¿Es el conjunto $\{(x,y)\in\mathbb{R}^2|y>0\}$ un subespacio de $\mathbb{R}^2$?
  \item ¿Es el conjunto $\{(x,y,z)\in\mathbb{K}^3|x+y+z=0\}$ un subespacio de $\mathbb{K}^3$?
  \item ¿Es el conjunto $\{(x,-x,2x)\in\mathbb{K}^3|x\in\mathbb{R}\}$ un subespacio de $\mathbb{K}^3$?
  \item Demuestre que el conjunto $\{(x,y,z)\in\mathbb{R}^3|2x+y-z=0,x-y=0\}$ es un subespacio de $\mathbb{Q}^3$ y encuentre un conjunto de vectores que los genere.
  \item Demuestre que el conjunto $\{(x,y,z)\in\mathbb{R}^3|2x+y-z=0\}$ es un subespacio de $\mathbb{Q}^3$ y encuentre un conjunto de vectores que lo genere.
  \item Describa geométricamente el subconjunto $\langle (1,0,1), (0,1,0)\rangle$ de $\mathbb{R}^3$.
  \item Considere los siguientes subespacio de $\mathbb{Q}^3$, $U_1=\langle (1,1,0), (0,1,1)\rangle$ y $U_2=\langle (1,0,1), (0,1,0)\rangle$. Describa los elementos $(x,y,z)$ de $U_1\cap U_2$ como soluciones de un sistema y encuentre un conjunto generador.
\end{enumerate}

\section{Base y dimensi\'on}

Dado un conjunto de indices $I$ y un conjunto $C$, una \emph{familia de elementos de $C$ indexada por $I$}, o simplemente una \emph{familia de $C$}, es una función $I\rightarrow C$ que denotaremos por $(x_i)_{i\in I}$ cuando la imagen de $i$ es $x_i$. Cuando no haya lugar a confusión, regularmente identificaremos esta familia con el subconjunto $\{x_i\}_{i\in I}$ de $C$.

Sea $V$ un espacio vectorial sobre $\mathbb{K}$. 

\begin{nota}
Sea $C=(v_i)_{i\in I}$ una familia de vectores de $V$ indexados por un conjunto $I$ y $(c_i)_{i\in I}$ una familia de escalares indexados por $I$, tales que $c_i=0$ para todo indice $i\in I$, salvo para una subcolecci\'on finita, es decir que $(c_i)_{i\in I}\in \mathbb{K}^I_0$ (ver el ejemplo \ref{ejem0}(v)). A la combinación lineal de elementos de $C$ con coeficientes $c_i$ la denotaremos por $\sum_{i\in I} c_iv_i$ y a $c_i$ lo llamamos el $i$-ésimo coeficiente. Note que estas sumas son finitas pues los coeficientes que no son $0$ son finitos. Cuando $I$ es un conjunto finito de $n$ elementos, lo usual es tomar $I=\{1,\ldots,n\}$.
\end{nota}

\begin{defn}
Sea $\mathcal{B}=(v_i)_{i\in I}$ una familia de vectores en $V$. Decimos que $\mathcal{B}$ es una \emph{base} de $V$ si para cada $v\in V$ existe una \'unica combinaci\'on lineal de elementos de $C$ igual a $v$. Si $v=\sum_{i\in I} c_iv_i$, al coeficiente $c_i$ lo llamamos la \emph{coordenada $i$ de $v$ en la base $\mathcal{B}$}. Por convenci\'on, la base del espacio cero-dimensional es $\emptyset$. 
\end{defn}

\begin{lema}\label{lemabas}
Suponga que $V$ no es el espacio cero-dimensional y sea $\mathcal{B}=(v_i)_{i\in I}$ una base. Si $c_i$, $i\in I$, son escalares para los cuales $O=\sum_{i\in I}c_iv_i$, entonces $c_i=0$ para todo $i\in I$.
\end{lema}

\dem La combinaci\'on lineal $\sum_{i\in I}0v_i$ es la \'unica combinaci\'on lineal de elementos en $\mathcal{B}$ igual al origen, entonces $c_i=0$ para todo $i$.\qed 


\begin{defn}
Decimos que $V$ tiene dimensi\'on finita si tiene una base finita. De lo contrario decimos que $V$ tiene dimensi\'on infinita.
\end{defn}

\begin{teo}[Teorema de la dimensi\'on] \label{basedim}
Si $V$ tiene dimensi\'on finita, el n\'umero de elementos de la base es independiente de la base escogida.
\end{teo}

\dem La afirmaci\'on para el caso $V=\{O\}$, se sigue del hecho de que su \'unica base es de cero elementos. Tome $V$ diferente del espacio cero-dimensional y suponga por contradicci\'on que $V$ tiene dos bases finitas $(v_1,\ldots, v_n)$ y $(w_1,\ldots, w_m)$ de diferentes tamaños, es decir $n\ne m$. Sin perdida de generalidad, podemos asumir que $m>n$.\\
Para $j\in\{1,\ldots,m\}$, tome escalares $a_{1j},\ldots,a_{nj}$ tales que $$w_j=\sum_{i=1}^n a_{ij}v_i.$$ As\'i, dado $v\in V$ con $v=x_1w_1+\cdots+x_mw_m$ y $x_1,\ldots,x_m\in\mathbb{K}$, tendr\'iamos
$$v = \sum_{j=1}^m x_j\left(\sum_{i=1}^n a_{ij}v_i\right) = \sum_{i=1}^n\left(\sum_{j=1}^m a_{ij}x_j\right)v_i.$$
Por el lema anterior, se cumple $v=O$ si y solo si
\[
\sum_{j=1}^m a_{ij}x_j=0,
\]
para $i\in\{1,\ldots,n\}$. Estas $n$ igualdades forman un sistema homogeneo subdeterminado, es decir con m\'as variables que ecuaciones. En particular, este sistema tiene al menos una solución no trivial. Si $(x_1,\ldots,x_m)$ es una de ellas, entonces obtenemos el origen como una combinaci\'on lineal de los elementos de la base $\{w_1,\ldots, w_m\}$ con coeficientes no todos iguales a cero, lo cual contradice el lema. Por lo tanto tenemos $m=n$.\\
Cuando asumimos por contradicción que $V$ admite una base infinita $(w_i)_{i\in I}$, y tomamos $v\in V$, entonces existe una combinación lineal $v=x_1w_1+\cdots+x_nw_m$ de vectores $w_1,\ldots,w_n\in\{w_i\}_{i\in I}$ y obtenemos una contradicción similarmente a como la acabamos de obtener.\qed

\begin{defn}
Suponga que $V$ tiene dimensi\'on finita. Al n\'umero de elementos en una base de $V$ lo llamamos dimensi\'on de $V$ y lo denotamos por $\dim_\mathbb{K}(V)$, ó $\dim (V)$. Si $V$ tiene dimensi\'on infinita, escribimos $\dim(V)=\infty$, y usamos la convenci\'on de que $n<\infty$ para todo entero $n$.
\end{defn}

\begin{defn}
Sea $C$ un subconjunto de $V$. Decimos que $C$ es \emph{linealmente dependiente} si alg\'un elemento de $C$ es combinaci\'on lineal de los otros, es decir si existen $v_0,v_1,\ldots,v_n\in C$, dos a dos distintos, tales que
\[
v_0=c_1v_1+\cdots+c_nv_n
\]
para algunos escalares $c_1,\ldots,c_n$. Si $C$ no es linealmente dependiente, decimos que $S$ es \emph{linealmente independiente}. Por convención diremos que $\emptyset$ es linealmente independiente.
\end{defn}

\begin{prop}[Caracterización de independencia lineal]\label{proplinind}
Un conjunto $C$ de vectores es linealmente independiente si y solo si la única combinación lineal de vectores en $C$ igual al origen es la que todos sus coeficientes son iguales a cero.
\end{prop}

\dem Establecemos la contrapositiva: $C$ es linealmente dependiente si y solo si existen $v_1,\ldots,v_n\in C$ y $c_1,\ldots,c_n\in \mathbb{K}$, con $c_j\ne 0$ para alg\'un $j\in\{1,\ldots, n\}$, tales que
\[
O=c_1v_1+\cdots+c_nv_n.
\]
Lo cual se sigue al notar que esta igualdad equivale a
\[
v_j=\sum_{i=1,i\ne j}^n (-c_i/c_j)v_i
\]
cuando $c_j$ es invertible, es decir cuando $c_j\ne 0$ para algún $j\in\{1,\ldots,n\}$.
\qed

\begin{teo}[Caracterización de las bases]\label{defbase2}
Sea $\mathcal{B}=(v_i)_{i\in I}$ una familia vectores de $V$ indexada por $I$, con $I\ne\emptyset$. Entonces $\mathcal{B}$ es una base de $V$ si y solo si satisface las siguientes dos propiedades.
\begin{enumerate}[(i)]
\item El conjunto $\mathcal{B}$ es linealmente independiente.
\item El espacio $V$ es generado por $\mathcal{B}$.
\end{enumerate}
\end{teo}

\dem Es suficiente demostrar que si tenemos $\langle \mathcal{B}\rangle=V$ entonces $\mathcal{B}$ es una base si y solo si $\mathcal{B}$ es linealmente independiente. Con esto en mente, suponga primero que $\mathcal{B}$ es base, luego por el lema \ref{lemabas}, $\mathcal{B}$ es linealmente independiente. Recíprocamente, suponga que $\mathcal{B}$ es linealmente independiente y asuma por contradicci\'on que $\mathcal{B}$ no es base. Luego, existen dos combinaciones lineales con coeficientes distintos, ambas iguales a alg\'un $v\in V$. La diferencia de estas dos combinaciones lineales dar\'ia una combinaci\'on lineal igual a $O$ con no todos los coeficientes nulos, lo cual contradice la propiedad \ref{proplinind}.\qed

\begin{ejem}\label{ejembas0}
Por la propiedad \ref{defbase2}, se puede verificar que, para cada uno de los siguientes espacios $V$, el respectivo conjunto $\mathcal{B}$ es una base.
\begin{enumerate}[(i)]
\item En $V=K^n$, para $i\in\{1,\ldots, n\}$, defina $e_i\in V$ como el elemento con ceros en todas las entradas salvo en la $i$-\'esima, donde tiene $1$, es decir
$$e_1=(1,0,\ldots,0),\quad e_2=(0,1,\ldots,0),\quad e_n=(0,0,\ldots,1).$$
Tome $\mathcal{B}=(e_1,\ldots,e_n)$.
% \item  Sea $I$ un conjunto finito y sea $V=K^I$. Para $i\in I$, defina la funci\'on $\delta_i: I\rightarrow K$ por $\delta_i(i)=1$ y $\delta_i(j)=0$ para $j\ne i$. Tome $\mathcal{B}=\{\delta_i\}_{i\in I}$. 
\item Sea $I$ un conjunto y $V=\left(K^I\right)_0$ (ver Ejemplo \ref{ejem0}.5). Para $i\in I$, defina la funci\'on $\delta_i: I\rightarrow K$ por $\delta_i(i)=1$ y $\delta_i(j)=0$ para $j\ne i$. Tome $\mathcal{B}=(\delta_i)_{i\in I}$. 
\item Para $V=K[t]$, sea $\mathcal{B}=(1,t,t^2,\ldots)=(t^n)_{n\in\mathbb{N}}$.
\end{enumerate}
\end{ejem}

\begin{nota}
Para $K^n$, la \emph{base can\'onica} es la base $(e_1,\ldots,e_n)$ definida en el ejemplo \ref{ejembas0}.(i), que denotaremos por $\mathcal{C}_n$, o simplemente $\mathcal{C}$.
\end{nota}

\begin{lema}\label{inddep}
Sea $C$ un subconjunto de $V$ linealmente independiente. Si $v\in V$ es tal que $C\cup\{v\}$ es linealmente dependiente, entonces $v$ pertenece a $\langle C\rangle$.
\end{lema}

\dem Como $C\cup\{v\}$ es linealmente dependiente, por la proposici\'on \ref{proplinind} existen escalares $c_1,\ldots,c_n,c_{n+1}$, no todos iguales a cero, y $v_1,\ldots,v_n\in C$, dos a dos distintos, tales que
\[
O=a_1v_1+\cdots+a_nv_n+a_{n+1}v.
\]
Note que $a_{n+1}$ es diferente de $0$, o de lo contrario tendr\'iamos una combinaci\'on lineal de $v_1,\ldots,v_n$ igual a $O$, con no todos los coeficientes iguales a cero, lo que contradiría la independencia lineal de $C$. Obtenemos
\[
v=\sum_{i=1}^n(-a_i/a_{n+1})v_i\in\langle v_1,\ldots,v_n\rangle,
\]
y por lo tanto $v$ pertenece a $\langle v_1,\ldots,v_n\rangle$ que está contenido en $\langle C\rangle$. \qed

\begin{prop}\label{maximallinind}
Suponga que $V$ tiene dimensi\'on finita distinta de cero y sea $C$ un subconjunto no vacío finito de $V$. Si $C_0$ es un subconjunto linealmente independiente de $C$, entonces existe $C'\subseteq C$ maximal entre los subconjuntos linealmente independientes de $C$ que contienen a $C_0$. Es decir, dado un subconjunto $C_1$ de $C$ que contiene a $C'$, si $C_1$ es linealmente independiente, entonces $C_1=C'$, y si $C_1$ contiene propiamente a $C'$, entonces $C_1$ es linealmente dependiente. M\'as a\'un se tiene $\langle C'\rangle=\langle C\rangle$.  
\end{prop}

\dem Sean $v_1,\ldots,v_n$ los elementos de $C$, enumerados de forma tal que $\{v_1,\ldots,v_m\}$ sea $C_0$. Definimos $m=0$ cuando $C_0=\emptyset$. Tenemos $m\le n$. Iteratívamente, para $i\in\{1,\ldots,n-m\}$, definimos
$$
C_i = \left\{ \begin{array}{rl}
C_{i-1}&\textrm{ si } v_{m+i}\in\langle C_{i-1}\rangle\\
C_{i-1}\cup\{v_{m+i}\} &\textrm{ si } v_{m+i}\not\in\langle C_{i-1}\rangle
\end{array}\right. .
$$
Por el lema anterior, la independencia lineal de $C_{i-1}$ implica la de $C_i$. Tome $C'=C_{n-m}$. En particular, $C'$ es linealmente independiente. Por construcci\'on, tenemos $C_0\subseteq C_1\subseteq\ldots\subseteq C_{n-m}= C'$. Para ver la maximalidad de $C'$, tomemos $j\in\{1,\ldots,n\}$. Si $v_j$ no pertenece a $C$, esto quiere decir que $v_j$ est\'a en $\langle C_{j-1}\rangle$, el cual es un subconjunto de $\langle C'\rangle$, y as\'i $C'\cup\{v_j\}$ es linealmente dependiente. Luego $C'\subset C$ es m\'aximal respecto a las propiedades de contener a $C_0$ y ser linealmente independiente. El mismo argumento demuestra la contenencia de $C$ en $\langle C'\rangle$, y la proposici\'on \ref{propunion}.2. implica que $\langle C\rangle\le\langle C'\rangle$. Para la contenencia opuesta, note que $C'\subseteq C$, y por lo tanto $\langle C'\rangle\le\langle C\rangle$, y así $\langle C'\rangle=\langle C\rangle$.\qed

\begin{teo}[Extensi\'on a una base]\label{extabase}
Suponga que $V$ tiene dimensi\'on finita. Si $\mathcal{B}_0$ es una familia finita de $V$ linealmente independiente, entonces existe una base $\mathcal{B}$ de $V$ que contiene a $\mathcal{B}_0$.
\end{teo}

\dem Como $V$ tiene dimensi\'on finita, existe una base finita $\mathcal{B}_1$ de $V$. Denote $C$ al conjunto $\mathcal{B}_0\cup \mathcal{B}_1$. Por la propiedad anterior, existe un subconjunto $\mathcal{B}$ de $C$ linealmente independiente maximal que contiene a $\mathcal{B}_0$. Tenemos $\langle \mathcal{B}\rangle=\langle C \rangle\ge\langle \mathcal{B}_1\rangle=V$. As\'i $\mathcal{B}$ forma una familia linealmente independiente que genera a $V$, y luego, por la proposici\'on \ref{defbase2}, $\mathcal{B}$ forma una base.\qed

\begin{lema}
Si $V$ tiene dimensi\'on infinita, entonces para todo entero $n\ge 1$, existe un subconjunto $C$ de $V$ linealmente independiente con $n$ elementos.
\end{lema}

\dem Hacemos inducci\'on en $n$. Como $V$ tiene dimensi\'on infinita, tenemos $V\ne\{O\}$, y as\'i, para cualquier $v\in V$ distinto de $O$, el conjunto $\{v\}$ es linealmente independiente y tiene $1$ elemento. Esto establece el caso base $n=1$. Para el paso inductivo, suponga que tenemos un subconjunto linealmente independiente $\{v_1,\ldots,v_n\}$ en $V$. Como $V$ tiene dimensi\'on infinita, $(v_1,\ldots,v_n)$ no es una base de $V$, luego tampoco lo genera y por ende existe $v_{n+1}\in V$ fuera de $\langle v_1,\ldots,v_n\rangle$. Por lo tanto, el lema \ref{inddep} implica que el conjunto $\{v_1,\ldots,v_n,v_{n+1}\}$ es linealmente independiente.\qed

\begin{teo}[Monoton\'ia de la dimensi\'on]\label{monodim}
Si $U$ es un subespacio de $V$, entonces tenemos $\dim U\le \dim V$. M\'as a\'un, si $V$ tiene dimensi\'on finita, entonces $\dim U=\dim V$ si y solo si $U=V$.
\end{teo}

\dem Suponga primero que $\dim(U)=\infty$. Asuma por contradicc\'on que $V$ tiene dimensi\'on finita. Por el lema anterior, existe una familia $\mathcal{B}_0$ de $U$ finita y linealmente independiente con $\dim(V)+1$ elementos. Por el teorema \ref{extabase} de extensión a una base, existe una base $\mathcal{B}_1$ de $V$ que extiende a $\mathcal{B}_0$. Luego, $V$ tiene una base con m\'as elementos que su dimensi\'on, contradiciendo el teorema \ref{basedim}. Por lo tanto, tenemos $\dim(V)=\infty$, y as\'i $\dim(U)\le\dim(V)$.\\
Suponga ahora que $U$ tiene dimensi\'on finita. Si $V$ tiene dimensi\'on infinita, obtenemos $\dim(U)\le\dim(V)$. Ahora asumamos que $V$ tiene dimensi\'on finita. Tome una base $\mathcal{B}_0$ de $U$, la cual, nuevamente por el teorema \ref{extabase}, podemos extender a una base $\mathcal{B}_1$ de $V$. Tenemos entonces $|\mathcal{B}_0|\le|\mathcal{B}_1|$, es decir $\dim(U)\le\dim(V)$.\\
Finalmente, suponga que $V$ tiene dimensi\'on finita. Evidentemente, si $U=V$, entonces $\dim U=\dim V$. Recíprocamente, si $\dim(U)=\dim(V)$, entonces toda base $\mathcal{B}_0$ de $U$ es tambi\'en una base de $V$. De hecho, ya vimos que una base de $U$ puede ser extendendida a una base de $V$, pero si esta extensi\'on contiene m\'as elementos, la dimensi\'on de $V$ ser\'ia mayor a la de $U$, contradiciendo la hip\'otesis $\dim(U)=\dim(V)$. Obtenemos as\'i $U=\langle \mathcal{B}_0\rangle=V$.\qed

\begin{obs}[Existencias de bases y dimensi\'on infinita]\label{basesinfty}
El teorema \ref{extabase} de extensión a una base se puede usar para demostrar que, partiendo de un conjunto vacio, todo espacio vectorial de dimensi\'on finita tiene una base. La cuesti\'on para dimensi\'on infinita toca la fibra de los fundamentos de la matem\'atica y, para demostrar la existencia de una base, requiere admitir el axioma de elecci\'on. Siendo m\'as precisos, usamos una versi\'on equivalente a este.
\begin{quote}
Lema de Zorn. Si $(P,\preccurlyeq)$ es un conjunto con un orden parcial en el que toda cadena admite una cota superior, entonces $P$ contiene al menos un elemento maximal.
\end{quote}
A partir de este axioma, suponga que $V$ tiene dimensi\'on infinita y tome un familia $\mathcal{B}_0$ de $V$ linealmente independiente. Sea $P$ el conjunto de familias de $V$ linealmente independientes que contienen a $\mathcal{B}_0$, el cual ordenamos por contenencia. Dada una cadena en $P$, la uni\'on de todos sus elementos tambi\'en est\'a en $P$ y es una cota superior de ella. Por el lema de Zorn, $P$ contiene un m\'aximal $\mathcal{B}_1$. Usando un argumento similar al del lema\ref{inddep}, se demuestra que $\mathcal{B}_1$ es una base de $V$. De hecho, si existe $v\in V$ fuera de $\langle \mathcal{B}_1\rangle$, con el conjunto $\mathcal{B}_1\cup\{v\}$ formamos una familia linealmente independiente que contiene estrictamente a $\mathcal{B}_1$ y a $\mathcal{B}_0$, contradiciendo la maximalidad de $\mathcal{B}_1$ en $P$.\\
De esta forma todo espacio vectorial tiene una base y a\'un m\'as, en cualquier espacio vectorial, todo conjunto linealmente independiente se puede extender a una.\\
Similarmente podemos extender la proposici\'on \ref{maximallinind} para concluir que si dentro de un subconjunto $C$ de $V$, tomamos un subconjunto $C_0$ linealmente independiente, entonces existe un subconjunto $C'$ de $C$ linealmente independiente m\'aximal que contiene a $C_0$, y para un tal $C'$ se tiene $\langle C\rangle=\langle C'\rangle$. De hecho, tomamos, usando Lema de Zorn, un m\'aximal $C'$ en la colecci\'on, ordenada por inclusi\'on, de subconjunto linealmente indpendientes de $C$ que contienen a $C_0$. El lema \ref{inddep} implica la igualdad $\langle C\rangle=\langle C'\rangle$.
\end{obs}

\section*{Ejercicios}

\begin{enumerate}
  \item Determine si el conjunto $\{(1,2), (1,3), (1,-1)\}$ es linealmente dependiente en $\mathbb{R}^2$, y en tal caso exprese un vector como combinación lineal de los otros.
  \item Determine si el conjunto $\{(1,2,3), (2,3,4), (3,4,5)\}$ es linealmente dependiente en $\mathbb{Q}^3$, y en tal caso exprese un vector como combinación lineal de los otros.
  \item Determine si el conjunto $\{(1,0,0,1), (1,0,1,0), (0,1,1,0), (0,1,0,1)\}$ es linealmente dependiente en $\mathbb{K}^4$, y en tal caso exprese un vector como combinación lineal de los otros.
  \item Encuentre una base del subespacio $\{(x,y,z)\in\mathbb{R}^3|2x+y-z=0,x-y=0\}$ de $\mathbb{R}^3$.
  \item Encuentre una base del subespacio $\{(x,y,z)\in\mathbb{R}^3|2x+y-z=0\}$ de $\mathbb{Q}^3$.
  \item Para cada uno de las siguientes conjuntos de vectores encuentre un subconjunto linealmente independiente maximal.
  \begin{enumerate}
  \item $\big\{(1,0,-2,1),(0,-1,1,1),(-1,2,1,0),(2,1,-4,4)\big\}\subseteq\mathbb{Q}^4$
  \item $\big\{(1,0,-2,1),(0,-1,1,1),(-1,2,1,0),(2,1,2,-2)\big\}\subseteq\mathbb{Q}^4$
  \item $\big\{(1,-1,5,-8,6),(-1,1,-5,5,-3),(1,0,3,-3,5),(2,3,4,-1,1),(0,1,0,-1,2)\big\}\subseteq\mathbb{Q}^5$
  \item $\big\{(1,-1,5,-8,6),(-1,1,-5,5,-3),(1,0,3,-3,5),(2,1,4,8,0)\big\}\subseteq\mathbb{Q}^5$
  \item $\big\{(1,1,0,0,0,0),(0,0,1,1,0,0),(0,0,0,0,1,1),(1,0,1,0,1,0),(0,1,0,1,0,1)\big\}\subseteq\mathbb{Q}^6$
  \end{enumerate}
\end{enumerate}

\section{Transformaciones lineales}

Sean $U$, $V$ y $W$ espacios vectoriales sobre $\mathbb{K}$.

\begin{defn}\label{deftrli}
Sea $f:V\rightarrow W$ una funci\'on. Decimos que $f$ es una \emph{transformaci\'on lineal} (o un \emph{morfismo de espacios vectoriales}) si satisface las siguientes propiedades.
\begin{enumerate}[(i)]
\item \emph{Preserva sumas}: Para todo $v_1,v_2\in V$ se tiene $f(v_1+v_2)=f(v_1)+f(v_2)$.
\item \emph{Preserva productos por escalar}: Para todo $c\in \mathbb{K}$ y todo $v\in V$ se tiene $f(cv)=cf(v)$. 
\end{enumerate}
Al conjunto de transformaciones lineales de $V$ en $W$ lo denotamos por $\Hom_{\mathbb{K}}(V,W)$. A las transformaciones lineales de un espacio en \'el mismo las llamamos \emph{operadores} (o \emph{endomorfismos de espacios vectoriales}). Al conjunto $\Hom_{\mathbb{K}}(V,V)$ de operadores de $V$ lo denotamos por $\End_{\mathbb{K}}(V)$.
\end{defn}

\begin{ejem}
\begin{enumerate}[(i)]
\item \emph{Transforaci\'on lineal cero}: La funci\'on $\underline{O}:V\rightarrow W$ definida por $\underline{O}(v)=O$ para todo $v$ es una transformaci\'on lineal.
\item \emph{Operador identidad}: La funci\'on $\id_V:V\rightarrow V$ definida por $\id_V(v)=v$ para todo $v$ es un operador.
\end{enumerate}  
\end{ejem}

\begin{prop}\label{proptrlinbasicas}
Para toda $f\in\Hom_{\mathbb{K}}(V,W)$ se tiene
\begin{enumerate}[(i)]
\item $f(O)=O$,
\item $f(-v)=-f(v)$ para todo $v\in V$, y
\item $f(c_1v_1+\cdots+c_nv_n)=c_1f(v_1)+\cdots+c_nf(v_n)$ para todo $c_1,\ldots,c_n\in K$ y todo $v_1,\ldots,v_n\in V$.
\end{enumerate}
\end{prop}

\dem 
\begin{enumerate}[(i)]
\item Tenemos $f(O)=f(0O)=0f(O)=O$.
\item Dado $v\in V$, se tiene $f(v)+f(-v)=f\left(v+(-v)\right)=f(O)=O$, y as\'i, por la unicidad del opuesto, $f(-v)=-f(v)$.
\item Usaremos inducci\'on en $n$, siendo el caso base, $n=2$, cierto por el axioma (ii) en la definici\'on \ref{deftrli} de transformaci\'on lineal. Ahora, si asumimos que la propiedad es cierta para $n$, entonces para todo $c_1,\ldots,c_{n+1}\in K$ y todo $v_1,\ldots,v_{n+1}\in V$ tenemos
\begin{align*}
f(c_1v_1+\cdots+c_nv_n+c_{n+1}v_{n+1})& = f(c_1v_1+\cdots+c_nv_n)+f(c_{n+1}v_{n+1})\\
  & = c_1f(v_1)+\cdots+c_nf(v_n)+c_{n+1}f(v_{n+1}).
\end{align*}
Por lo tanto, es cierto para $n+1$ y la propiedad se sigue por inducci\'on.
\end{enumerate}\qed

\begin{obs}
Dados $f,g\in\Hom_{\mathbb{K}}(V,W)$ y $c\in K$ definimos las transformaciones lineales $f+g$ y $cg$ en $\Hom_K(V,W)$ por $(f+g)(v)=f(v)+g(v)$ y $(cg)(v) = cg(v)$ para todo $v\in V$. El conjunto $\Hom_{\mathbb{K}}(V,W)$ junto con estas operaciones y el origen dado por $\underline{O}$ es un espacio vectorial sobre $\mathbb{K}$.
\end{obs}

\begin{prop}\label{compeslineal}
Si $f\in\Hom_{\mathbb{K}}(V,W)$ y $g\in\Hom_{\mathbb{K}}(W,U)$, entonces $(g\circ f)\in\Hom_{\mathbb{K}}(V,U)$.
\end{prop}

\dem Para todo $u,v\in V$ tenemos
\[
g\circ f(u+v)=g\left( f(u)+f(v)\right)= g\circ f(u)+g\circ f(v).
\]
Para todo $v\in V$ y todo $c\in \mathbb{K}$, tenemos
\[
g\circ f(cv)=g\left( c f(v)\right)=cg\circ f(v).
\]
\qed

\begin{prop}[Rigidez de las transformaciones lineales]\label{unitrlin}
Sean $v_1,\ldots,v_n\in V$ tales que $\langle v_1,\ldots,v_n\rangle=V$. Si $w_1,\ldots,w_n$ son elementos en $W$, entonces tenemos las siguientes dos propiedades.
\begin{enumerate}[(i)]
\item Existe a lo sumo una transformaci\'on lineal $f\in\Hom_{\mathbb{K}}(V,W)$ tal que $f(v_i)=w_i$, para $i\in\{1,\ldots,n\}$.
\item Si $\{v_1,\ldots,v_n\}$ es linealmente independiente, entonces existe una transformaci\'on $f\in\Hom_{\mathbb{K}}(V,W)$ tal que $f(v_i)=w_i$, para $i\in\{1,\ldots,n\}$.
\end{enumerate}
\end{prop}

\dem
\begin{enumerate}[(i)]
\item Considere dos transformaciones lineales $f,g\in\Hom_{\mathbb{K}}(V,W)$ tales que $f(v_i)=w_i=g(v_i)$, para $i\in\{1,\ldots,n\}$. Dado $v\in V$, existen $c_1,\ldots,c_n\in \mathbb{K}$ para los cuales $v=c_1v_1+\cdots+c_nv_n$ y así 
\[
f(v)=f\left(\sum_{i=1}^nc_iv_i\right)=\sum_{i=1}^nc_if(v_i)=\sum_{i=1}^nc_iw_i=\sum_{i=1}^nc_ig(v_i)=g(v).
\]
Por lo tanto $f=g$.
\item Si $\{v_1,\ldots,v_n\}$ es linealmente independiente, por la proposici\'on \ref{defbase2}, se sigue que $(v_1,\ldots,v_n)$ es una base de $V$. Dado $v\in V$, existe un \'unico elemento $(c_1,\ldots, c_n)\in \mathbb{K}^n$ para el que se tiene $v=c_1v_1+\cdots+c_nv_n$. Defina la funci\'on $f:V\rightarrow W$ por
\[
f(v)=c_1w_1+\cdots+c_nw_n.
\]
Veamos que $f$ es una transformaci\'on lineal. Dados $u,v\in V$, para $(a_1,\ldots, a_n)$ y $(b_1,\ldots, b_n)$ en $\mathbb{K}^n$ tales que $u=a_1v_1+\cdots+a_nv_n$ y $v=b_1v_1+\cdots+b_nv_n$, obtenemos $u+v =  (a_1+b_1)v_1+\cdots+(a_n+b_n)v_n$ y
\begin{eqnarray*}
f(u+v) & = & (a_1+b_1)w_1+\cdots+(a_n+b_n)w_n\\
     & = & a_1w_1+\cdots+a_nw_n+ b_1w_1+\cdots+b_nw_n\\
     & = & f(u)+f(v).
\end{eqnarray*} 
Luego, $f$ respecta sumas.
Dado $v\in V$, si se tiene $v=c_1v_1+\cdots+c_nv_n$ con $(c_1,\ldots, c_n)\in \mathbb{K}^n$, entonces, para todo $c\in \mathbb{K}$, $cv = (ca_1)v_1+\cdots+(ca_n)v_n$ y
\begin{eqnarray*}
f(cv_1) & = & (ca_1)w_1+\cdots+(ca_n)w_n\\
     & = & c(a_1w_1+\cdots+a_nw_n)\\
     & = & cf(v_1)
\end{eqnarray*}
Por lo tanto, $f$ tambi\'en respecta productos por escalar y se sigue que $f$ es una transformaci\'on lineal.
\end{enumerate}\qed

\begin{prop}
Sea $f\in\Hom_{\mathbb{K}}(V,W)$. Si $f$ es biyectiva, entonces $f^{-1}$ es una transformaci\'on lineal. 
\end{prop}

\dem Sean $w_1,w_2\in W$. Como $f$ es sobreyectiva, tenemos $f(v_1)=w_1$ y $f(v_2)=w_2$ para algunos $v_1,v_2\in V$ y, as\'i, $f(v_1+v_2)=f(v_1)+f(v_2)=w_1+w_2$. Se sigue que
\[
f^{-1}(w_1+w_2)=f^{-1}\left(f(v_1+v_2)\right)=v_1+v_2,
\] 
y
\[
f^{-1}(w_1)+f^{-1}(w_2)=f^{-1}\left(f(v_1)\right)+f^{-1}\left(f(v_2)\right)=v_1+v_2.
\]
Luego, para todo $w_1,w_2\in W$ tenemos $f^{-1}(w_1+w_2)=f^{-1}(w_1)+f^{-1}(w_2)$.\\
Sea $w\in W$. Dado $v\in V$ tal que $f(v)=w$, vemos que $f(cv)=cf(v)=cw$ para todo $c\in \mathbb{K}$. Por ende,
\[
f^{-1}(cw)=f^{-1}\left(f(cv)\right)=cv,
\]
y
\[
cf^{-1}(w)=cf^{-1}\left(f(v)\right)=cv.
\]
Luego, para todo $w\in W$ y todo $c\in \mathbb{K}$ se tiene que $f^{-1}(cw)=cf^{-1}(w)$. Por lo tanto, $f^{-1}$ respeta sumas y productos por escalar, y por consiguiente $f^{-1}$ es una transformaci\'on lineal.

\begin{defn}
Sea $f\in\Hom_{\mathbb{K}}(V,W)$. Si $f$ es una biyecci\'on, entonces decimos que $f$ es un \emph{isomorfismo}. Si existe un isomorfismo $f\in\Hom_{\mathbb{K}}(V,W)$ decimos que $V$ y $W$ son \emph{isomorfos} y lo denotamos por $V\simeq_{\mathbb{K}} W$.
\end{defn}

\begin{ejem} Suponga que $V$ es unidimensional. Dado $\lambda\in \mathbb{K}$, la funci\'on $f:V\rightarrow V$ definida por $f(v)=\lambda v$ para todo $v$ es una transformaci\'on lineal. Rec\'iprocamente, si $f:V\rightarrow V$ es un transformaci\'on lineal, existe $\lambda\in \mathbb{K}$ tal que $f(v)=\lambda v$ para todo $v$. De hecho, si $v_0\ne 0$ entonces $V=\langle v_0\rangle$ as\'i $f(v_0)=\lambda v_0$ para alg\'un $\lambda\in \mathbb{K}$. Ahora, dado cualquier $v\in V$ existe $c\in \mathbb{K}$ tal que $cv_0=v$, y tenemos que
\[
f(v)=cf(v_0)=c\lambda v_0=\lambda cv_0=\lambda v.
\]
Entonces, si $\Phi: \mathbb{K} \rightarrow \End_{\mathbb{K}}(V)$ es la funci\'on definida por $\Phi(\lambda)=m_\lambda$, con $m_\lambda$ definida por $m_\lambda(v)=\lambda v$ para todo $v\in V$, vemos que $\Phi$ es un isomorfismo y $\End_{\mathbb{K}}(V)\simeq_{\mathbb{K}} \mathbb{K}$.
\end{ejem}

\begin{defn}
Sea $f\in\End_{\mathbb{K}}(V)$. Si $f$ es una biyecci\'on, entonces decimos que $f$ es un \emph{automorfismo}. Al conjunto de automorfismos de $V$ lo denotamos por $\GL_{\mathbb{K}}(V)$.
\end{defn}

\begin{teo}
Si que $V$ y $W$ tienen dimensi\'on finita, entonces $V\simeq_{\mathbb{K}} W$ si y solo si $\dim(V)=\dim(W)$.
\end{teo}

\dem Primero establecemos la necesidad. Suponga que $V\simeq_{\mathbb{K}} W$, luego existe un isomorfismo $f\in\Hom_{\mathbb{K}}(V,W)$. Tome $(v_1,\ldots,v_n)$ una base de $V$, donde $n=\dim(V)$. Para $i\in\{1,\ldots,n\}$, defina $w_i=f(v_i)$. Veamos que $(w_1,\ldots,w_n)$ es base de $W$, y así obtener que $\dim(W)=n=\dim(V)$. Si $c_1,\ldots,c_n\in \mathbb{K}$ son tales que $c_1w_1+\cdots+c_nw_n=O$, entonces
\[
f(c_1v_1+\cdots+c_nv_n)=c_1f(v_1)+\cdots+c_nf(v_n)=c_1w_1+\cdots+c_nw_n=O.
\]
Como $f$ es inyectiva y $f(O)=O$, se sigue que $c_1v_1+\cdots+c_nv_n=O$, pero al ser $\{v_1,\ldots,v_n\}$ linealmente independiente, entonces $c_1=\ldots=c_n=0$. De esta forma, el conjunto $\{w_1,\ldots,w_n\}$ es linealmente independiente. Veamos ahora que es un conjunto generador. Sea $w\in W$. Como $f$ es sobreyectiva, existe $v\in V$ tal que $f(v)=w$. Como $\{v_1,\ldots,v_n\}$ genera $V$, existen $c_1,\ldots,c_n\in \mathbb{K}$ tales que $v=c_1v_1+\cdots+c_nv_n$. Luego
\[
w=f(v)=f(c_1v_1+\cdots+c_nv_n)=c_1f(v_1)+\cdots+c_nf(v_n)=c_1w_1+\cdots+c_nw_n.
\]
De donde $W=\langle w_1,\ldots,w_n\rangle$ y as\'i $(w_1,\ldots,w_n)$ es una base de $W$. Con esto completamos la prueba de la necesidad.\\
Ahora establecemos la suficiencia. Suponga que $\dim(V)=\dim(W)=n$ y tome dos base $(v_1,\ldots,v_n)$ y $(w_1,\ldots,w_n)$ respectivamente de $V$ y $W$. Por la proposici\'on \ref{unitrlin}.(ii), existe $f\in\Hom(V,W)$ tal que $f(v_i)=w_i$, para $i\in\{1,\ldots,n\}$. La prueba estar\'a completa cuando establezcamos que $f$ es biyectiva. Sean $u,v\in V$ tales que $f(u)=f(v)$. Existen $(a_1,\ldots,a_n)$ y $(b_1,\ldots,b_n)$ en $\mathbb{K}^n$ tales que $u=a_1v_1+\cdots+a_nv_n$ y $v=b_1v_1+\cdots+b_nv_n$. Como $f(u-v)=f(u)-f(v)=O$ y
\[
u-v=(a_1-b_1)v_1+\cdots+(a_n-b_n)v_n,
\]
entonces
\[
O=f(u-v)=(a_1-b_1)w_1+\cdots+(a_n-b_n)w_n.
\]
La independencia lineal de $\{w_1,\ldots,w_n\}$ implica que, para $i\in\{1,\ldots,n\}$, $a_i-b_i=0$, o equivalentemente, $a_i=b_i$. De esta forma tenemos que $u=v$ y se sigue que $f$ es inyectiva. Sea $w\in W$ y sea $(c_1,\ldots, c_n)\in \mathbb{K}^n$ tal que $w=c_1w_1+\cdots+c_nw_n$. Al tomar $v=c_1v_1+\cdots+c_nv_n$, se obtiene
\[
f(v)=f(c_1v_1+\cdots+c_nv_n)=c_1f(v_1)+\cdots+c_nf(v_n)=c_1w_1+\cdots+c_nw_n=w.
\]
Por lo cual, $f$ es sobreyectiva. Al ser inyectiva y sobreyectiva, $f$ es biyectiva.\qed

\begin{defn}
Sea $f\in\Hom_{\mathbb{K}}(V,W)$.
\begin{enumerate}[(i)]
\item El \emph{n\'ucleo} (o el \emph{kernel}) de $f$ es el conjunto $\{v\in V|\ f(v)=O\}$ y lo denotamos por $\ker(f)$.
\item La \emph{imagen} de $f$ es el conjunto $\{w\in W|\ \exists v\in V: f(v)=w\}$ y la denotamos por
$\im(f)$.
\end{enumerate}
\end{defn}

\begin{prop}
Sea $f\in\Hom_{\mathbb{K}}(V,W)$, entonces $\ker(f)$ e $\im(f)$ son respectivamente subespacios de $V$ y $W$.
\end{prop}

\dem Para la demostración, mostramos que los dos conjuntos contienen al origen y son cerrados mediate suma y producto por escalar. Como $f(O)=O$, entonces $O\in\ker(f)$ y $O\in\im(f)$. Para todo $v_1,v_2\in \ker(f)$, tenemos $f(v_1+v_2)=f(v_1)+f(v_2)=O+O=O$ y  as\'i $u+v\in\ker(f)$. Para todo $v\in \ker(f)$ y todo $c\in \mathbb{K}$, $f(cv)=cf(v)=cO=O$ y as\'i $cv\in\ker(f)$. Luego, de la propiedad \ref{subespsiysolosi}, se sigue que $\ker(f)$ es un subespacio de $V$. Para todo $w_1,w_2\in \im(f)$ existen $v_1,v_2\in V$ tales que $f(v_1)=w_1$ y $f(v_2)=w_2$. Luego $f(v_1+v_2)=f(v_1)+f(v_2)=w_1+w_2$ y as\'i $w_1+w_2\in\im(f)$. Para todo $w\in\im(f)$ existe $v\in V$ tal que $f(v)=w$. Luego, para todo $c\in \mathbb{K}$, $f(cv)=cf(v)=cw$ y as\'i $cw\in\im(f)$. Luego, de la propiedad \ref{subespsiysolosi}, se sigue que $\im(f)$ es un subespacio de $V$.\qed

\begin{prop}\label{inyectiva}
Sea $f\in\Hom_{\mathbb{K}}(V,W)$, entonces $f$ es inyectiva si y solo si $\ker(f)=\{O\}$.
\end{prop}

\dem Suponga primero que $f$ es inyectiva, entonces, como $f(O)=O$, tenemos $\ker(f)=\{O\}$. Suponga ahora que $\ker(f)=\{O\}$. Si $u,v\in V$ son tales que $f(u)=f(v)$, entonces
\[
f(u-v)=f(u)-f(v)=O,
\]
De donde $u-v\in\ker(f)$, luego $u-v=O$, o equivalentemente $u=v$, y as\'i ,$f$ es inyecta.\qed

\begin{defn}
Suponga que $V$ tiene dimensi\'on finita. Sea $f\in\Hom_{\mathbb{K}}(V,W)$.
\begin{enumerate}[(i)]
\item La \emph{nulidad} de $f$, que denotamos $\nu(f)$ es la dimensi\'on de $\ker(f)$.
\item El \emph{rango} de $f$, que denotamos $\rho(f)$ es la dimensi\'on de $\im(f)$.
\end{enumerate}
\end{defn}

\begin{teo}[Teorema del rango]\label{teorango}
Suponga que $V$ tiene dimensi\'on finita. Para todo $f\in\Hom_{\mathbb{K}}(V,W)$, se tiene
\[
\nu(f)+\rho(f)=\dim (V)
\]
\end{teo}

\dem Note que para el caso $\rho(f)=0$ el teorema se sigue inmediatamente. Asumamos que $\rho(f)>0$. Como $\ker(f)\le V$, por la monoton\'ia de la dimensi\'on tenemos $\nu(f)=\dim\left(\ker(f)\right)\le\dim(V)$. Sean $n=\nu(f)$ y $n+m=\dim (V)$. Sea $\mathcal{B}_0=(v_1,\ldots,v_n)\subseteq V$ una base de $\ker(f)$ (si $n=0$ tomamos $\mathcal{B}_0=\emptyset$). Extendemos $\mathcal{B}_0$ a una base $\mathcal{B}=(v_1,\ldots,v_n,v_{n+1},\ldots,v_{n+m})$ de $V$.\\
Para $i\in\{1,\ldots,m\}$, defina $w_i=f(v_{n+i})$. Basta demostrar que $\{w_1,\ldots,w_m\}$ es una base de $\im(f)$, pues en tal caso tendr\'iamos que $m=\dim\left(im(f)\right)=\rho(f)=\dim (V)-\nu(f)$. Para establecerlo usaremos la proposici\'on \ref{defbase2}.\\
Veamos primero que $\{w_1,\ldots,w_m\}$ es linealmente independiente. Suponga que $a_1,\ldots,a_m\in \mathbb{K}$ son tales que
\[
a_1w_1+\cdots+a_mw_m=O.
\]
Luego, si $v=a_1v_{n+1}+\cdots+a_mv_{n+m}$, entonces
\[
f(v)=a_1f(v_{n+1})+\cdots+a_mf(v_{n+m})=a_1w_1+\cdots+a_mw_m=O,
\]
y as\'i $v\in\ker(f)$. Pero como $\langle v_1,\ldots,v_n\rangle=\ker(f)$, entonces existe $(b_1,\ldots,b_n)\in \mathbb{K}^n$ tal que
\[
v=b_1v_1+\cdots+b_nv_n
\]
es decir que $b_1v_1+\cdots+b_nv_n=v=a_1v_{n+1}+\cdots+a_mv_{n+m}$ y as\'i
\[
O=(-b_1)v_1+\cdots+(-b_n)v_n+a_1v_{n+1}+\cdots+a_mv_{n+m}.
\]
Por ende, como $\{v_1,\ldots,v_n,v_{n+1},\ldots,v_{n+m}\}$ es linealmente independiente, la igualdad anterior implica que $a_1=\ldots=a_m=0$ y la independencia lineal de $\{w_1,\ldots,w_m\}$ se sigue ahora de la  proposici\'on \ref{proplinind}.\\
Veamos que  $\{w_1,\ldots,w_m\}$ genera a $im(f)$ y con eso completamos la prueba. Como $w_1,\ldots,w_m\in \im(f)$ entonces $\langle w_1,\ldots,w_m\rangle\subseteq\im(f)$. Basta entonces establecer la otra inclusi\'on. Dado $w\in\im(f)$, existe $v\in V$ tal que $f(v)=w$. Sean $c_1,\ldots,c_n,c_{n+1},\ldots,c_{n+m}\in \mathbb{K}$ tales que 
\[
v=c_1v_1+\cdots+c_nv_n+c_{n+1}v_{n+1}+\cdots+c_{n+m}v_{n+m},
\]
de forma que
\begin{eqnarray*}
w=f(v) & = & f(\underbrace{c_1v_1+\cdots+c_nv_n}_{\in\ \ker(f)})+c_{n+1}f(v_{n+1})+\cdots+c_{n+m}f(v_{n+m})\\
           & = & c_{n+1}w_1+\cdots+c_{n+m}w_m,
\end{eqnarray*}
y as\'i $w\in\langle w_1,\ldots,w_m\rangle$. De donde $\im(f)\subseteq\langle w_1,\ldots,w_m\rangle$.\qed

\begin{coro}\label{corteorango}
Suponga que $V$ tiene dimensi\'on finita y sea $f\in\Hom_{\mathbb{K}}(V,W)$. Entonces las siguientes dos propiedades son equivalentes:
\begin{enumerate}[(i)]
\item $\nu(f)=0$
\item $\rho(f)=\dim(V)$
\end{enumerate}
\end{coro}

\dem Se sigue inmediatamente del teorema del rango.

\section*{Ejercicios}

\begin{enumerate}
  \item Demuestre que la función $f:\mathbb{K}^2\rightarrow\mathbb{K}^3$ dada por $f(x,y)=(x+2y,2x-y,x+y)$ es una transformación lineal. Asuma que $\chara(K)\ne 2$.
  \item ¿Existe alguna transformación lineal $f$ de $\mathbb{Q}^2$ en $\mathbb{Q}^3$ tal que $f(1,-2)=(1,1,1)$ y $f(-2,4)=(1,-1,-1)$?
  \item ¿Cuántas transformaciones lineales $f$ de $\mathbb{Q}^2$ en $\mathbb{Q}^3$ existen tales que $f(1,1)=(3,2,4)$ y $f(1,2)=(1,1,1)$? Calcule $f(0,1)$ y $f(1,0)$ para estas transformaciones.
  \item Sea $f:V\rightarrow W$ una transformación lineal, con $\dim_\mathbb{K}(V)=\dim_\mathbb{K}(W)$. Demuestre que $f$ es inyectiva si y solo si es sobreyectiva.
  \item Considere las funciones $d:\mathbb{R}[t]\rightarrow\mathbb{R}[t]$ e $i:\mathbb{R}[t]\rightarrow\mathbb{R}[t]$ dadas por:
  $$d(P(t))=\dfrac{d}{dt}P(t)\qquad i(P(t))=\int_0^tP(x)dx.$$
  Demuestre que $d$ e $i$ son transformación lineales de espacios vectoriales sobre $\mathbb{R}$. Demuestre además que $d$ es sobreyectiva pero no inyectiva, y que $i$ es inyectica pero no sobreyectiva.
  \item Para cada una de las siguientes transformaciones lineales, encuentre una base del núcleo y del rango.
    \begin{enumerate}
      \item $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^3,\mathbb{Q}^3)$ dada por $f(x,y,z)=(3x-3y-z,-y-4z,5x-7y+2z)$.
      \item $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^4,\mathbb{Q}^4)$ dada por $f(x,y,z,w)=(x-y+z+w,-x-y-z,2x-y-2z-w,2x-y-z)$.
      \item $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^2,\mathbb{Q}^3)$ dada por $f(x,y)=(y,x,-x)$.
      \item $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^2,\mathbb{Q}^3)$ dada por $f(x,y)=\dfrac{1}{2}(x+y,x+y,-x-y)$.
      \item $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^2,\mathbb{Q}^4)$ dada por $f(x,y)=\dfrac{1}{3}(2y,2y,3x-y,-3x-y)$.
      \item $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^3,\mathbb{Q}^4)$ dada por $f(x,y)=\dfrac{1}{3}(2x+y+z,2x+y+z,-x+y-2z,-x-2y+z)$.
    \end{enumerate}
\end{enumerate}

\section{Matrices y vectores de coordenadas}

Sea $\mathbb{K}$ un cuerpo. Denotaremos por $m,n,r,s$ cuatro enteros estrictamente positivos y por $[m]$ y $[n]$ los conjuntos $\{1,\ldots,m\}$ y $\{1,\ldots,n\}$.

\begin{defn}
Una \emph{matriz $m\times n$ sobre $\mathbb{K}$} (o una \emph{matriz $m\times n$ con entradas en $\mathbb{K}$}) es una familia $A$ de escalares indexada por $[m]\times [n]$, es decir $A\in \mathbb{K}^{[m]\times [n]}$. Si $a_{ij}=A(i,j)$, para $(i,j)\in [m]\times [n]$, denotaremos $A=(a_{ij})$ \'o
$$ A=\left[\begin{array}{ccc}
a_{11} & \cdots & a_{1n}\\
\vdots & \ddots & \vdots\\
a_{m1} & \cdots & a_{mn}
\end{array}\right].$$
y llamaremos a $a_{ij}$ la entrada $ij$ de $A$. La fila $i$ de $A$ es la matrix $1\times n$
$$\left[a_{i1}\ldots a_{in}\right]$$
y la columna $j$ de $A$ es la matrix $m\times 1$,
$$ \left[\begin{array}{c}
a_{1j}\\
\vdots\\
a_{mj}
\end{array}\right].$$

El conjunto $M_{m\times n}(\mathbb{K})$ de matrices $m\times n$ sobre $\mathbb{K}$ es el espacio vectorial $\mathbb{K}^{[m]\times [n]}$ (ver el ejemplo \ref{ejem0}(iv)).
\end{defn}

\begin{defn}
Un \emph{vector de $n$ coordenadas sobre $\mathbb{K}$}  (o un \emph{vector de $n$ coordenadas con entradas en $\mathbb{K}$}) es una matriz $n\times 1$. Si $\overline{x}\in M_{n\times 1}(\mathbb{K})$ es tal que $\overline{x}(i,1)=x_i$, para $i\in\{1,\ldots,n\}$, entonces denotaremos $\overline{x}=(x_i)$ \'o
$$ \overline{x}=\left[\begin{array}{c}
x_{1}\\
\vdots\\
x_{n}
\end{array}\right]$$
y llamamos a $x_i$ la coordenada $i$ de $\overline{x}$. Para simplificar, denotaremos $\overline{x}(i,1)$ por $\overline{x}(i)$.
\end{defn}

\begin{defn}
Sean $A$ y $B$ respectivamente matrices $m\times n$ y $n\times r$. Definimos el \emph{producto de $A$ y $B$}, que denotamos por $AB$, como la matriz $m\times r$ cuya entrada $ij$ es
$$\sum_{k=1}^n a_{ik}b_{kj}=a_{i1}b_{1i}+\cdots+a_{in}b_{nj}.$$
\end{defn}

\begin{prop}
La multiplicaci\'on matricial satisface las siguientes propiedades.
\begin{enumerate}[(i)]
\item \emph{Commutatividad con escalares}: Para $c\in \mathbb{K}$, $A\in M_{m\times n}(\mathbb{K})$ y $B\in M_{n\times r}(\mathbb{K})$ cualesquiera se tiene $A(cB)=cAB=(cA)B$.
\item \emph{Distributividad}: Para $A\in M_{m\times n}(\mathbb{K})$ y $B,C\in M_{n\times r}(\mathbb{K})$ cualesquiera se tiene $A(B+C)=AB+AC$.
\item \emph{Asociatividad}: Para $A\in M_{m\times n}(\mathbb{K})$, $B\in M_{n\times r}(\mathbb{K})$ y $C\in M_{r\times s}(\mathbb{K})$ cualesquiera se tiene $A(BC)=(AB)C$.
\end{enumerate}
\end{prop}

\dem Sean $A=(a_{ij})$, $B=(b_{jk})$ y $C=(c_{kl})$.
\begin{enumerate}[(i)]
\item La entrada $ij$ de $A(cB)$ es
$$\sum_{k=1}^n a_{ik}cb_{kj}=c\sum_{k=1}^n a_{ik}b_{kj}=\sum_{k=1}^n ca_{ik}b_{kj},$$
y es igual a la entrada $ij$ de $cAB$ y de $(cA)B$.
\item La entrada $ij$ de $A(B+C)$ es
$$\sum_{k=1}^n a_{ik}(b_{kj}+c_{kj})=\sum_{k=1}^n a_{ik}b_{kj}+\sum_{k=1}^n a_{ik}c_{kj},$$
y es igual a la entrada $ij$ de $AB+AC$.
\item La entrada $ij$ de $A(BC)$ es
$$\sum_{l=1}^n a_{il}\left(\sum_{k=1}^r b_{lk}c_{kj}\right) = \sum_{k=1}^r\sum_{l=1}^n a_{il}b_{lk}c_{kj} = \sum_{k=1}^r\left(\sum_{l=1}^n a_{il}b_{lk}\right)c_{kj},$$
y es igual a la entrada $ij$ de $(AB)C$.
\end{enumerate}
\qed

\begin{defn}
La \emph{matriz identidad $n\times n$} es la matriz $I_n\in M_{n\times n}(\mathbb{K})$ cuya entrada $ij$ es $1$ cuando $i=j$ y $0$ cuando $i\ne j$. En particular tenemos
$$I_n=\left[\begin{array}{ccc}
1 & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & 1
\end{array}\right]$$
e $I_n=(\delta_{ij})$ donde definimos $\delta_{ij}=1$ cuando $i=j$ y $\delta_{ij}=0$ cuando $i\ne j$. La funci\'on $\delta\in \mathbb{K}^{[n]\times [n]}$ definida por $\delta(i,j)=\delta_{ij}$ se llama \emph{la funci\'on delta de Kronecker}.  
\end{defn}

\begin{prop}
Para toda matriz $A\in M_{m\times n}(\mathbb{K})$, se tiene $I_mA=A=AI_n$.
\end{prop}

\dem Si $a_{ij}$ es la entrada $ij$ de $A$, entonces la entrada $ij$ de $I_mA$ es $\sum_{k=1}^m \delta_{ik}a_{kj}=a_{ij}$ y la de $AI_n$ es $\sum_{k=1}^na_{ik}\delta_{kj}=a_{ij}$. \qed

\begin{defn}
Sea $A\in M_{n\times n}(\mathbb{K})$. Decimos que $A$ es una \emph{matriz invertible} si existe una matriz $A^{-1}\in M_{n\times n}(\mathbb{K})$ para la cual se tiene $AA^{-1}=I_n=A^{-1}A$. En tal caso, llamamos a $A^{-1}$ \emph{la matriz inversa de $A$} y decimos que $A$ es \emph{invertible}.
\end{defn}

\begin{prop}[Unicidad de la inversa]
Sea $A\in M_{n\times n}(\mathbb{K})$ una matriz invertible. Si $B\in M_{n\times n}$ es tal que $BA=I_n$ \'o $AB=I_n$ entonces $B=A^{-1}$.
\end{prop}

\dem Si $BA$ es igual a $I_n$, entonces tenemos $B=BI_n=B(AA^{-1})=(BA)A^{-1}=I_nA^{-1}=A^{-1}$. Similarmente se establece $B=A^{-1}$ cuando $AB$ es igual a $I_n$.\qed

\subsection*{Matrices de transformaciones}

Sean $V$, $W$ y $U$ espacios vectoriales sobre $\mathbb{K}$ de dimensi\'on finita, $n$, $m$ y $r$ sus respectivas dimensiones. Fijamos una base $\mathcal{B}_V=(v_1,\ldots,v_n)$, $\mathcal{B}_W=(w_1,\ldots,w_m)$ y $\mathcal{B}_U=(u_1,\ldots,u_r)$ de cada uno de estos tres espacios.

\begin{defn}
Dado $v\in V$, sean $c_1,\ldots,c_n\in \mathbb{K}$ tales que
$$c_1v_1+\cdots+c_nv_n.$$
El \emph{vector de coordenadas de $v$ en la base $\mathcal{B}_V$} es el vector de $n$ coordenadas 
$$\Big[ v \Big]^{\mathcal{B}_V}=\left[\begin{array}{c}
  c_{1}\\
  \vdots\\
  c_{n}
  \end{array}\right]$$.
\end{defn}

\begin{prop}
La funci\'on
\begin{eqnarray*}
\Big[ \bullet \Big]^{\mathcal{B}_V}: V & \longrightarrow & \mathbb{K}^{[n]}\\
v & \longmapsto & \Big[ v \Big]^{\mathcal{B}_V}
\end{eqnarray*}
es un isomorfismo.
\end{prop}

\dem Tenemos $\left[ v \right]^{\mathcal{B}_V}=O$ si y solo si $v=O$, as\'i la proposici\'on se sigue del corolario \ref{corteorango} del teorema del rango. 

\begin{defn}
Dada $f\in\Hom_{\mathbb{K}}(V,W)$, para $i\in\{1,\ldots,m\}$ y $j\in\{1,\ldots,n\}$, definimos $a_{ij}\in \mathbb{K}$ tal que
$$f(v_j)=a_{1j}w_1+\cdots+a_{mj}w_m.$$
La \emph{matriz de $f$ para las bases $\mathcal{B}_V$ y $\mathcal{B}_W$} es la matrix $m\times n$ cuya entrada $ij$ es $a_{ij}$, la cual denotamos $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$.
\end{defn}

\begin{obs}
\begin{enumerate}[(i)]
  \item La columna $j$ de $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$ es el vector de coordenadas $\Big[f(v_j)\Big]^{\mathcal{B}_W}$, en particular tenemos 
$$\Big[f\Big]^{\mathcal{B}_W}_{\mathcal{B}_V}=\Bigg[\Big[ f(v_1)\Big]^{\mathcal{B}_W}\Big|\cdots \Big| \Big[ f(v_n)\Big]^{\mathcal{B}_W}\Bigg]$$
  y $\Big[\id_V\Big]^{\mathcal{B}_V}_{\mathcal{B}_V}=I_n$.
  \item Cuando $V$ y $W$ son los espacios $\mathbb{K}^n$ y $\mathbb{K}^m$ matriz para las bases canónicas $\mathcal{C}_n$ y $\mathcal{C}_m$ la llamamos la \emph{matriz canónica}.
\end{enumerate}
\end{obs}

\begin{prop}
Dado $f\in\Hom_{\mathbb{K}}(V,W)$, para todo $v\in V$, se tiene
$$\Big[ f(v)\Big]^{\mathcal{B}_W}=\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}\Big[ v \Big]^{\mathcal{B}_V}.$$
En particular, si $A=\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$, $\overline{x}=\Big[ v \Big]^{\mathcal{B}_V}$ e $\overline{y}=\Big[ f(v)\Big]^{\mathcal{B}_W}$ entonces
$$\overline{y}=A\overline{x}.$$
\end{prop}

\dem Sean $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}=(a_{ij})$ y $\Big[v\Big]^{\mathcal{B}_V}=(c_i)$. La coordenada $i$ del vector de coordenadas $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}\Big[ v \Big]^{\mathcal{B}_V}$ es $\sum_j a_{ij}c_j$, y as\'i, de las igualdades
\begin{align*}
f(v) & = f(c_1v_1+\cdots+c_nv_n)=c_1f(v_1)+\cdots+c_nf(v_n)\\
 & = c_1\sum_{i=1}^m a_{i1}w_i+\cdots+c_n\sum_{i=1}^m a_{in}w_i\\
 & = \sum_{j=1}^n\sum_{i=1}^m a_{ij}c_jw_i=\sum_{i=1}^m\left(\sum_{j=1}^n a_{ij}c_j\right)w_i,
\end{align*}
se sigue que la coordenada $i$ de $f(v)$ en la base $\mathcal{B}_W$ es igual a la coordenada $i$ del vector de coordenadas  $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}\Big[ v \Big]^{\mathcal{B}_V}$.\qed

\begin{prop}\label{compmult}
Dado $f\in\Hom_{\mathbb{K}}(V,W)$ y $g\in\Hom_{\mathbb{K}}(W,U)$, se tiene
$$
\Big[ g\circ f \Big]^{\mathcal{B}_U}_{\mathcal{B}_V}=\Big[ g \Big]^{\mathcal{B}_U}_{\mathcal{B}_W}\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}.
$$
En particular, si $A=\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$, $B=\Big[ g \Big]^{\mathcal{B}_U}_{\mathcal{B}_W}$ y $C=\Big[ g\circ f \Big]^{\mathcal{B}_U}_{\mathcal{B}_V}$ entonces
$$C=BA.$$
\end{prop}

\dem Sea $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}=(a_{ij})$ y $\Big[ g \Big]^{\mathcal{B}_U}_{\mathcal{B}_W}=(b_{ij})$.
La entrada $ij$ de $\Big[ g \Big]^{\mathcal{B}_U}_{\mathcal{B}_W}\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$ es $\sum_k b_{ik}a_{kj}$, y as\'i, de las igualdades
\begin{align*}
g\circ f(v_j) &= g(a_{1j}w_1+\cdots+a_{mj}w_m)=a_{1j}g(w_1)+\cdots+a_{mj}g(w_m)\\
 & = a_{1j}\sum_{i=1}^rb_{i1}u_i+\cdots+a_{mj}\sum_{i=1}^rb_{im}u_i\\
 & = \sum_{k=1}^r\sum_{i=1}^rb_{ik}a_{kj}u_i=\sum_{i=1}^r\left(\sum_{k=1}^r b_{ik}a_{kj}\right)u_i,
\end{align*}
se sigue que la coordenada $i$ de $g\circ f(v_j)$ en la base $\mathcal{B}_U$ es igual a la entrada $ij$ de la matriz $\Big[ g \Big]^{\mathcal{B}_U}_{\mathcal{B}_W}\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$.\qed

\begin{prop}\label{homym}
El mapa $\Big[ \bullet \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$ definido por
\begin{eqnarray*}
\Big[ \bullet \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}: \Hom_{\mathbb{K}}(V,W) & \longrightarrow & M_{m\times n}(\mathbb{K})\\
f & \longmapsto & \Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}
\end{eqnarray*}
es un isomorfismo de espacios vectoriales sobre $\mathbb{K}$. M\'as a\'un, $f$ es un isomorfismo si y solo si $A=\Big[ f \Big]_{\mathcal{B}_W}^{\mathcal{B}_V}$ es invertible, y en tal caso se tiene $\Big[ f^{-1} \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}=A^{-1}=\left(\Big[ f \Big]_{\mathcal{B}_V}^{\mathcal{B}_W}\right)^{-1}$.
\end{prop}

\dem Sean $f,g\in\Hom_{\mathbb{K}}(V,W)$. Como $(f+g)(v_j)=f(v_j)+g(v_j)$ y $(cf)(v_j)=cf(v_j)$ para todo $j\in\{1,\ldots,n\}$ y todo $c\in \mathbb{K}$, entonces  $\Big[ \bullet \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$ es una transformaci\'on lineal. Para establecer que es una biyecci\'on basta notar que, por la proposici\'on \ref{unitrlin}, dada una matriz $A\in M_{m\times n}(\mathbb{K})$, con $A=(a_{ij})$, existe una \'unica transformaci\'on lineal $f\in \Hom_{\mathbb{K}}(V,W)$ tal que $f(v_j)=\sum_i a_{ij}w_i$.

Sea $\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}=A$. Si $f$ es bijectiva y $B$ es la matriz $\Big[ f^{-1} \Big]_{\mathcal{B}_W}^{\mathcal{B}_V}$, entonces se tiene
$$BA=\Big[ f^{-1} \Big]_{\mathcal{B}_W}^{\mathcal{B}_V}\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}= \Big[ f^{-1}\circ f \Big]^{\mathcal{B}_V}_{\mathcal{B}_V}=\Big[\id_V\Big]^{\mathcal{B}_V}_{\mathcal{B}_V}=I_n,$$
luego $A$ es invertible y $B=A^{-1}$. Si $A$ es invertible, entonces por la proposici\'on \ref{homym} existe una \'unica transformaci\'on lineal $g\in \Hom_{\mathbb{K}}(W,V)$ tal que $A^{-1}$ es la matriz $\Big[ g \Big]^{\mathcal{B}_V}_{\mathcal{B}_W}$. Las igualdades
$$\Big[ g\circ f \Big]^{\mathcal{B}_V}_{\mathcal{B}_V}=\Big[ g \Big]^{\mathcal{B}_V}_{\mathcal{B}_W}\Big[ f \Big]^{\mathcal{B}_W}_{\mathcal{B}_V}=A^{-1}A=I_n=\Big[ \id_V \Big]^{\mathcal{B}_V}_{\mathcal{B}_V},$$
implican $g\circ f=\id_V$. Similarmente, tenemos $f\circ g=\id_W$. As\'i, $f$ es una biyecci\'on y $g$ es la inversa $f^{-1}$.\qed

\begin{defn}
Dadas dos bases $\mathcal{B}=(v_1,\ldots,v_n)$ y $\mathcal{B}'=(v'_1,\ldots,v'_n)$ de $V$. La \emph{matriz de cambio de coordenadas de la base $\mathcal{B}$ a la base $\mathcal{B}'$} es la matriz $\Big[\id_V\Big]^{\mathcal{B}'}_\mathcal{B}$.
\end{defn}

\begin{obs}
La columna $j$ de $\Big[\id_V\Big]^{\mathcal{B}'}_{\mathcal{B}}$ es el vector de coordenadas $\Big[ v_j\Big]^{\mathcal{B}'}$, en particular tenemos
$$\Big[\id_V\Big]^{\mathcal{B}'}_{\mathcal{B}}=\Bigg[\Big[ v_1\Big]^{\mathcal{B}'}\Big|\cdots \Big| \Big[ v_n\Big]^{\mathcal{B}'}\Bigg].$$
\end{obs}

\begin{prop}
Dadas dos bases $\mathcal{B}=(v_1,\ldots,v_n)$ y $\mathcal{B}'=(v'_1,\ldots,v'_n)$ de $V$.
\begin{enumerate}[(i)]
\item Para todo $v\in V$ se tiene $\Big[v\Big]^{\mathcal{B}'}=\Big[\id_V\Big]^{\mathcal{B}'}_\mathcal{B}\Big[v\Big]^{\mathcal{B}}.$
\item La matriz de cambio de coordenadas de una base a la otra y la matriz de cambio inverso son una la inversa de la otra, es decir que se tiene la igualdad
$$\Big[\id_V\Big]^{\mathcal{B}}_{\mathcal{B}'}=\left(\Big[\id_V\Big]^{\mathcal{B}'}_{\mathcal{B}}\right)^{-1}.$$
\end{enumerate}
\end{prop}

\dem \begin{enumerate}[(i)]
\item Se sigue de las igualdades $\Big[v\Big]^{\mathcal{B}'}=\Big[\id_V(v)\Big]^{\mathcal{B}'}=\Big[\id_V\Big]^{\mathcal{B}'}_\mathcal{B}\Big[v\Big]^{\mathcal{B}}.$ 
\item Se sigue de la proposici\'on \ref{homym} aplicada a $\id_V$ y de la igualdad $\id_V^{-1}=\id_V.$
\end{enumerate}
\qed

\begin{prop}
Sean $\mathcal{B}_V$, y $\mathcal{B}'_V$ bases de $V$, y $\mathcal{B}_W$, y $\mathcal{B}'_W$ bases de $W$. Para toda $f\in\Hom_{\mathbb{K}}(V,W)$, se tiene
\[
\Big[ f\Big]^{\mathcal{B}_W'}_{\mathcal{B}'_V}=\Big[\id_W\Big]^{\mathcal{B}'_W}_{\mathcal{B}_W}\Big[ f\Big]^{\mathcal{B}_W}_{\mathcal{B}_V}\Big[\id_V\Big]^{\mathcal{B}_V}_{\mathcal{B}'_V}.
\]
En particular, si $A=\Big[ f\Big]^{\mathcal{B}_W}_{\mathcal{B}_V}$, $B=\Big[ f\Big]^{\mathcal{B}_W'}_{\mathcal{B}'_V}$, $C_1=\Big[\id_V\Big]^{\mathcal{B}_V}_{\mathcal{B}'_V}$ y $C_2=\Big[\id_W\Big]^{\mathcal{B}_W}_{\mathcal{B}'_W}$ entonces
$$B=C_2^{-1}AC_1.$$
\end{prop}

\dem La propiedad se sigue de la igualdad $f=\id_W\circ f\circ id_V$ y de la proposici\'on \ref{compmult}.\qed

\begin{obs}
Sean $\mathcal{B}$ y $\mathcal{B}'$ bases de $V$ y sea $f\in\End_{\mathbb{K}}(V)$. Para
\[
A=\Big[ f\Big]^{\mathcal{B}}_{\mathcal{B}},\quad B=\Big[ f\Big]^{\mathcal{B}'}_{\mathcal{B}'},\textrm{ y}\quad C=\Big[\id_V\Big]^{\mathcal{B}}_{\mathcal{B}'}
\]
tenemos
\[
B=C^{-1}AC.
\]
\end{obs}

\begin{ejem}
Suponga que $\chara(\mathbb{K})\ne 2$, de forma que $-1\ne 1$ en $\mathbb{K}$. Sea $f\in\Hom_{\mathbb{K}}\left(\mathbb{K}^2,\mathbb{K}^2\right)$ el operador definido por
$$f(x,y)=(y,x).$$
Para la base canónica $\mathcal{C}$ se tiene
$$\Big[ f\Big]^{\mathcal{C}}_{\mathcal{C}}=
\left[\begin{array}{rr}
0 & 1\\ 1 & 0
\end{array}\right]
$$
y para $\mathcal{B}=\left((1,1),(1,-1)\right)$ se tiene
$$\Big[ \id_{\mathbb{K}^2}\Big]^{\mathcal{C}}_{\mathcal{B}}=
\left[\begin{array}{rr}
1 & 1\\ 1 & -1
\end{array}\right],
$$
luego
\begin{align*}
\Big[ f\Big]^{\mathcal{B}}_{\mathcal{B}} &= \Big[ \id_{\mathbb{K}^2}\Big]^{\mathcal{B}}_{\mathcal{C}}\Big[ f\Big]^{\mathcal{C}}_{\mathcal{C}}\Big[ \id_{\mathbb{K}^2}\Big]^{\mathcal{C}}_{\mathcal{B}}\\
 &=\left[\begin{array}{rr}
1 & 1\\ 1 & -1
\end{array}\right]^{-1}
\left[\begin{array}{rr}
0 & 1\\ 1 & 0
\end{array}\right]
\left[\begin{array}{rr}
1 & 1\\ 1 & -1
\end{array}\right]\\
 &= \left[\begin{array}{rr}
1 & 0\\ 0 & -1
\end{array}\right].
\end{align*}
\end{ejem}

\begin{obs}[Vector de coordenadas en dimensi\'on infinita]\label{defnvectcoorinfty}
Dada una base $\mathcal{B}$ de $V$, con $\mathcal{B}=(v_i)_{i\in I}$, para cada $v\in V$ existe una \'unica combinaci\'on lineal de $\mathcal{B}$ igual a $v$. Para $i\in I$, sean $c_i\in \mathbb{K}$ los coeficientes de esta combinaci\'on lineal, es decir tenemos $\sum_{i\in I} c_iv_i=v$.
La unicidad de esta combinaci\'on lineal nos permite identificar cada elemento en $v$ con el elemento $\Big[v\Big]^\mathcal{B}\in\left(\mathbb{K}^I\right)_0$ definido por
\begin{eqnarray*}
\Big[v\Big]^\mathcal{B}: I & \longrightarrow & \mathbb{K}\\
i & \longrightarrow & c_i.
\end{eqnarray*}
\end{obs}

\begin{obs}[Dimensi\'on infinita e isomorfismo]\label{dimiso}
La caracterizaci\'on de los espacios lineales, salvo isomorfismos, por su dimensi\'on se puede reescribir as\'i: si $\mathcal{B}_V$ y $\mathcal{B}_W$ son respectivamente bases $V$ y $W$, con $\mathcal{B}_V=(v_j)_{j\in J}$ y $\mathcal{B}_W=(w_i)_{i\in I}$, entonces $V\simeq_{\mathbb{K}} W$ si y solo si existe una biyecci\'on $\phi:J\rightarrow I$.\\
Empecemos por establecer la suficiencia. Note que los mapas (ver notaci\'on en Observaci\'on \ref{defnvectcoorinfty})
\[
\begin{array}{rclcrcl}
V & \longrightarrow & \left(\mathbb{K}^{J}\right)_0 &\qquad\textrm{y}\qquad& W & \longrightarrow & \left(\mathbb{K}^I\right)_0 \\
v & \longmapsto & \Big[v\Big]^{\mathcal{B}_V} &\qquad& w & \longmapsto & \Big[w\Big]^{\mathcal{B}_W}, 
\end{array}
\]
son isomorfismos. Ahora, dada una biyecci\'on $\phi:J\rightarrow I$ entre los indices de las bases, la transformaci\'on lineal $\Phi\in\Hom_{\mathbb{K}}\left(\left(\mathbb{K}^J\right)_0,\left(\mathbb{K}^I\right)_0\right)$ definida en la base $\{\delta_j\}_{j\in J}$ de $\left(\mathbb{K}^J\right)_0$ (ver el ejemplo \ref{ejembas0}.(iii)) por $\Phi(\delta_j)=\delta_{\phi(j)}$ es un isomorfismo. Tenemos as\'i $V\simeq_{\mathbb{K}}\left(\mathbb{K}^J\right)_0\simeq_{\mathbb{K}}\left(\mathbb{K}^I\right)_0\simeq_{\mathbb{K}} W$.\\
Para establecer la necesidad necesitamos demostrar que si $V$ y  $W$ son isomorfos, entonces existe una biyecci\'on entre $J$ e $I$. Para esto basta demostrar que dos bases cualesquiera de $V$ est\'an en correspondencia biyectiva, pues si $f\in\Hom_{\mathbb{K}}(W,V)$ es un isomorfismo, entonces la imagen $f(\mathcal{B}_W)$ es una base de $V$ y es un conjunto en biyecci\'on con $J$, y luego, si existe una biyecci\'on entre $\mathcal{B}_V$ y $f\left(\mathcal{B}_W\right)$, entonces hay una biyecci\'on entre $J$ e $I$. Supongamos entonces que $V$ tiene dimensi\'on infinita y sean $\mathcal{B}_V$ y $\mathcal{B}'_V$ respectivamente las bases $(v_j)_{j\in J}$ y $(v_{j'})_{j'\in J'}$ de $V$. Para cada $j\in J$ denote por $J'_j$ al conjunto de indices $j'\in J'$ para los cuales $v_j$ tiene coordenada diferente de cero en la base $\mathcal{B}'$, es decir tenemos $J'_j=\left\{j'\in J'\ |\ \Big[v_j\Big]^{\mathcal{B}'_V}_{j'}\ne 0\right\}$. En particular $J'_j$ es la m\'inima colecci\'on de indices $j'\in J'$ con la propiedad $v_j\in\langle v_j'\rangle_{j'\in J'_j}$. Tenemos que, para $j\in J$, cada $J'_j$ es finito. Veamos que $\cup_{j\in J}J'_j=J'$. De hecho, en caso contrario, si existe $j'\in J'\setminus \bigcup_{j\in J}J'_j $ y $\{v_{j_1},\ldots,v_{j_n}\}\subseteq \mathcal{B}_V$ es tal que $v_{j'}$ est\'a en $\langle v_{j_1},\ldots,v_{j_n}\rangle$, entonces $v_{j'}$ est\'a en $\langle v_{k'}|\ k'\in \bigcup_{k=1}^n J'_{j_k} \rangle$ que es un subespacio de $\langle v_{k'}|\ k'\in J'\setminus\{j'\}\rangle$,
lo cual, por el lema \ref{inddep}, violar\'ia la independencia lineal de $\mathcal{B}'_V=\{v_{k'}\}_{k'\in J'}$. Defina $\mathcal{J}'$ como la uni\'on disyunta de todos los $J'_j$, para $j\in J$, es decir $\mathcal{J}'=\coprod_{j\in J} J'_j$.
Como $\mathcal{J}'$ es una uni\'on de conjuntos finitos y disyuntos indexada por $J$ y $J$ es infinito, entonces $J$ y $\mathcal{J}'$ son conjuntos biyectivos. Como tenemos $\cup_{j\in J}J'_j=J'$, en $\mathcal{J}'$ podemos inyectar a $J'$, y, as\'i tambi\'en, en $J$. Sim\'etricamente podemos inyectar $J$ en $J'$. Luego, por el teorema de Schroeder-Bernstein, $J$ y $J'$ son biyectivos.
\end{obs}

\begin{obs}[Dimensi\'on arbitraria y descomposici\'on del dominio]
El teorema \ref{teorango} del rango se demostr\'o descomponiendo una base del dominio de la transformaci\'on lineal. Este resultado lo podemos generalizar a espacios de dimensi\'on infinita de la siguiente manera. Sea $f\in\Hom_{\mathbb{K}}(V,W)$, entonces existe una base de $\mathcal{B}$ de $V$ tal que $\mathcal{B}$ es igual a la unión de dos conjuntos disyuntos $\mathcal{B}_0$ y $ \mathcal{B}_1$, donde $\mathcal{B}_0$ es una base de $\ker(f)$ y $f\left(\mathcal{B}_1\right)$ es una base de $\im(f)$. De hecho, basta tomar una base $\mathcal{B}_0$ de $\ker(f)$ y extenderla a una de $V$ (ver Observaci\'on \ref{basesinfty}). El resto de detalles son similares a los de la demostraci\'on del teorema.
\end{obs}

\begin{obs}[Dimensi\'on infinita y transformaciones lineales]\label{unitrlinealinfty}
La proposici\'on \ref{unitrlin} de rigidez de las transformaciones lineales tambi\'en se puede generalizar a espacios de dimensi\'on infinita. Sea $C$ un conjunto generador de $V$. Dada una funci\'on $f_0: C\rightarrow W$, existe a los sumo una transformaci\'on lineal $f\in\Hom_{\mathbb{K}}(V,W)$ para la cual se tiene $f(v)=f_0(v)$ para todo $v\in C$. Si adem\'as $C$ es linealmente independiente, entonces una tal transformaci\'on lineal $f$ existe. La demostraci\'on es fundamentalmente la misma que en el caso de base finita. Note que un caso particular de esta observaci\'on ya se us\'o en Observaci\'on \ref{dimiso}.
\end{obs}

\section*{Ejercicios}
\begin{enumerate}
  \item Sea $f\in\Hom_{\mathbb{Q}}\left(\mathbb{Q}^3,\mathbb{Q}^3\right)$ tal que $f(1,0,0)=(0,1,2)$, $f(0,1,0)=(1,2,3)$ y $f(0,0,1)=(2,0,-1)$. Encuentre la matriz canónica de $f$ y verifique que $f(x,y,z)=(y+2z,x+2y,2x+3y-z)$.
  \item Obtenga la matrix canónica de $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^3,\mathbb{Q}^3)$ donde
$$f(x,y,z)=(3x-3y-z,-y-4z,5x-7y+2z).$$
  \item Obtenga la matrix canónica de $f\in\textrm{Hom}_{\mathbb{Q}}(\mathbb{Q}^4,\mathbb{Q}^4)$ donde
$$f(x,y,z,w)=(x-y+z+w,-x-y-z,2x-y-2z-w,2x-y-z)$$
  \item Obtenga la matrix canónica de cada una de las transformaciones en el ejercicio 1.3.6.
  \item Sean $f,g\in\Hom_{\mathbb{Q}}\left(\mathbb{Q}^3,\mathbb{Q}^3\right)$ definidas por
  $$f(x,y,z)=(y+2z,x+2y,2x+3y-z)$$
  y
  $$g(x,y,z)=(3x-3y-z,-y-4z,5x-7y+2z).$$
  Encuentre la matriz canónica de $f\circ g$ y $g\circ f$.
  \item Sea $V=\mathbb{R}[t]_{\le 2}$ el espacio de polinomios de grado menor o igual a $2$ con coeficientes reales y $\mathcal{B}$ la base $(1,t,t^2)$. Encuentre la matrix para la base $\mathcal{B}$ de $f\in\End_{\mathbb{R}}(V)$ con $f(P(t))=P(t)+\frac{d}{dt}P(t)$. Determine si $f$ es invertible y en tal caso encuentre la matrix de $f^{-1}$ para $\mathcal{B}$.
\end{enumerate}

\section{Sumas directas y proyecciones}

Sea $V$ un espacio vectorial sobre $\mathbb{K}$.

\begin{defn}
Dados $V_1,\ldots,V_n\le V$, definimos su \emph{suma} como el conjunto $\left\{v_1+\cdots+v_n\in V\ |\ v_i\in V_i, i=1,\ldots,n \right\}$ que denotamos por $V_1+\cdots+V_n$ \'o por $\sum_{i=1}^n V_i$.
\end{defn}

\begin{prop}
Si $V_1,\ldots,V_n$ son subespacios de $V$, entonces $V_1+\cdots+V_n$ es un subespacion de $V$.
\end{prop}

\dem Usamos la proposición \ref{subespsiysolosi}. Primero, note que $V_1+\cdots+V_n$ contiene al origen. Tome $v,v'\in  V_1+\cdots+V_n$ y $c\in \mathbb{K}$. Para $i\in\{1,\ldots,n\}$, sean $v_i,v'_i\in V_i$ tales que se tiene $v=v_1+\cdots+v_n$ y $v'=v'_1+\cdots+v'_n$. Obtenemos as\'i $v+v'=(v_1+v'_1)+\cdots+(v_n+v'_n)$, y por ende, como $v_i+v'_i$ pertenece a $V_i$, para $i\in\{1,\ldots,n\}$, entonces $v+v'$ pertenece a $V_1+\cdots+V_n$. Igualmente, como tenemos $cv_i\in V_i$, para $i\in\{1,\ldots,n\}$, de la igualdad $cv=cv_1+\cdots+cv_n$ vemos que $v$ est\'a en $V_1+\cdots+V_n$.\qed

\begin{teo}\label{sumaint}
Si $V_1$ y $V_2$ son subespacios de $V$ de dimensi\'on finita, entonces $V_1\cap V_2$ y $V_1+V_2$ tambi\'en lo son. M\'as a\'un se tiene
\[
\dim(V_1+V_2)=\dim(V_1)+\dim(V_2)-\dim(V_1\cap V_2),
\]
o equivalentemente, $\dim(V_1)+\dim(V_2)=\dim(V_1+V_2)+\dim(V_1\cap V_2)$.
\end{teo}

\dem Como $V_1$ tiene dimensi\'on finita, y $V_1\cap V_2$ es un subespacio de $V_1$, entonces, por el teorema \ref{monodim} de monotonía de la dimensión, $V_1\cap V_2$ tambi\'en tiene dimensi\'on finita. Sean $n_1=\dim(V_1)$, $n_2=\dim(V_2)$, $p=\dim(V_1\cap V_2)$ y $\{v_1,\ldots,v_p\}$ una base de $V_1\cap V_2$. Extendemos esta base de $V_1\cap V_2$ a una base $\mathcal{B}_1$ de $V_1$ constituida por los vectores $v_1,\ldots,v_p,v'_{p+1},\ldots,v'_{n_1}$, y a una base $\mathcal{B}_2$ de $V_2$ constituida por los vectores $v_1,\ldots,v_p,v''_{p+1},\ldots,v''_{n_2}$. As\'i, el conjunto $\{v_1,\ldots,v_p,v'_{p+1},\ldots,v'_{n_1},v''_{p+1},\ldots,v''_{n_2}\}$ genera a $V_1+V_2$, luego este subespacio tiene dimensi\'on finita. Sea $$\mathcal{B}=(v_1,\ldots,v_p,v'_{p+1},\ldots,v'_{n_1},v''_{p+1},\ldots,v''_{n_2}).$$ El teorema se sigue si demostramos que $\mathcal{B}$ es una base, para esto nos hace falta demostrar que es linealmente independiente y lo haremos usando la proposici\'on \ref{proplinind}. Suponga que $a_1,\ldots,a_p,a'_{p+1},\ldots,a'_{n_1},a''_{p+1},\ldots,a''_{n_2}$ son tales que se tiene
\[
O=\underbrace{\sum_{i=1}^p a_iv_i+\sum_{i=p+1}^{n_1}a'_iv'_i}_{v}+\underbrace{\sum_{i=p+1}^{n_2} a''_iv''_i}_{-v}.
\]
Luego, para $v=\sum_{i=1}^p a_iv_i+\sum_{i=p+1}^{n_1}a'_iv'_i$ tenemos que $v$ est\'a en $V_1$ y también $v=-\sum_{i=p+1}^{n_2} a''_iv''_i$ tambi\'en está en $V_2$, y por ende $v$ est\'a en $V_1\cap V_2$. Sean $b_1\ldots,b_p\in \mathbb{K}$ para los cuales se tiene
\[
v=b_1v_1+\cdots+b_pv_p,
\]
entonces obtenemos
\[
O=v-v=\sum_{i=1}^p (a_i-b_i)v_i+\sum_{i=p+1}^{n_1}a'_iv'_i.
\]
Por la independencia lineal de $\mathcal{B}_1$ tenemos $a'_{p+1}=\ldots=a'_{n_1}=0$ y
\[
O=\sum_{i=1}^p a_iv_i+\sum_{i=p+1}^{n_2} a''_iv''_i.
\]
Por la independencia lineal de $\mathcal{B}_2$, tenemos $a_1=\ldots=a_p=a''_{p+1}=\ldots=a''_{n_2}=0$. \qed

\begin{obs}
Note que si $i,s,n_1,n_2$ son tales que $i\le n_1\le n_2\le s$ y $s$ es menor que la dimensi\'on de $V$, entonces existen $V_1,V_2\le V$ con $\dim(V_1)=n_1$, $\dim(V_2)=n_2$, $\dim(V_1\cap V_2)=i$ y $\dim(V_1+V_2)=s$, siempre que
\[
n_1+n_2=s+i.
\]
De hecho si $\{v_1,\ldots,v_s\}$ es una colecci\'on de $s$ vectores linealmente independientes en $V$ basta tomar
$V_1=\langle v_1,\ldots,v_{n_1}\rangle$ y  $V_2=\langle v_1,\ldots,v_i,v_{n_1+1},\ldots,v_s\rangle$.
M\'as a\'un, si $V'_1$ y $V'_2$ son subespacios de $V$ para los que se tiene $\dim(V'_1)=n_1$, $\dim(V'_2)=n_2$, $\dim(V'_1\cap V'_2)=i$ y $\dim(V'_1+V'_2)=s$, entonces existe un automorfismo $f\in\End_\mathbb{K}(V)$ tal que $f(V_1)=V'_1$ y $f(V_2)=V'_2$.
\end{obs}

\begin{defn}
Sean $V_1,V_2\le V$. Decimos que $V_1$ y $V_2$ est\'an en \emph{posici\'on general} si $\dim(V_1+V_2)$ es tan grande y $\dim(V_1\cap V_2)$ es tan peque\~no como lo es posible.
\end{defn}

\begin{ejem}
Dos subespacios bidimensional de un espacio tridimensional est\'an en posici\'on general si su intersecci\'on es un espacio unidimensional. Dos subespacio cuatridimensional de un espacio sexadimensional est\'an en posici\'on general si su intersecci\'on es un espacio bidimensional. Dos subespacios tridimensionales en un espacio septadimensional est\'an en posici\'on general si su intersecci\'on es trivial.
\end{ejem}

\begin{defn}
Sean $V_1,\ldots,V_r\le V$, decimos que $V$ es la \emph{suma directa} de $V_1,\ldots,V_r$, lo cual denotamos por
\[
V=V_1\oplus\cdots\oplus V_r=\bigoplus_{i=1}^r V_i
\]
si para cada $v\in V$ existe un \'unico $(v_1,\ldots,v_r)\in V_1\times\cdots\times V_r$ que cumple
\[
v=v_1+\cdots+v_r.
\]
\end{defn}

\begin{prop}\label{sumadirsiysolosi}
Sean $V_1,\ldots,V_r\le V$. Se tiene $V=\bigoplus_{i=1}^r V_i$ si y solo si $V_1,\ldots,v_r$ satisfacen las siguientes dos propiedades.
\begin{enumerate}[(i)]
\item La suma $\sum_{i=1}^r V_i$ es igual a $V$.
\item Para todo $i\in\{1,\ldots,r\}$ se tiene $V_i\cap\sum_{j\ne i} V_j=\{O\}$.
\end{enumerate}
\end{prop}

\dem Suponga primero que tenemos $V=\bigoplus_{i=1}^r V_i$, luego por definici\'on tenemos $V=\sum_{i=1}^r V_i$. Por otro lado, sea $i\in\{1,\ldots,r\}$ y tome $v\in V_i\cap\sum_{j\ne i} V_j$. As\'i, existe $(v_1,\ldots,v_r)\in V_1\times\cdots\times V_r$ para el cual se cumple $v=-v_i=\sum_{j\ne i} v_j$ y por lo cual se tiene $O=v_1+\cdots+v_r$. Pero por otro lado, para $(O,\ldots,O)\in V_1\times\cdots\times V_r$ se tiene $O=O+\cdots+O$, luego, por unicidad de esta descomposici\'on se siguen las igualdades $v_1=\ldots=v_r=O$, $v=O$ y $V_i\cap\sum_{j\ne i} V_j=\{O\}$.\\
Rec\'iprocamente, suponga que $\sum_{i=1}^r V_i$ es igual a $V$ y que para todo $i\in\{1,\ldots,r\}$ se tiene $V_i\cap\sum_{j\ne i} V_j=\{O\}$. Sea $v\in V$. Entonces existe $(v_1,\ldots,v_r)\in V_1\times\cdots\times V_n$ para el cual se tiene $v=v_1+\cdots+v_r$. Veamos que esta descomposici\'on es \'unica. De hecho, si $(v'_1,\ldots,v'_r)\in V_1\times\cdots\times V_r$ es tal que se tiene $v=v'_1+\cdots+v'_r$, dado $i\in\{1,\ldots,r\}$, se obtiene
\[
\underbrace{v_i-v'_i}_{\in\ V_i}=\underbrace{\sum_{j\ne i} (v'_j-v_j)}_{\in\ \sum_{j\ne i} V_j}.
\]
Luego tenemos $v_i-v'_i\in V_i\cap\sum_{j\ne i} V_j=\{O\}$, es decir $v_i-v'_i=O$ y as\'i $v_i=v'_i$.\qed

\begin{prop}
Sean $V_1,\ldots, V_r\le V$ tales que $V=\sum_{i=1}^r V_i$ y suponga que $V$ tiene dimensi\'on finita. Entonces la siguientes propiedades son equivalentes.
\begin{enumerate}[(i)]
\item Para todo $i\in\{1,\ldots,r\}$ se tiene $V_i\cap\sum_{j\ne i} V_j=\{O\}$.
\item Se tiene $\sum_{i=1}^n \dim(V_i)=\dim(V)$.
\end{enumerate}
\end{prop}

\dem Suponga primero que tenemos $V_i\cap\sum_{j\ne i} V_j=\{O\}$, para todo $i\in\{1,\ldots,r\}$. Por el teorema \ref{sumaint} se obtiene
$$\dim(V)=\dim(V_1)+\dim\left(\sum_{j>1} V_j\right).$$
La inclusi\'on $V_2\cap\sum_{j>2} V_j\subseteq V_2\cap\sum_{j\ne 2} V_j$ implica la igualdad $\left(V_2\cap\sum_{j> 2} V_j\right)=\{O\}$. Por el teorema \ref{sumaint} se obtiene
$$\dim\left(\sum_{j>1} V_j\right)=\dim(V_2)+\dim\left(\sum_{j>2} V_j\right).$$
Inductivamente, obtenemos 
\begin{eqnarray*}
\dim(V) & = & \dim(V_1)+\dim\left(\sum_{j>1} V_j\right)\\
             & = & \dim(V_1)+\dim(V_2)+\dim\left(\sum_{j>2} V_j\right)\\
             & \vdots & \\
             & = & \dim(V_1)+\cdots+\dim(V_r)          
\end{eqnarray*}
Suponga ahora que se tiene $\sum_{i=1}^r \dim(V_i)=\dim(V)$. Por el teorema \ref{sumaint} se tienen las desigualdades
\begin{eqnarray*}
\dim(V) & \le & \dim(V_1)+\dim\left(\sum_{j>1} V_j\right)\\
             & \le & \dim(V_1)+\dim(V_2)+\dim\left(\sum_{j>2} V_j\right)\\
             & \vdots & \\
             & \le & \sum_{i=1}^r \dim(V_i).      
\end{eqnarray*}
Pero se tiene $\sum_{i=1}^r \dim(V_i)=\dim(V)$, luego estas desigualdades son igualdades y en particular obtenemos $\dim(V)=\dim(V_1)+\dim\left(\sum_{j>1} V_j\right)$. De donde, por el mismo teorema \ref{sumaint}, se tiene $\dim\left(V_1\cap\sum_{j\ne 1} V_j\right)=O$, es decir $V_1\cap\sum_{j\ne 1} V_j=\{O\}$. Reordenando los subespacios $V_i$, $i=1,\ldots,n$, obtenemos $V_i\cap\sum_{j\ne i} V_j=\{0\}$, para todo $i\in\{1,\ldots,r\}$. \qed

\begin{obs}\label{baseparticion}
  De la proposición anterior se sigue que si $\mathcal{B}=(v_1,\ldots,v_n)$ es una base de $V$ y $C_1$, $\ldots$, $C_r$ forman una partición de $\mathcal{B}$, entonces $V=V_1\oplus\cdots\oplus V_r$ donde $V_i=\langle C_i\rangle$, $i\in\{1,\ldots,r\}$. Y reciprocamente, si $V=V_1\oplus\cdots\oplus V_r$ y $\B_i$ es una base de $V_i$ para $i\in\{1,\ldots,r\}$, la concatenación de estas bases $\B=\left(\B_1|\cdots|B_n\right)$ es una base de $V$.
\end{obs}

\begin{defn}
Sea $p\in\End_\mathbb{K}(V)$. Decimos que $p$ es una \emph{proyecci\'on} si $p\circ p=p$.
\end{defn}

\begin{obs}
Si $p\in\End_\mathbb{K}(V)$ es una proyecci\'on y $V_0$ es la imagen de $p$, entonces $p(v_0)=v_0$ para todo $v_0\in V_0$. De hecho si $v_0$ pertenece a $V_0$, existe $v\in V$ que satisface $p(v)=v_0$, luego obtenemos $p(v_0)=p\circ p(v)=p(v)=v_0$.
\end{obs}

\begin{obs}\label{sumayproyeccion}
Suponga que tenemos $V=V_1\oplus V_2$, y defina los operadores $p_1,p_2\in\End_\mathbb{K}(V)$ por $p_1(v)=v_1$ y $p_2(v)=v_2$ si se tiene $v=v_1+v_2$ con $(v_1,v_2)\in V_1\times V_2$. Note que $p_1$ y $p_2$ son proyecciones que cumplen $p_1\circ p_2=p_2\circ p_1=\underline{O}$ y $p_1+p_2=\id_V$. Similarmente, si tenemos $V=\bigoplus_{i=1}^{n}V_i$, podemos definir $n$ proyecciones $p_1,\ldots,p_n$ que satisfacen $p_i(V)=V_i$, para cada $i\in\{1,\ldots,n\}$, $\sum_{i=1}^n p_i=\id_V$, y $p_i\circ p_j=\underline{O}$ si $i\ne j$. Esto nos sugiere otra forma de caracterizar sumas directas, como se hace en el siguiente teorema.
\end{obs}

\begin{teo}\label{proysumadir}
Sean $p_1,\ldots,p_n\in\End_\mathbb{K}(V)$ proyecciones y $V_1,\ldots,V_n$ sus respectivas im\'agenes. Si $\sum_{i=1}^n p_i=\id_V$ y $p_i\circ p_j=0$ para $i\ne j$, entonces $V=\bigoplus_{i=1}^n V_i$.
\end{teo}

\dem Usamos la propiedad \ref{sumadirsiysolosi} para establecer este teorema. Veamos que tenemos $V=\sum_{i=1}^nV_i$. Dado $v\in V$, tomamos, para $i\in\{1,\ldots,n\}$, $v_i\in V_i$ con $v_i=p_i(v)$ y obtenemos
\[
v=\id_V(v)=\sum_{i=1}^n p_i(v)=\sum_{i=1}^n v_i.
\]
Basta ahora establecer que $V_i\cap\sum_{j\ne i} V_j=\{O\}$ para todo $i\in\{1,\ldots,n\}$. Para ello, fijemos un índice $i$, tomemos $v\in V_i\cap\sum_{j\ne i} V_j$ y veamos que $v=O$. Como $v$ pertenece a $\sum_{j\ne i} V_j$, tenemos $v=\sum_{j\ne i} v_j$ para algunos $v_j\in V_j$, con $j\ne i$. En particular, para cada $j\ne i$, existe $v'_j\in V$ que satisface $v_j=p_j(v'_j)$, y as\'i obtenemos $v=\sum_{j\ne i} p_j(v_j)$. Por otro lado, como $v$ pertenece a $V_i$, existe $v'_i\in V$ que satisface $v=p_i(v'_i)$. Por ende, se siguen las igualdades
\[
v=p_i(v'_i)=p_i\circ p_i (v'_i)=p_i(v)=p_i\left(\sum_{j\ne i} p_j(v_j)\right)=\sum_{j\ne i} p_i\circ p_j(v_j)=O.
\]
\qed

\begin{defn}\label{sumadirectaoperadores}
  Suponga que $V=V_1\oplus\cdots\oplus V_r$. Para $i\in\{1,\ldots,r\}$, sean $f_{V_i}\in\Hom_\mathbb{K}(V_i,V_i)$. La \emph{suma directa} $f=f_{V_1}\oplus\cdots\oplus f_{V_r}$ es el operador en $\End_\mathbb{K}(V)$ definido por $$f(v)=f_{V_1}(v_1)+\cdots+f_{V_r}(v_r)$$
  donde $(v_1,\ldots,v_r)\in V_1\times\cdots\times V_r$ es tal que $v=v_1+\cdots+v_r$.
\end{defn}

\begin{obs}\label{diagonalbloques}
  Suponga que $V=V_1\oplus\cdots\oplus V_r$. Si para $i\in\{1,\ldots,r\}$, se tiene una base $\mathcal{B}_i$ de $V_i$, y $\mathcal{B}=\left(\mathcal{B}_1|\cdots|\mathcal{B}_r\right)$ es la base de $V$ que se obtiene al concatenar estas bases, cuando $f=f_{V_1}\oplus\cdots\oplus f_{V_r}$ con $f_{V_i}\in\Hom_\mathbb{K}(V_i,V_i)$, entonces la matriz de $f$ para la base $\mathcal{B}$
  $$A=\left[\begin{array}{c|c|c}
    A_1 & \cdots & 0\\
    \hline
    \vdots & \ddots & \vdots\\
    \hline
    0 & \cdots & A_r
  \end{array}\right]$$
es una matriz diagonal por bloques donde cada bloque cooresponde a la matriz $A_i=\left[f_{V_i}\right]_{\mathcal{B}_i}^{\mathcal{B}_i}$.
\end{obs}

\begin{obs}
Para terminar est\'a secci\'on, vamos a definir dos generalizaciones de la suma directa, que son la suma directa externa y el producto directo. En estas definiciones combinamos una colecci\'on, no necesariamente finita, de espacios para obtener un nuevo espacio. La suma directa externe y el producto directo de una misma colecci\'on finita de espacios producen espacio isomorfos.
\end{obs}

\begin{defn}\label{productoysuma}
Sea $I$ una colecci\'on de indices y $\left(V_i\right)_{i\in I}$ una familia de espacios vectoriales sobre $\mathbb{K}$. Definimos los siguientes espacios.
\begin{enumerate}[(i)]
\item El \emph{producto directo} de $\left\{V_i\right\}_{i\in I}$ es el espacio
\[
\prod_{i\in I} V_i=\left\{\phi: I\rightarrow \coprod_{i\in I}V_i\ \Big|\ \phi(i)\in V_i\right\},
\]
el cual es un espacio vectorial sobre $\mathbb{K}$ bajo las operaciones
\[
(\phi+\psi)(i)=\phi(i)+\psi(i)\qquad (c\phi)(i)=a\psi(i)
\]
para todo $\phi,\psi\in \prod_{i\in I} V_i$ y $c\in \mathbb{K}$. Para $j\in I$, definimos la $j$-ésima inclusión como la transformación lineal
\begin{eqnarray*}
  \imath_j: V_j & \longrightarrow &\prod_{i\in I} V_i\\
    v_j & \longmapsto & \imath_j(v_j):\left\{\begin{array}{rcl}
                                              j& \mapsto & v_j\\
                                              i& \mapsto & O\text{ si } i\ne j
                                            \end{array}\right\}
\end{eqnarray*}
\item La \emph{suma directa externa} de $\left\{V_i\right\}_{i\in I}$ es el espacio
\[
\bigoplus_{i\in I} V_i=\left\{\phi\in \prod_{i\in I} V_i \Big|\ \phi(i)\ne 0\textrm{ \'unicamente para finitos indices } i\in I\right\},
\]
el cual es un subespacio de $\prod_{i\in I} V_i$. Para $j\in I$, definimos la $j$-ésima proyección como la transformación lineal
\begin{eqnarray*}
  p_j: \bigoplus_{i\in I} V_i & \longrightarrow & V_j\\
    \phi & \longmapsto & \phi(j)
\end{eqnarray*}
\end{enumerate} 
\end{defn}

\begin{obs}\label{propiedaduniversalproductoysuma}
Note que si $\left(V_i\right)_{i\in I}$ es una familia de espacios vectoriales sobre $\mathbb{K}$ indexada por los indices $i\in I$, y nos son dadas $f_i\in\End_\mathbb{K}(V,V_i)$ y $g_i\in\Hom_\mathbb{K}(V_i,V)$, para todo $i\in I$, podemos definir las transformaciones lineales
\[
\begin{array}{rclcrcl}
f:V& \longrightarrow & \prod_{i\in I} V_i &\quad& g: \bigoplus_{i\in I} V_i & \longrightarrow & V \\
  v & \longmapsto & f(v):i\mapsto f_i(v) &\quad& \phi & \longmapsto & \sum_{i\in I} g_i\left(\phi(i)\right). 
\end{array}
\]
Note que la suma $\sum_{i\in I} g_i\left(\phi(i)\right)$ es finita pues $\phi(i)=0$ para todos los $i\in I$ salvo un n\'umero finito de indices.
\end{obs}

\begin{obs}
Si $\mathcal{B}=(v_i)_{i\in I}$ es una base de $V$, entonces se obtienen los isomorfismos
\[
V\ \simeq_\mathbb{K}\ \left(\mathbb{K}^I\right)_0\ \simeq_\mathbb{K}\ \bigoplus_{i\in I}\mathbb{K}.
\]
En general, se tiene
\[
\mathbb{K}^I\ \simeq_\mathbb{K}\ \prod_{i\in I} \mathbb{K}.
\]
\end{obs}

\begin{defn}\label{productoysumadefunciones}
  Suponga que $\left(V_i\right)_{i\in I}$ y $\left(W_i\right)_{i\in I}$ son familias de espacios vectoriales sobre $\mathbb{K}$ indexadas por $I$. Si para cada $i\in I$ tenemos un $f_i\in\Hom_\mathbb{K}(V_i,W_i)$, definimos las siguientes funciones.
\begin{enumerate}[(i)]
  \item El \emph{producto externo} de $\left(f_i\right)_{i\in I}$ por
    \begin{eqnarray*}
    \prod_{i\in I} f_i: \prod_{i\in I} V_i & \longrightarrow & \prod_{i\in I} W_i\\
                           \phi & \longmapsto & \left(\prod_{i\in I} f_i\right) (\phi): i\mapsto f_i\left(\phi(i)\right).
    \end{eqnarray*}
  \item La \emph{suma directa externa} de $\left(f_i\right)_{i\in I}$ por
    \begin{eqnarray*}
    \bigoplus_{i\in I} f_i: \bigoplus_{i\in I} V_i & \longrightarrow & \bigoplus_{i\in I} W_i\\
                           \phi & \longmapsto & \left(\prod_{i\in I} f_i\right) (\phi): i\mapsto f_i\left(\phi(i)\right),
    \end{eqnarray*}
  la cual es la función inducida por $\prod_{i\in I} f_i$ entre los subespacios $\bigoplus_{i\in I} V_i$ y $\bigoplus_{i\in I} W_i$.
\end{enumerate}
\end{defn}

\section*{Ejercicios}
\begin{enumerate}
  \item Suponga que $V_1,V_2,V_3\le V$ son tales que $\dim(V_1+V_2+V_3)< \infty$. Demuestre que
  \begin{align*}
    \dim(V_1+V_2+V_3) = & \dim(V_1)+\dim(V_2)+\dim(V_3)\\
      & \ -\dim(V_1\cap V_2)-\dim(V_1\cap V_3)-\dim(V_2\cap V_3)\\
      & \ \ +\dim(V_1\cap V_2\cap V_3)
  \end{align*}
  \item Suponga que $V_1,\ldots,V_r\le V$ son tales que $\dim(V_1+\cdots+V_r)< \infty$. Demuestre que
  \begin{align*}
    \dim(V_1+\cdots+V_r) = & \sum_{i}^r\dim(V_i)-\sum_{i<j}\dim(V_i\cap V_j)+\sum_{i<j<k}\dim(V_i\cap V_j\cap V_k)\\
      & -\ldots+(-1)^{r-1}\dim(V_1\cap \ldots\cap V_r)
  \end{align*}
  \item Demuestre la afirmación hecha en la observación \ref{baseparticion}.
  \item Demuestre la afirmación hecha en la observación \ref{diagonalbloques}.
  \item Sea $p_1\in\End_\mathbb{K}(V)$ una proyección. Demuestre que $p_2=\id_V-p_1$ es una proyección y que $V=V_1\otimes V_2$ donde $V_1=\im(p_1)$ y $V_2=\im(p_2)$. Pruebe además que $V_1=\ker(p_2)$ y $V_2=\ker(p_1)$.
  \item En $\mathbb{Q}^3$, tome $v_1=(1,0,1)$, $v_2=(0,1,1)$, $v_3=(1,1,0)$ y $\mathcal{B}=(v_1,v_2,v_3)$. Sea $V_1=\langle v_1,v_2\rangle$ y $V_2=\langle v_3\rangle$, y $p_1$ la proyección con imagen $V_1$ y núcleo $V_2$, y $p_2$ la proyección con imagen $V_2$ y núcleo $V_1$. 
    \begin{enumerate}
      \item Encuentre las matrices de $p_1$ y $p_2$ para la base $\mathcal{B}$.
      \item Encuentre las matrices canónicas de $p_1$ y $p_2$.
    \end{enumerate}
  \item En $\mathbb{Q}^3$, tome $v_1=(2,1,1))$, $v_2=(1,2,1)$, $v_3=(1,1,2)$ y $\mathcal{B}=(v_1,v_2,v_3)$. Sea $V_1=\langle v_1\rangle$ y $V_2=\langle v_2,v_3\rangle$, y $p_1$ la proyección con imagen $V_1$ y núcleo $V_2$, y $p_2$ la proyección con imagen $V_2$ y núcleo $V_1$. Encuentre las matrices canónicas de $p_1$ y $p_2$.
  \item Suponga que $V=V_1\oplus\cdots\oplus V_r$ y que $p_1,\ldots,p_r$ son las proyecciones sobre cada uno de los sumandos de acuerdo a esta descomposición de $V$ como suma directa. Tomamos un operador $f\in\End_\mathbb{K}(V)$ y una base $\mathcal{B}$ de $V$.
    \begin{enumerate}
      \item Demuestre que, cuando $\dim(V)<\infty$, se tiene $A=A_1+\cdots+A_r$, donde $A$ es la matriz de $f$ para $\mathcal{B}$, y para $i\in\{1,\ldots,r\}$, $A_i=AP_i$ donde $P_i$ es la matriz de $p_i$ para $\mathcal{B}$.
      \item Suponga además que $f\in\End_\mathbb{K}(V)$ es tal que $f=f_{V_1}\oplus\cdots\oplus f_{V_r}$ con $f_{V_i}\in\End_\mathbb{K}(V_i)$. Demuestre que se tiene $AP_i=P_iA$ para $i\in\{1,\ldots,r\}$.
    \end{enumerate}
  \item Demuestre que las $j$-ésimas inclusiones $\imath_j$ y proyecciones $p_j$ en la definición \ref{productoysuma} son transformaciones lineales. 
  \item Demuestre que las funciones $f$ y $g$ definidas en la observación \ref{propiedaduniversalproductoysuma} son únicas con la propiedad $f\circ\imath_j=f_j$ y $p_j\circ g=g_j$ para todo $j\in I$.
  \item Demuestre que las funciones $\prod_{i\in I} f_i$ y $\bigoplus_{i\in I} f_i$ definidas en la definición \ref{productoysumadefunciones} son transformaciones lineales.
\end{enumerate}

\section{Espacios cocientes}

Sean $V$, $W$ espacios vectoriales sobre $\mathbb{K}$.

\begin{defn}
Dados $V_0\le V$ y $v\in V$, la \emph{translaci\'on de $V_0$ por $v$} es el conjunto
\[
v+V_0=\{v'\in V\ |\ v'=v+v_0,\ v_0\in V\}.
\]
\end{defn}

\begin{obs}
Tenemos $v+V_0=v'+V_0$ si y solo si $v-v'\in V_0$. De hecho, si $v+V_0=v'+V_0$, como $v\in v+V_0=v'+V_0$, entonces existe $v_0\in V_0$ tal que $v=v'+v_0$, es decir $v-v'=v_0\in V_0$; rec\'iprocamente, si $v_0=v-v'\in V_0$, cualquier $w\in v+V_0$ es de la forma $w=v+w_0$ para alg\'un $w_0\in V_0$, en particular $w=v'+(v_0+w_0)\in v'+V_0$, y cualquier $w'\in v'+V_0$ es de la forma $w'=v'+w'_0$ para alg\'un $w'_0\in V_0$, en particular $w'=v+(w'_0-v_0)\in v+V_0$.
\end{obs}

\begin{defn}
Sea $V_0\le V$, el \emph{espacio cociente $V$ m\'odulo $V_0$} es el conjunto de traslaciones de $V_0$:
\[
V/V_0=\{v+V_0\ |\ v\in V\}
\] 
\end{defn}

\begin{prop}
Para todo $V_0\le V$ se tienen las siguientes propiedades.
\begin{enumerate}[(i)]
  \item Si $v,v',w,w'\in V$ son tales que $v+V_0=v'+V_0$ y $w+V_0=w'+V_0$ entonces $(v+w)+V_0=(v'+w')+V_0$
  \item Si $v,v'\in V$ son tales que $v+V_0=v'+V_0$, entonces $cv+V_0=cv'+V_0$ para todo $c\in\mathbb{C}$.
\end{enumerate}
\end{prop}

\dem Se tiene que $v+V_0=v'+V_0$ y $w+V_0=w'+V_0$ si y solo si $v-v'\in V_0$ y $w-w'\in V_0$. En tal caso se sigue que $(v+w)-(v'+w')=(v-v')+(w'-w')\in V_0$, y por ende $(v+v')+V_0=(w+w')+V_0$. Similarmente, se tiene $cv-cv'=c(v-v')\in V_0$, y por ello $cv+V_0=cv'+V_0$.\qed

\begin{prop}
Sea $V_0\le V$. El espacio cociente $V/V_0$ es un espacio vectorial sobre $\mathbb{K}$ bajo las operaciones
\[
\left(v+V_0\right)+\left(w+V_0\right)=(v+w)+V_0\qquad c\left(v+V_0\right)=cv+V_0,
\]
y con origen $O+V_0=V_0$. El mapa
\begin{eqnarray*}
\pi_{V_0}: V & \longrightarrow & V/V_0 \\
                v & \longmapsto & v+V_0
\end{eqnarray*}
es una transformaci\'on lineal sobreyectiva con $\ker(\pi_{V_0})=V_0$
\end{prop}

\dem La proposici\'on anterior garantiza que tales operaciones est\'an bien definidas. Las propiedades de la definici\'on \ref{defespvec} se heredan de las de $V$. La misma proposici\'on implica la linearidad de $\pi_{V_0}$. Por definici\'on de $V/V_0$, $\pi_{V_0}$ es sobreyectiva. Por \'ultimo, se tiene $v\in\ker(\pi_{V_0})$ si y solo si $\pi_{V_0}(v)=V_0$, es decir si y solo si $v+V_0=V_0$, que equivale a $v\in V_0$. \qed

\begin{prop}
Sea $V_0\le V$ y suponga que $V$ tiene dimensi\'on finita, entonces
\[
\dim(V/V_0)=\dim(V)-\dim(V_0)
\]
\end{prop}

\dem Se sigue inmediatamente del teorema \ref{teorango} del rango y de la proposición anterior.

\begin{prop}\label{basecociente}
  Suponga que $V$ tiene dimensión finita y sea $V_0\le V$. Si $\B_0=(v_1,\ldots,v_{n_0})$ es una base de $V_0$ y la extendemos a una base $\B=(v_1,\ldots,v_{n_0},v_{n_0+1},\ldots,v_{n_0+n_1})$ de $V$, entonces $\B_1=(v_{n_0+1}+V_0,\ldots,v_{n_0+n_1}+V_0)$ es una base de $V/V_0$.
\end{prop}

\dem Veamos que $\B_1$ es linealmente independiente. Si $c_1(v_{n_0+1}+V_0) + \cdots + c_{n_1}(v_{n_0+n_1}+V_0) = O+V_0$ entonces $c_1v_{n_0+1}+\cdots+c_{n_1}v_{n_0+n_1}$ está en $V_0$, luego existen $a_1,\ldots,a_{n_0}\in\K$ tales que $c_1v_{n_0+1}+\cdots+c_{n_1}v_{n_0+n_1}=a_1v_1+\ldots+a_{n_0}v_{n_0}$, y así $$-a_1v_1-\cdots-a_{n_0}v_{n_0}+c_1v_{n_0+1}+\cdots+c_{n_1}v_{n_0+n_1}=O.$$ La independencia lineal de los elementos en $\B$ implica que $c_1=\cdots=c_{n_0}=0$. Veamos que $\B_1$ genera a $V/V_0$. De hecho, dado $v+V_0\in V/V_0$ con $$v=a_1v_1+\cdots+a_{n_0}v_{n_0}+c_1v_{n_0+1}+\cdots+c_{n_1}v_{n_0+n_1},$$
si $v'=c_1v_{n_0+1}+\cdots+c_{n_1}v_{n_0+n_1}$, entonces $v-v'=a_1v_1+\cdots+a_{n_0}v_{n_0}$ está en $V_0$, luego $v+V_0=v'+V_0$, y así $v+V_0=c_1(v_{n_0+1}+V_0)+\cdots+c_{n_1}(v_{n_0+n_1}+V_0)$.\qed

\begin{teo}
Sea $f\in\Hom_\mathbb{K}(V,W)$. Si $V_0=\ker(f)$, entonces existe una \'unica transformaci\'on lineal $f_0\in\Hom_\mathbb{K}(V/V_0,W)$ tal que $f=f_0\circ\pi_{V_0}$. La transformaci\'on $f_{0}$ es inyectiva, y, si $f$ es adem\'as sobreyectiva, entonces $f_{0}$ es un isomorfismo.
\end{teo}

\dem Note que $f(v)=f(v')$ si y solo si $v-v'\in V_0$, es decir si y solo si $v+V_0=v'+V_0$. Defina entonces
\begin{eqnarray*}
f_{0}: V/V_0 & \longrightarrow & W\\
            v+V_0 & \longmapsto      & f(v).
\end{eqnarray*}
As\'i, $f_{0}$ es lineal pues $f$ lo es, y adem\'as es inyectiva pues $f(v)=f(v')$ si y solo si $v+V_0=v'+V_0$. Por contrucci\'on $f=f_{0}\circ\pi_{V_0}$. Ahora si $f$ es sobreyectiva, entonces $f_{0}$ es biyectiva y, as\'i, es un isomorfismo.\qed

\begin{teo}\label{operadorcociente}
  Sea $f\in\End_\K(V)$ y $V_0\le V$ tal que $f(V_0)\le V_0$, entonces la función
  \begin{eqnarray*}
    f_{/V_0}: V/V_0 & \longrightarrow & V/V_0\\
    v+V_0 & \longmapsto & f(v)+V_0
  \end{eqnarray*}
  define un operador en $\End_\K(V/V_0)$
\end{teo}

\dem Veamos que $f_{/V_0}$ está bien definida. Si $v,v'\in V$ son tales que $v+V_0=v'+V_0$, es decir $v-v'\in V_0$, entonces $f(v)-f(v')=f(v-v')\in V_0$, así $f(v)+V_0=f(v')+V_0$. Ahora, la linearidad de $f_{/V_0}$ se hereda de la de $f$.

\begin{obs}\label{matrizcociente}
  Suponga que $V$ tiene dimensión finita y que $V_0\le V$ es tal que $f(V_0)\le V_0$ para algún operador $f\in\End_\K(V)$. Considere bases $\B_0$, $\B$ y $\B_1$ de $V_0$, $V$ y $V/V_0$ como en la proposición \ref{basecociente}. Se tiene entonces que la matriz de $f$ para $\B$ es de la forma
  $$
    \left[f\right]_\B^\B=\left[\begin{array}{c|c}
      A & B\\
      \hline
      O & C
    \end{array}\right]
  $$
donde $A$, $B$ y $C$ son respectivamente matrices $n_0\times n_0$, $n_0\times n_1$ y $n_1\times n_1$; y la matriz de $f_{/V_0}$ para $\B_1$ es
  $$
    \left[f_{/V_0}\right]_{\B_1}^{\B_1}=C.
  $$
\end{obs}

\section*{Ejercicios}
\begin{enumerate}
  \item Considere el operador $f$ de $\Q^3$ dado por $f(x,y,z)=(-2x+4z,-x+3y,-3x+2y+3z)$. Verifique que para  $V_0=\langle (1,1,1)\rangle$ se tiene $f(V_0)=V_0$. Encuentre una base de $V/V_0$ y la matriz de $f_{/V_0}$ para esta base.
  \item Considere el operador $f$ de $\Q^4$ dado por $f(x,y,z,w)=(5x+5z+w,-3x-3y,-3x+y,x-y+w)$. Verifique que para  $V_0=\langle e_1,e_4 \rangle$ se tiene $f(V_0)=V_0$. Encuentre una base de $V/V_0$ y la matriz de $f_{/V_0}$ para esta base.
  \item Dada $f\in\Hom_\mathbb{K}(V,W)$ definimos el co-núcleo de $f$ por $\text{cok}(f)=W/\im(f)$. Demuestre que $f$ es sobreyectiva si y solo si el $\text{cok}(f)=\{O+\im(f)\}$.
  \item Sea $f\in\Hom_\mathbb{K}(V,W)$ y suponga que $\dim(W)<\infty$. Demuestre que las siguientes propiedades son equivalentes.
    \begin{enumerate}[(i)]
      \item $\dim(\text{cok}(f))=0$
      \item $\dim(\im(f))=\dim(W)$
    \end{enumerate}
  Compare esta equivalencia con el corolario al teorema del rango \ref{corteorango}.
\end{enumerate}